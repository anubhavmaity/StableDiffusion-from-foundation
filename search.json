[
  {
    "objectID": "lectures/meanshift.html",
    "href": "lectures/meanshift.html",
    "title": "Clustering",
    "section": "",
    "text": "Clustering techniques are unsupervised algorithms that try to group unlabelled data into “clusters”, using the (typically spatial) structure of the data itself. It has many applications.\nThe easiest way to demonstrate how clustering works is to simply generate some data and show them in action. We’ll start off by importing the libraries we’ll be using today.\nimport math, matplotlib.pyplot as plt, operator, torch\nfrom functools import partial\n\n/Users/anubhavmaity/mambaforge/envs/fastai/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\ntorch.manual_seed(42)\ntorch.set_printoptions(precision=3, linewidth=140, sci_mode=False)"
  },
  {
    "objectID": "lectures/meanshift.html#create-data",
    "href": "lectures/meanshift.html#create-data",
    "title": "Clustering",
    "section": "Create data",
    "text": "Create data\n\nn_clusters = 6\nn_samples = 250\n\nTo generate our data, we are going back to pick 6 random points, which we will call centroids, and for each point we are going to generate 250 random points about it.\n\ncentroids = torch.rand(n_clusters, 2) * 70 - 35\n\n\ncentroids\n\ntensor([[ 26.759,  29.050],\n        [ -8.200,  32.151],\n        [ -7.669,   7.063],\n        [-17.040,  20.555],\n        [ 30.854, -25.677],\n        [ 30.422,   6.551]])\n\n\n\nfrom torch.distributions.multivariate_normal import MultivariateNormal\nfrom torch import tensor\n\n\ndef sample(m): return MultivariateNormal(m, torch.diag(tensor([5., 5.]))).sample((n_samples, ))\n\n\nslices = [sample(c) for c in centroids]\ndata  = torch.cat(slices)\ndata.shape\n\ntorch.Size([1500, 2])\n\n\nBelow we can see each centroid marked w/X, and the coloring associated to each respective cluster.\n\ndef plot_data(centroids, data, n_samples, ax=None):\n    if ax is None: _, ax = plt.subplots()\n    for i, centroid in enumerate(centroids):\n        samples = data[i*n_samples: (i+1)*n_samples]\n        ax.scatter(samples[:, 0], samples[:, 1], s=1)\n        ax.plot(*centroid, markersize=10, marker=\"x\", color='k', mew=5)\n        ax.plot(*centroid, markersize=5, marker=\"x\", color='m', mew=2)\n\n\nplot_data(centroids, data, n_samples)"
  },
  {
    "objectID": "lectures/meanshift.html#mean-shift",
    "href": "lectures/meanshift.html#mean-shift",
    "title": "Clustering",
    "section": "Mean Shift",
    "text": "Mean Shift\nMost people that have come across clustering algorithms have learnt about k-means. Mean shift clustering is a newer and less well-known approach, but it has some important advantages: - It doesn’t require selecting the number of clusters in advance, but instead just requires a bandwidth to be specified, which can be easily chosen automatically. - It can handle clusters of any shape, whereas k-means (without using special extensions) requires that clusters be roughly ball shaped\nThe algorithm is as follows: - For each data point x in the sample X, find the distance between that point x and every other point in X - Create weights for each point in X by using the Gaussian kernel of that point’s distance to x - This weighting approach penalizes points further away from x - The rate at which the weights fall to zero is determined by the bandwidth, which is the standard deviation of the Gaussian - Update x as the weighted all other points in X, weighted based on the previous step\nThis will iteratively push points that are close together even closer until they are next to each other\n\nmidp = data.mean(0)\nmidp\n\ntensor([ 9.222, 11.604])\n\n\n\nplot_data([midp]*6, data, n_samples)\n\n\n\n\nSo here is the definition of the gaussian kernel, which you may remember from high school..\n\\[ \\frac{1}{\\sqrt{ 2 \\pi \\sigma^2 }} \\exp\\biggl( - \\frac{ (x - \\mu)^2 } {2 \\sigma^2} \\biggr) \\]\n\ndef gaussian(d, bw): return torch.exp(-0.5*((d/bw))**2) / (bw*math.sqrt(2*math.pi))\n\n\ndef plot_func(f):\n    x = torch.linspace(0, 10, 100)\n    plt.plot(x, f(x))\n\n\nplot_func(partial(gaussian, bw=2.5))\n\n\n\n\n\npartial\n\nfunctools.partial\n\n\nIn our implementation, we choose the bandwidth to be 2.5\nOne easy way to choose bandwidth is to find which bandwidth covers one thid of the data\n\ndef tri(d, i): return (-d + i).clamp_min(0)/i\n\n\nplot_func(partial(tri, i=8))\n\n\n\n\n\nX = data.clone()\nx = data[0]\n\n\nx\n\ntensor([26.204, 26.349])\n\n\n\nx.shape, X.shape, x[None].shape\n\n(torch.Size([2]), torch.Size([1500, 2]), torch.Size([1, 2]))\n\n\n\n(x[None] - X)[:8]\n\ntensor([[ 0.000,  0.000],\n        [ 0.513, -3.865],\n        [-4.227, -2.345],\n        [ 0.557, -3.685],\n        [-5.033, -3.745],\n        [-4.073, -0.638],\n        [-3.415, -5.601],\n        [-1.920, -5.686]])\n\n\n\n(x - X)[:8]\n\ntensor([[ 0.000,  0.000],\n        [ 0.513, -3.865],\n        [-4.227, -2.345],\n        [ 0.557, -3.685],\n        [-5.033, -3.745],\n        [-4.073, -0.638],\n        [-3.415, -5.601],\n        [-1.920, -5.686]])\n\n\n\ndist = ((x-X)**2).sum(1).sqrt()\ndist[:8]\n\ntensor([0.000, 3.899, 4.834, 3.726, 6.273, 4.122, 6.560, 6.002])\n\n\n\n((x-X)**2).sum(1)\n\ntensor([  0.000,  15.199,  23.369,  ..., 310.729, 511.192, 467.316])\n\n\n\nrewrite using torch.einsum\n\n\ntorch.einsum('ik,ik-&gt;i',x-X, x-X).sqrt()\n\ntensor([ 0.000,  3.899,  4.834,  ..., 17.628, 22.610, 21.617])\n\n\n\nweight = gaussian(dist, 2.5)\nweight\n\ntensor([    0.160,     0.047,     0.025,  ...,     0.000,     0.000,     0.000])\n\n\n\nweight.shape, X.shape\n\n(torch.Size([1500]), torch.Size([1500, 2]))\n\n\n\nweight[:, None].shape\n\ntorch.Size([1500, 1])\n\n\n\nweight[:, None] * X\n\ntensor([[    4.182,     4.205],\n        [    1.215,     1.429],\n        [    0.749,     0.706],\n        ...,\n        [    0.000,     0.000],\n        [    0.000,     0.000],\n        [    0.000,     0.000]])\n\n\n\ndef one_update(X):\n    for i, x in enumerate(X):\n        dist = torch.sqrt(((x - X)**2).sum(1))\n#         weight = gaussian(dist, 2.5)\n        weight = tri(dist, 8)\n        X[i] = (weight[:, None] * X).sum(0)/weight.sum()\n\n\ndef meanshift(data):\n    X = data.clone()\n    for it in range(5): one_update(X)\n    return X\n\n\n\n\nCPU times: user 470 ms, sys: 0 ns, total: 470 ms\nWall time: 470 ms\n\n\n\nplot_data(centroids + 2, X, n_samples)"
  },
  {
    "objectID": "lectures/meanshift.html#animation",
    "href": "lectures/meanshift.html#animation",
    "title": "Clustering",
    "section": "Animation",
    "text": "Animation\n\nfrom matplotlib.animation import FuncAnimation\nfrom IPython.display import HTML\n\n\ndef do_one(d):\n    if not d: return plot_data(centroids + 2, X, n_samples, ax=ax)\n    one_update(X)\n    ax.clear()\n    plot_data(centroids + 2, X, n_samples, ax=ax)\n\n\nX = data.clone()\nfig,ax = plt.subplots()\nani = FuncAnimation(fig, do_one, frames=5, interval=500, repeat=False)\nplt.close()\nHTML(ani.to_jshtml())\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\nanimation for your own algorithm"
  },
  {
    "objectID": "lectures/meanshift.html#gpu-batched-algorithm",
    "href": "lectures/meanshift.html#gpu-batched-algorithm",
    "title": "Clustering",
    "section": "GPU batched algorithm",
    "text": "GPU batched algorithm\nTo truly accelerate the algorithm, we need to be performing updates on a batch of points per iteration, instead of just one as were doing\n\nbs = 5\nX = data.clone()\nx = X[:bs]\nx.shape, X.shape\n\n(torch.Size([5, 2]), torch.Size([1500, 2]))\n\n\n\ndef dist_b(a, b): return torch.sqrt(((a[None] - b[:, None])**2).sum(2))\n\n\ndist_b(X, x)\n\ntensor([[ 0.000,  3.899,  4.834,  ..., 17.628, 22.610, 21.617],\n        [ 3.899,  0.000,  4.978,  ..., 21.499, 26.508, 25.500],\n        [ 4.834,  4.978,  0.000,  ..., 19.373, 24.757, 23.396],\n        [ 3.726,  0.185,  4.969,  ..., 21.335, 26.336, 25.333],\n        [ 6.273,  5.547,  1.615,  ..., 20.775, 26.201, 24.785]])\n\n\n\ndist_b(X, x).shape\n\ntorch.Size([5, 1500])\n\n\n\nX[None, :].shape, x[:, None].shape, (X[None, :] - x[:, None]).shape\n\n(torch.Size([1, 1500, 2]), torch.Size([5, 1, 2]), torch.Size([5, 1500, 2]))\n\n\n\nweight = gaussian(dist_b(X, x), 2)\nweight\n\ntensor([[    0.199,     0.030,     0.011,  ...,     0.000,     0.000,     0.000],\n        [    0.030,     0.199,     0.009,  ...,     0.000,     0.000,     0.000],\n        [    0.011,     0.009,     0.199,  ...,     0.000,     0.000,     0.000],\n        [    0.035,     0.199,     0.009,  ...,     0.000,     0.000,     0.000],\n        [    0.001,     0.004,     0.144,  ...,     0.000,     0.000,     0.000]])\n\n\n\nweight.shape, X.shape\n\n(torch.Size([5, 1500]), torch.Size([1500, 2]))\n\n\n\nweight[..., None].shape, X[None].shape\n\n(torch.Size([5, 1500, 1]), torch.Size([1, 1500, 2]))\n\n\n\nnum = (weight[..., None]*X[None]).sum(1)\nnum.shape\n\ntorch.Size([5, 2])\n\n\n\nnum\n\ntensor([[367.870, 386.231],\n        [518.332, 588.680],\n        [329.665, 330.782],\n        [527.617, 598.217],\n        [231.302, 234.155]])\n\n\n\ntorch.einsum('ij,jk-&gt;ik', weight, X)\n\ntensor([[367.870, 386.231],\n        [518.332, 588.680],\n        [329.665, 330.782],\n        [527.617, 598.217],\n        [231.302, 234.155]])\n\n\n\nweight@X\n\ntensor([[367.870, 386.231],\n        [518.332, 588.680],\n        [329.665, 330.782],\n        [527.617, 598.217],\n        [231.302, 234.155]])\n\n\n\ndiv = weight.sum(1, keepdim=True)\ndiv.shape\n\ntorch.Size([5, 1])\n\n\n\nnum/div\n\ntensor([[26.376, 27.692],\n        [26.101, 29.643],\n        [28.892, 28.990],\n        [26.071, 29.559],\n        [29.323, 29.685]])\n\n\n\ndef meanshift(data, bs=500):\n    n = len(data)\n    X = data.clone()\n    for it in range(5):\n        for i in range(0, n, bs):\n            s = slice(i, min(i+bs, n))\n            weight = gaussian(dist_b(X, X[s]), 2.5)\n            div = weight.sum(1, keepdim=True)\n            X[s] = weight@X/div\n    return X\n\nAlthough each iteration still has to launch a new cuda kernel, there are now fewer iterations, and the acceleration from updating a batch of points more than makes up for it.\n\ndata = data.cuda()\n\n\nX = meanshift(data).cpu()\n\n\n\n\n2.25 ms ± 36 µs per loop (mean ± std. dev. of 7 runs, 5 loops each)\n\n\n\nplot_data(centroids + 2, X, n_samples)\n\n\n\n\n\n\n\n45 ms ± 654 µs per loop (mean ± std. dev. of 7 runs, 5 loops each)"
  },
  {
    "objectID": "lectures/matmul_notmnist.html",
    "href": "lectures/matmul_notmnist.html",
    "title": "Matrix multiplication from foundations",
    "section": "",
    "text": "The foundations we will assume throughout this course are - Python - matplotlib - The python standard library - Jupyter notebooks and nbdev\n!pip install deeplake\n\nRequirement already satisfied: deeplake in /usr/local/lib/python3.10/dist-packages (3.8.8)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deeplake) (1.23.5)\nRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from deeplake) (9.4.0)\nRequirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from deeplake) (1.28.64)\nRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from deeplake) (8.1.7)\nRequirement already satisfied: pathos in /usr/local/lib/python3.10/dist-packages (from deeplake) (0.3.1)\nRequirement already satisfied: humbug&gt;=0.3.1 in /usr/local/lib/python3.10/dist-packages (from deeplake) (0.3.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deeplake) (4.66.1)\nRequirement already satisfied: lz4 in /usr/local/lib/python3.10/dist-packages (from deeplake) (4.3.2)\nRequirement already satisfied: pyjwt in /usr/lib/python3/dist-packages (from deeplake) (2.3.0)\nRequirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deeplake) (1.10.13)\nRequirement already satisfied: libdeeplake==0.0.90 in /usr/local/lib/python3.10/dist-packages (from deeplake) (0.0.90)\nRequirement already satisfied: aioboto3&gt;=10.4.0 in /usr/local/lib/python3.10/dist-packages (from deeplake) (12.0.0)\nRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from deeplake) (1.5.8)\nRequirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from libdeeplake==0.0.90-&gt;deeplake) (0.3.7)\nRequirement already satisfied: aiobotocore[boto3]==2.7.0 in /usr/local/lib/python3.10/dist-packages (from aioboto3&gt;=10.4.0-&gt;deeplake) (2.7.0)\nRequirement already satisfied: botocore&lt;1.31.65,&gt;=1.31.16 in /usr/local/lib/python3.10/dist-packages (from aiobotocore[boto3]==2.7.0-&gt;aioboto3&gt;=10.4.0-&gt;deeplake) (1.31.64)\nRequirement already satisfied: aiohttp&lt;4.0.0,&gt;=3.7.4.post0 in /usr/local/lib/python3.10/dist-packages (from aiobotocore[boto3]==2.7.0-&gt;aioboto3&gt;=10.4.0-&gt;deeplake) (3.8.6)\nRequirement already satisfied: wrapt&lt;2.0.0,&gt;=1.10.10 in /usr/local/lib/python3.10/dist-packages (from aiobotocore[boto3]==2.7.0-&gt;aioboto3&gt;=10.4.0-&gt;deeplake) (1.14.1)\nRequirement already satisfied: aioitertools&lt;1.0.0,&gt;=0.5.1 in /usr/local/lib/python3.10/dist-packages (from aiobotocore[boto3]==2.7.0-&gt;aioboto3&gt;=10.4.0-&gt;deeplake) (0.11.0)\nRequirement already satisfied: jmespath&lt;2.0.0,&gt;=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3-&gt;deeplake) (1.0.1)\nRequirement already satisfied: s3transfer&lt;0.8.0,&gt;=0.7.0 in /usr/local/lib/python3.10/dist-packages (from boto3-&gt;deeplake) (0.7.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from humbug&gt;=0.3.1-&gt;deeplake) (2.31.0)\nRequirement already satisfied: ppft&gt;=1.7.6.7 in /usr/local/lib/python3.10/dist-packages (from pathos-&gt;deeplake) (1.7.6.7)\nRequirement already satisfied: pox&gt;=0.3.3 in /usr/local/lib/python3.10/dist-packages (from pathos-&gt;deeplake) (0.3.3)\nRequirement already satisfied: multiprocess&gt;=0.70.15 in /usr/local/lib/python3.10/dist-packages (from pathos-&gt;deeplake) (0.70.15)\nRequirement already satisfied: typing-extensions&gt;=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-&gt;deeplake) (4.5.0)\nRequirement already satisfied: python-dateutil&lt;3.0.0,&gt;=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore&lt;1.31.65,&gt;=1.31.16-&gt;aiobotocore[boto3]==2.7.0-&gt;aioboto3&gt;=10.4.0-&gt;deeplake) (2.8.2)\nRequirement already satisfied: urllib3&lt;2.1,&gt;=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore&lt;1.31.65,&gt;=1.31.16-&gt;aiobotocore[boto3]==2.7.0-&gt;aioboto3&gt;=10.4.0-&gt;deeplake) (2.0.7)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;humbug&gt;=0.3.1-&gt;deeplake) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;humbug&gt;=0.3.1-&gt;deeplake) (3.4)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;humbug&gt;=0.3.1-&gt;deeplake) (2023.7.22)\nRequirement already satisfied: attrs&gt;=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp&lt;4.0.0,&gt;=3.7.4.post0-&gt;aiobotocore[boto3]==2.7.0-&gt;aioboto3&gt;=10.4.0-&gt;deeplake) (23.1.0)\nRequirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp&lt;4.0.0,&gt;=3.7.4.post0-&gt;aiobotocore[boto3]==2.7.0-&gt;aioboto3&gt;=10.4.0-&gt;deeplake) (6.0.4)\nRequirement already satisfied: async-timeout&lt;5.0,&gt;=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp&lt;4.0.0,&gt;=3.7.4.post0-&gt;aiobotocore[boto3]==2.7.0-&gt;aioboto3&gt;=10.4.0-&gt;deeplake) (4.0.3)\nRequirement already satisfied: yarl&lt;2.0,&gt;=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp&lt;4.0.0,&gt;=3.7.4.post0-&gt;aiobotocore[boto3]==2.7.0-&gt;aioboto3&gt;=10.4.0-&gt;deeplake) (1.9.2)\nRequirement already satisfied: frozenlist&gt;=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp&lt;4.0.0,&gt;=3.7.4.post0-&gt;aiobotocore[boto3]==2.7.0-&gt;aioboto3&gt;=10.4.0-&gt;deeplake) (1.4.0)\nRequirement already satisfied: aiosignal&gt;=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp&lt;4.0.0,&gt;=3.7.4.post0-&gt;aiobotocore[boto3]==2.7.0-&gt;aioboto3&gt;=10.4.0-&gt;deeplake) (1.3.1)\nRequirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil&lt;3.0.0,&gt;=2.1-&gt;botocore&lt;1.31.65,&gt;=1.31.16-&gt;aiobotocore[boto3]==2.7.0-&gt;aioboto3&gt;=10.4.0-&gt;deeplake) (1.16.0)\nfrom pathlib import Path\nimport pickle, gzip, math, os, time, shutil, matplotlib as mpl, matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport random"
  },
  {
    "objectID": "lectures/matmul_notmnist.html#what-is-not-mnist",
    "href": "lectures/matmul_notmnist.html#what-is-not-mnist",
    "title": "Matrix multiplication from foundations",
    "section": "What is not-MNIST?",
    "text": "What is not-MNIST?\nThe not-MNIST dataset comprises of some freely accessible fonts and symbols extracted to create a dataset similar to MNIST. The dataset is divided into two parts: a relatively small hand-cleaned portion of approximately 19k samples and a larger uncleaned portion of 500k samples. There are ten classes, with letters A-J drawn from various fonts. Here we will use the hand-cleaned portion\n1. A\n\n2. B\n\n3. C\n\n4. D\n\n5. E\n\n6. F\n\n7. G\n\n8. H\n\n9. I\n\n10. J"
  },
  {
    "objectID": "lectures/matmul_notmnist.html#get-data",
    "href": "lectures/matmul_notmnist.html#get-data",
    "title": "Matrix multiplication from foundations",
    "section": "Get data",
    "text": "Get data\n\nimport deeplake\nds = deeplake.load('hub://activeloop/not-mnist-small')\n\n-|- \n\n\nOpening dataset in read-only mode as you don't have write permissions.\nThis dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/not-mnist-small\n\nhub://activeloop/not-mnist-small loaded successfully.\n\n\n\n\nimages = ds.tensors['images'].numpy().astype('float32') / 255.\nlabels = ds.tensors['labels'].numpy().astype(int)\n\n\nimages.shape\n\n(18724, 28, 28)\n\n\n\nlabels.shape\n\n(18724, 1)\n\n\n\nX_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=1)\n\n\nX_train.shape, X_test.shape, y_train.shape, y_test.shape\n\n((14979, 28, 28), (3745, 28, 28), (14979, 1), (3745, 1))\n\n\n\nplt.imshow(X_train[0], cmap='gray')\n\n&lt;matplotlib.image.AxesImage&gt;\n\n\n\n\n\n\ny_train = y_train.squeeze(-1)\ny_test = y_test.squeeze(-1)\n\n\ndef char(y): return 'ABCDEFGHIJ'[y]\n\n\nchar(y_train[0])\n\n'I'\n\n\n\nX_train = X_train.reshape(-1, 784)\nX_test = X_test.reshape(-1, 784)\n\n\nX_train.shape, X_test.shape\n\n((14979, 784), (3745, 784))\n\n\n\nlst1 = list(X_train[0])\nvals = lst1[290: 300]\nvals\n\n[1.0, 0.9843137, 1.0, 1.0, 1.0, 1.0, 0.9843137, 1.0, 0.68235296, 0.0]\n\n\n\ndef chunks(x, sz):\n    for i in range(0, len(x), sz): yield x[i: i + sz]\n\n\nlist(chunks(vals, 5))\n\n[[1.0, 0.9843137, 1.0, 1.0, 1.0], [1.0, 0.9843137, 1.0, 0.68235296, 0.0]]\n\n\n\nval_iter = chunks(vals, 5)\n\n\nnext(val_iter)\n\n[1.0, 0.9843137, 1.0, 1.0, 1.0]\n\n\n\nnext(val_iter)\n\n[1.0, 0.9843137, 1.0, 0.68235296, 0.0]\n\n\n\nnext(val_iter)\n\nStopIteration: ignored\n\n\n\nplt.imshow(list(chunks(lst1, 28)), cmap='gray')\n\n&lt;matplotlib.image.AxesImage&gt;\n\n\n\n\n\n\nfrom itertools import islice\n\n\nit = iter(vals)\nislice(it, 5)\n\n&lt;itertools.islice&gt;\n\n\n\nlist(islice(it, 5))\n\n[1.0, 0.9843137, 1.0, 1.0, 1.0]\n\n\n\nfor i in islice(it, 5):\n    print(i)\n\n1.0\n0.9843137\n1.0\n0.68235296\n0.0\n\n\n\nit = iter(lst1)\nimg = list(iter(lambda : list(islice(it, 28)), []))\n\n\nplt.imshow(img)\n\n&lt;matplotlib.image.AxesImage&gt;"
  },
  {
    "objectID": "lectures/matmul_notmnist.html#matrix-and-tensor",
    "href": "lectures/matmul_notmnist.html#matrix-and-tensor",
    "title": "Matrix multiplication from foundations",
    "section": "Matrix and Tensor",
    "text": "Matrix and Tensor\n\nimg[20][15]\n\n1.0\n\n\n\nclass Matrix:\n    def __init__(self, xs): self.xs = xs\n    def __getitem__(self, idxs): return self.xs[idxs[0]][idxs[1]]\n\n\nm = Matrix(img)\nm[20, 15]\n\n1.0\n\n\n\nimport torch\nfrom torch import tensor\n\n\ntensor([1, 2, 3])\n\ntensor([1, 2, 3])\n\n\n\ntens = tensor(img); tens[20, 15]\n\ntensor(1.)\n\n\n\nX_train, y_train, X_test, y_test = map(tensor, (X_train, y_train, X_test, y_test))\n\n\nX_train.type()\n\n'torch.FloatTensor'\n\n\n\nX_train.shape\n\ntorch.Size([14979, 784])\n\n\n\nimgs = X_train.reshape((-1, 28, 28))\nimgs.shape\n\ntorch.Size([14979, 28, 28])\n\n\n\nplt.imshow(imgs[0])\n\n&lt;matplotlib.image.AxesImage&gt;"
  },
  {
    "objectID": "lectures/matmul_notmnist.html#random-numbers",
    "href": "lectures/matmul_notmnist.html#random-numbers",
    "title": "Matrix multiplication from foundations",
    "section": "Random numbers",
    "text": "Random numbers\n\nrnd_state = None\ndef seed(a):\n    global rnd_state\n    a, x = divmod(a, 30268)\n    a, y = divmod(a, 30306)\n    a, z = divmod(a, 30322)\n\n    rnd_state = int(x) + 1, int(y) + 1, int(z) + 1\n\n\nseed(457428938475)\n\n\nrnd_state\n\n(4976, 20238, 499)\n\n\n\ndef rand():\n    global rnd_state\n    x, y, z = rnd_state\n    x = (171 * x) % 30269\n    y = (172 * y) % 30307\n    z = (170 * z) % 30323\n    rnd_state = x, y, z\n    return (x / 30269 + y / 30307 + z / 30323) % 1.0\n\n\nrand(), rand(), rand()\n\n(0.7645251082582081, 0.7920889799553945, 0.06912886811267205)\n\n\n\nif os.fork(): print(f'In parent: {rand()}')\nelse:\n    print(f'In child: {rand()}')\n    os._exit(os.EX_OK)\n\nIn parent: 0.9559050644103264\nIn child: 0.9559050644103264\n\n\n\nif os.fork(): print(f'In parent: {torch.rand(1)}')\nelse:\n    print(f'In child: {torch.rand(1)}')\n    os._exit(os.EX_OK)\n\nIn parent: tensor([0.7129])\nIn child: tensor([0.7129])\n\n\n\nif os.fork(): print(f'In parent: {random.random()}')\nelse:\n    print(f'In child: {random.random()}')\n    os._exit(os.EX_OK)\n\nIn parent: 0.7579544029403025\nIn child: 0.1583037383506456\n\n\n\nplt.plot([rand() for _ in range(50)]);\n\n\n\n\n\nplt.hist([rand() for _ in range(100_000)])\n\n(array([10045.,  9990.,  9701., 10008.,  9934.,  9935., 10182., 10210.,\n         9924., 10071.]),\n array([3.03151161e-06, 1.00002109e-01, 2.00001186e-01, 3.00000263e-01,\n        3.99999341e-01, 4.99998418e-01, 5.99997495e-01, 6.99996572e-01,\n        7.99995650e-01, 8.99994727e-01, 9.99993804e-01]),\n &lt;BarContainer object of 10 artists&gt;)\n\n\n\n\n\n\n\n\n8.74 ms ± 319 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\n\n\n\n143 µs ± 60 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)"
  },
  {
    "objectID": "lectures/matmul_notmnist.html#matrix-multiplication",
    "href": "lectures/matmul_notmnist.html#matrix-multiplication",
    "title": "Matrix multiplication from foundations",
    "section": "Matrix Multiplication",
    "text": "Matrix Multiplication\n\ntorch.manual_seed(1)\nweights = torch.randn(784, 10)\nbias = torch.zeros(10)\n\n\nm1 = X_test[:5]\nm2 = weights\n\n\nm1.shape, m2.shape\n\n(torch.Size([5, 784]), torch.Size([784, 10]))\n\n\n\nar, ac = m1.shape\nbr, bc = m2.shape\n(ar, ac), (br, bc)\n\n((5, 784), (784, 10))\n\n\n\nt1 = torch.zeros(ar, bc)\nt1.shape\n\ntorch.Size([5, 10])\n\n\n\nfor i in range(ar):\n    for j in range(bc):\n        for k in range(ac):\n            t1[i, j] += m1[i, k] * m2[k, j]\n\n\nt1\n\ntensor([[  8.2509, -32.2384, -31.2659,  29.6144,  37.1024, -10.6518, -18.7646,\n          -9.3841,  13.5039,   3.1983],\n        [ 15.3977, -19.5008,  -5.6448,  30.4349,  59.5697,   6.9771, -25.8890,\n         -40.2893, -17.3914,  43.8492],\n        [  7.8317,  -4.5760,   5.5933, -13.6489,  28.6691, -11.6068, -25.0293,\n         -16.1800,   7.5447,  -6.0635],\n        [  5.7755,  -7.0180,   5.6232, -14.6877,  40.6079,   4.7634, -18.4372,\n         -18.1103,  -4.8335,  26.0490],\n        [-10.4290, -20.8873, -15.5178,  11.3828,  39.0230, -28.5750, -34.5579,\n          -0.3404,   8.5624,  -8.3245]])\n\n\n\ntorch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n\n\nt1\n\ntensor([[  8.25, -32.24, -31.27,  29.61,  37.10, -10.65, -18.76,  -9.38,  13.50,   3.20],\n        [ 15.40, -19.50,  -5.64,  30.43,  59.57,   6.98, -25.89, -40.29, -17.39,  43.85],\n        [  7.83,  -4.58,   5.59, -13.65,  28.67, -11.61, -25.03, -16.18,   7.54,  -6.06],\n        [  5.78,  -7.02,   5.62, -14.69,  40.61,   4.76, -18.44, -18.11,  -4.83,  26.05],\n        [-10.43, -20.89, -15.52,  11.38,  39.02, -28.58, -34.56,  -0.34,   8.56,  -8.32]])\n\n\n\nimport numpy as np\nnp.set_printoptions(precision=2, linewidth=140)\n\n\ndef matmul(a, b):\n    (ar, ac), (br, bc) = a.shape, b.shape\n    c = torch.zeros(ar, bc)\n    for i in range(ar):\n        for j in range(bc):\n            for k in range(ac):\n                c[i, j] += a[i, k] * b[k, j]\n    return c\n\n\nar*bc*ac\n\n39200"
  },
  {
    "objectID": "lectures/matmul_notmnist.html#numba",
    "href": "lectures/matmul_notmnist.html#numba",
    "title": "Matrix multiplication from foundations",
    "section": "Numba",
    "text": "Numba\n\nfrom numba import njit\n\n\n@njit\ndef dot(a, b):\n    res = 0\n    for i in range(len(a)):\n        res += a[i] * b[i]\n    return res\n\n\nfrom numpy import array\n\n\n\n\nCPU times: user 248 ms, sys: 21.4 ms, total: 270 ms\nWall time: 416 ms\n\n\n20.0\n\n\n\n\n\nCPU times: user 27 µs, sys: 0 ns, total: 27 µs\nWall time: 30 µs\n\n\n20.0\n\n\nNow only two of our loops are running in python, not three:\n\ndef matmul(a, b):\n    (ar, ac), (br, bc) = a.shape, b.shape\n    c = torch.zeros(ar, bc)\n    for i in range(ar):\n        for j in range(bc):\n            c[i, j] += dot(a[i, :], b[:, j])\n    return c\n\n\nm1a, m2a = m1.numpy(), m2.numpy()\n\n\nfrom fastcore.test import *\n\n\ntest_close(t1, matmul(m1a, m2a), eps=1e-4)"
  },
  {
    "objectID": "lectures/matmul_notmnist.html#elementwise-ops",
    "href": "lectures/matmul_notmnist.html#elementwise-ops",
    "title": "Matrix multiplication from foundations",
    "section": "Elementwise Ops",
    "text": "Elementwise Ops\n\na = tensor([10., 6, -4])\nb = tensor([2., 8, 7])\na, b\n\n(tensor([10.,  6., -4.]), tensor([2., 8., 7.]))\n\n\n\na + b\n\ntensor([12., 14.,  3.])\n\n\n\n(a &lt; b).float().mean()\n\ntensor(0.67)\n\n\n\nm = tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]]); m\n\ntensor([[1, 2, 3],\n        [4, 5, 6],\n        [7, 8, 9]])\n\n\nFrobenius Norm\n\nsf = (m*m).sum()\nsf\n\ntensor(285)\n\n\n\nsf.sqrt()\n\ntensor(16.88)\n\n\n\nm[2, :], m[:, 2]\n\n(tensor([7, 8, 9]), tensor([3, 6, 9]))\n\n\n\nm[2]\n\ntensor([7, 8, 9])\n\n\n\ndef matmul(a, b):\n    (ar, ac), (br, bc) = a.shape, b.shape\n    c = torch.zeros(ar, bc)\n    for i in range(ar):\n        for j in range(bc):\n            c[i, j] = (a[i, :] * b[:, j]).sum()\n    return c\n\n\ntest_close(t1, matmul(m1, m2), eps=1e-4)\n\n\n\n\n1.33 ms ± 108 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n\n\n\ndef matmul(a, b):\n    (ar, ac), (br, bc) = a.shape, b.shape\n    c = torch.zeros(ar, bc)\n    for i in range(ar):\n        for j in range(bc):\n            c[i, j] = torch.dot(a[i, :], b[:, j])\n    return c\n\n\ntest_close(t1, matmul(m1, m2), eps=1e-4)\n\n\n\n\n906 µs ± 57.7 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)"
  },
  {
    "objectID": "lectures/matmul_notmnist.html#broadcasting",
    "href": "lectures/matmul_notmnist.html#broadcasting",
    "title": "Matrix multiplication from foundations",
    "section": "Broadcasting",
    "text": "Broadcasting\n\na\n\ntensor([10.,  6., -4.])\n\n\n\na &gt; 0\n\ntensor([ True,  True, False])\n\n\n\na + 1\n\ntensor([11.,  7., -3.])\n\n\n\nm\n\ntensor([[1, 2, 3],\n        [4, 5, 6],\n        [7, 8, 9]])\n\n\n\n2 * m\n\ntensor([[ 2,  4,  6],\n        [ 8, 10, 12],\n        [14, 16, 18]])\n\n\n\nBroadcasting a vector to matrix\n\nc = tensor([10, 20, 30]); c\n\ntensor([10, 20, 30])\n\n\n\nm\n\ntensor([[1, 2, 3],\n        [4, 5, 6],\n        [7, 8, 9]])\n\n\n\nm.shape, c.shape\n\n(torch.Size([3, 3]), torch.Size([3]))\n\n\n\nm + c\n\ntensor([[11, 22, 33],\n        [14, 25, 36],\n        [17, 28, 39]])\n\n\n\nc + m\n\ntensor([[11, 22, 33],\n        [14, 25, 36],\n        [17, 28, 39]])\n\n\n\nt = c.expand_as(m); t\n\ntensor([[10, 20, 30],\n        [10, 20, 30],\n        [10, 20, 30]])\n\n\n\nt.storage()\n\nUserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  t.storage()\n\n\n 10\n 20\n 30\n[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 3]\n\n\n\nt.stride(), t.shape\n\n((0, 1), torch.Size([3, 3]))\n\n\n\nc.unsqueeze(0), c[None, :]\n\n(tensor([[10, 20, 30]]), tensor([[10, 20, 30]]))\n\n\n\nc.shape, c.unsqueeze(0).shape\n\n(torch.Size([3]), torch.Size([1, 3]))\n\n\n\nc.shape, c.unsqueeze(1).shape\n\n(torch.Size([3]), torch.Size([3, 1]))\n\n\n\nc[None].shape, c[..., None].shape\n\n(torch.Size([1, 3]), torch.Size([3, 1]))\n\n\n\nc[:, None].expand_as(m)\n\ntensor([[10, 10, 10],\n        [20, 20, 20],\n        [30, 30, 30]])\n\n\n\nm + c[:, None]\n\ntensor([[11, 12, 13],\n        [24, 25, 26],\n        [37, 38, 39]])\n\n\n\nm + c[None, :]\n\ntensor([[11, 22, 33],\n        [14, 25, 36],\n        [17, 28, 39]])\n\n\n\n\nBroadcasting rules\n\nc[None, :]\n\ntensor([[10, 20, 30]])\n\n\n\nc[None, :].shape\n\ntorch.Size([1, 3])\n\n\n\nc[:, None]\n\ntensor([[10],\n        [20],\n        [30]])\n\n\n\nc[:, None].shape\n\ntorch.Size([3, 1])\n\n\n\nc[:, None] * c[None, :]\n\ntensor([[100, 200, 300],\n        [200, 400, 600],\n        [300, 600, 900]])\n\n\n\nc[None] &gt; c[:, None]\n\ntensor([[False,  True,  True],\n        [False, False,  True],\n        [False, False, False]])\n\n\n\n\nMatmul with broadcasting\n\ndigit = m1[0]\n\n\ndigit.shape, m2.shape\n\n(torch.Size([784]), torch.Size([784, 10]))\n\n\n\ndigit[:, None].shape\n\ntorch.Size([784, 1])\n\n\n\ndigit[:, None].expand_as(m2).shape\n\ntorch.Size([784, 10])\n\n\n\n(digit[:, None] * m2).shape\n\ntorch.Size([784, 10])\n\n\n\ndef matmul(a, b):\n    (ar, ac), (br, bc) = a.shape, b.shape\n    c = torch.zeros(ar, bc)\n    for i in range(ar):\n        c[i] = (a[i,:, None] * b).sum(dim=0)\n    return c\n\n\ntest_close(t1, matmul(m1, m2), eps=1e-4)\n\n\n\n\n276 µs ± 30.4 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n\n\n\ntr = matmul(X_train, weights)\ntr\n\ntensor([[ 16.25, -15.36, -25.81,  ..., -21.11, -26.31,  17.92],\n        [  5.01,   0.29, -23.21,  ..., -14.26,  23.98,  24.13],\n        [  5.70,  -3.06,  -9.48,  ...,  -9.08,  11.74,   0.88],\n        ...,\n        [-12.85,  -6.30,  -4.18,  ..., -22.07,  16.46,  -0.86],\n        [ 13.19, -21.23, -10.63,  ...,  -9.95,  19.52,   3.76],\n        [ -1.56,  -5.29,  -8.10,  ...,  -2.18,  -0.69,   1.49]])\n\n\n\ntr.shape\n\ntorch.Size([14979, 10])\n\n\n\n\n\nCPU times: user 430 ms, sys: 3.76 ms, total: 434 ms\nWall time: 436 ms"
  },
  {
    "objectID": "lectures/matmul_notmnist.html#einstein-summation",
    "href": "lectures/matmul_notmnist.html#einstein-summation",
    "title": "Matrix multiplication from foundations",
    "section": "Einstein Summation",
    "text": "Einstein Summation\nEinstein Summation is a compact representation for combining products and sums in a general way. The key rules are: - Repeating letters between input arrays means that values along those axes will be multiplied together. - Omitting a letter from the output means that values along that axis will be summed\n\nm1.shape, m2.shape\n\n(torch.Size([5, 784]), torch.Size([784, 10]))\n\n\n\nmr = torch.einsum('ik,kj-&gt;ikj', m1, m2)\nmr.shape\n\ntorch.Size([5, 784, 10])\n\n\n\nmr.sum(1)\n\ntensor([[  8.25, -32.24, -31.27,  29.61,  37.10, -10.65, -18.76,  -9.38,  13.50,   3.20],\n        [ 15.40, -19.50,  -5.64,  30.43,  59.57,   6.98, -25.89, -40.29, -17.39,  43.85],\n        [  7.83,  -4.58,   5.59, -13.65,  28.67, -11.61, -25.03, -16.18,   7.54,  -6.06],\n        [  5.78,  -7.02,   5.62, -14.69,  40.61,   4.76, -18.44, -18.11,  -4.83,  26.05],\n        [-10.43, -20.89, -15.52,  11.38,  39.02, -28.58, -34.56,  -0.34,   8.56,  -8.32]])\n\n\n\ntorch.einsum('ik,kj-&gt;ij', m1,m2)\n\ntensor([[  8.25, -32.24, -31.27,  29.61,  37.10, -10.65, -18.76,  -9.38,  13.50,   3.20],\n        [ 15.40, -19.50,  -5.64,  30.43,  59.57,   6.98, -25.89, -40.29, -17.39,  43.85],\n        [  7.83,  -4.58,   5.59, -13.65,  28.67, -11.61, -25.03, -16.18,   7.54,  -6.06],\n        [  5.78,  -7.02,   5.62, -14.69,  40.61,   4.76, -18.44, -18.11,  -4.83,  26.05],\n        [-10.43, -20.89, -15.52,  11.38,  39.02, -28.58, -34.56,  -0.34,   8.56,  -8.32]])\n\n\n\ndef matmul(a, b): return torch.einsum('ik,kj-&gt;ij', a, b)\n\n\ntest_close(tr, matmul(X_train, weights), eps=1e-4)\n\n\n\n\n7.54 ms ± 489 µs per loop (mean ± std. dev. of 7 runs, 5 loops each)\n\n\n\npytorch op\nWe can use pytorch’s function or operator directly for matrix multiplication\n\ntest_close(tr, X_train@weights, eps=1e-3)\n\n\n\n\n7.24 ms ± 502 µs per loop (mean ± std. dev. of 7 runs, 5 loops each)\n\n\n\n\n\n7.53 ms ± 501 µs per loop (mean ± std. dev. of 7 runs, 5 loops each)"
  },
  {
    "objectID": "lectures/matmul_notmnist.html#cuda",
    "href": "lectures/matmul_notmnist.html#cuda",
    "title": "Matrix multiplication from foundations",
    "section": "CUDA",
    "text": "CUDA\n\ndef matmul(grid, a, b, c):\n    i, j = grid\n    if i &lt; c.shape[0] and j &lt; c.shape[1]:\n        tmp = 0.\n        for k in range(a.shape[1]): tmp += a[i, k] * b[k, j]\n        c[i, j] = tmp\n\n\nres = torch.zeros(ar, bc)\nmatmul((0, 0), m1, m2, res)\nres\n\ntensor([[8.25, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n        [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n        [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n        [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n        [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]])\n\n\n\ndef launch_kernel(kernel, grid_x, grid_y, *args, **kwargs):\n    for i in range(grid_x):\n        for j in range(grid_y): kernel((i, j), *args, **kwargs)\n\n\nres = torch.zeros(ar, bc)\nlaunch_kernel(matmul, ar, bc, m1, m2, res)\nres\n\ntensor([[  8.25, -32.24, -31.27,  29.61,  37.10, -10.65, -18.76,  -9.38,  13.50,   3.20],\n        [ 15.40, -19.50,  -5.64,  30.43,  59.57,   6.98, -25.89, -40.29, -17.39,  43.85],\n        [  7.83,  -4.58,   5.59, -13.65,  28.67, -11.61, -25.03, -16.18,   7.54,  -6.06],\n        [  5.78,  -7.02,   5.62, -14.69,  40.61,   4.76, -18.44, -18.11,  -4.83,  26.05],\n        [-10.43, -20.89, -15.52,  11.38,  39.02, -28.58, -34.56,  -0.34,   8.56,  -8.32]])\n\n\n\nfrom numba import cuda\n\n\n@cuda.jit\ndef matmul(a, b, c):\n    i, j = cuda.grid(2)\n    if i &lt; c.shape[0] and j &lt; c.shape[1]:\n        tmp = 0.\n        for k in range(a.shape[1]): tmp += a[i, k] * b[k, j]\n        c[i, j] = tmp\n\n\nr = np.zeros(tr.shape)\nm1g,m2g,rg = cuda.to_device(X_train), cuda.to_device(weights), cuda.to_device(r)\n\n\ncuda.is_available()\n\nTrue\n\n\n\nm1g,m2g,rg = map(cuda.to_device, (X_train, weights, r))\n\n\nr.shape\n\n(14979, 10)\n\n\n\nr\n\narray([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])\n\n\n\nTPB = 16\nrr, rc = r.shape\nblockspergrid = (math.ceil(rr / TPB), math.ceil(rc / TPB))\nblockspergrid\n\n(937, 1)\n\n\n\nmatmul[blockspergrid, (TPB, TPB)](m1g, m2g, rg)\nr =rg.copy_to_host()\ntest_close(tr, r, eps=1.03)\n\n\nmatmul[blockspergrid, (TPB, TPB)](m1g, m2g, rg)\nr = rg.copy_to_host()\n\n4.98 ms ± 1.06 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\n\nm1c, m2c = X_train.cuda(), weights.cuda()\n\n\nr = (m1c @ m2c).cpu()\n\n\n\n\n673 µs ± 65.5 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)"
  },
  {
    "objectID": "practice/meanshift_practice.html",
    "href": "practice/meanshift_practice.html",
    "title": "Meanshift Practice",
    "section": "",
    "text": "import numpy as np\nimport math\nfrom math import pi\nimport torch\nfrom matplotlib import pyplot as plt\nfrom torch.distributions import MultivariateNormal\ntorch.manual_seed(256)\ntorch.set_printoptions(precision=5, linewidth=140)\nn_clusters = 6\nn_samples= 250\ncentroids = torch.randn(n_clusters, 2) * 70 - 35\ndef sample(c): return MultivariateNormal(c, torch.diag(torch.tensor([5., 5.]))).sample((n_samples,))\ndata = torch.concat([sample(c) for c in centroids], axis=0)\ndata.shape\n\ntorch.Size([1500, 2])\ndef plot_data(centroids, data, ax=None):\n    if ax is None: fig, ax = plt.subplots()\n    for i, centroid in enumerate(centroids):\n        samples = data[i*n_samples:(i+1)*n_samples]\n        ax.scatter(samples[:, 0], samples[:, 1], s = 1)\n        ax.plot(*centroid, markersize=10, marker=\"x\", color=\"k\", mew=5)\n        ax.plot(*centroid, markersize=5, marker=\"x\", color=\"m\", mew=3)\nplot_data(centroids, data)\ndef gaussian(dist, bw=2.5): return (1/(math.sqrt(2*pi)*bw))*torch.exp(-0.5*(dist/bw)**2)\nfig, ax = plt.subplots()\nx = torch.linspace(-10, 10, 100)\nax.plot(x, gaussian(x))\ndef tri(dist, bw=10): return (-dist + bw).clamp(min=0)\nfig, ax = plt.subplots()\nx = torch.linspace(-50, 50, 100)\nax.plot(x, tri(x))\nX = data.clone()\nx = X[0]\ngaussian(((x - X)**2).sum(1).sqrt())\n\ntensor([0.15958, 0.07880, 0.06436,  ..., 0.00000, 0.00000, 0.00000])\ndef one_update(X, weight_func=gaussian):\n    for i, x in enumerate(X):\n        dist = ((x - X)**2).sum(1).sqrt()\n        weight = weight_func(dist, bw=2.5)\n        X[i] = (weight[..., None] * X).sum(0)/weight.sum(0)\ndef meanshift(data, weight_func=gaussian):\n    X = data.clone()\n    for i in range(5): one_update(X, weight_func)\n    return X\n645 ms ± 520 µs per loop (mean ± std. dev. of 7 runs, 5 loops each)\nY = meanshift(data)\nY\n\ntensor([[ -28.42868, -102.61228],\n        [ -28.42868, -102.61228],\n        [ -28.42867, -102.61228],\n        ...,\n        [ -26.45944,  106.64550],\n        [ -26.45944,  106.64550],\n        [ -26.45944,  106.64550]])\nplot_data(centroids+5, Y)\nfrom matplotlib.animation import FuncAnimation\nfrom IPython.display import HTML\ndef animate(d):\n    if not d: return plot_data(centroids + 5, X, ax=ax)\n    one_update(X)\n    ax.clear()\n    plot_data(centroids + 5, X, ax=ax)\nX= data.clone()\nfig, ax = plt.subplots()\nf = FuncAnimation(fig, animate, frames=5, interval=500, repeat=False)\nplt.close()\nHTML(f.to_jshtml())\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "practice/meanshift_practice.html#gpu-batched-algorithm",
    "href": "practice/meanshift_practice.html#gpu-batched-algorithm",
    "title": "Meanshift Practice",
    "section": "GPU Batched algorithm",
    "text": "GPU Batched algorithm\n\nbs = 5\nX = data.clone()\nx = X[:bs]\nx.shape, X.shape\n\n(torch.Size([5, 2]), torch.Size([1500, 2]))\n\n\n\ndist = ((x[:,None] - X[None]) ** 2).sum(-1).sqrt()\ndist.shape, dist\n\n(torch.Size([5, 1500]),\n tensor([[  0.00000,   2.96982,   3.36906,  ..., 209.04686, 210.20853, 209.90276],\n         [  2.96982,   0.00000,   4.58362,  ..., 208.38335, 209.50293, 209.21017],\n         [  3.36906,   4.58362,   0.00000,  ..., 212.35605, 213.50829, 213.20551],\n         [  3.42341,   1.80829,   3.42423,  ..., 210.16139, 211.27600, 210.98482],\n         [  2.33995,   1.62542,   2.96569,  ..., 209.84781, 210.97752, 210.68167]]))\n\n\n\nweight = gaussian(dist)\nweight\n\ntensor([[0.15958, 0.07880, 0.06436,  ..., 0.00000, 0.00000, 0.00000],\n        [0.07880, 0.15958, 0.02972,  ..., 0.00000, 0.00000, 0.00000],\n        [0.06436, 0.02972, 0.15958,  ..., 0.00000, 0.00000, 0.00000],\n        [0.06249, 0.12285, 0.06246,  ..., 0.00000, 0.00000, 0.00000],\n        [0.10298, 0.12917, 0.07896,  ..., 0.00000, 0.00000, 0.00000]])\n\n\n\nweight.shape\n\ntorch.Size([5, 1500])\n\n\n\n(weight @ X).shape\n\ntorch.Size([5, 2])\n\n\n\nweight.sum(1, keepdims=True).shape\n\ntorch.Size([5, 1])\n\n\n\nfor i in range(0, 10, 2):\n    print(i)\n\n0\n2\n4\n6\n8\n\n\n\ndef one_update(X, bs):\n    n = len(X)\n    for i in range(0, n, bs):\n        s = slice(i, min(i+bs, n))\n        x = X[s]\n        dist = ((x[:,None] - X[None]) ** 2).sum(-1).sqrt()\n        weight = gaussian(dist)\n        X[s] = (weight @ X)/ (weight.sum(1, keepdims=True))\n\n\ndef meanshift(data, bs=16):\n    X = data.clone()\n    for i in range(10): one_update(X, bs)\n    return X\n\n\ndata = data.cuda()\n\n48.2 ms ± 422 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\n\n\n\n4.36 ms ± 4.38 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\n\nX\n\ntensor([[ -30.65150, -102.48758],\n        [ -27.74988, -101.85477],\n        [ -30.07228, -105.80648],\n        ...,\n        [ -26.98898,  106.52718],\n        [ -23.92055,  107.61317],\n        [ -24.87365,  107.33564]])\n\n\n\nplot_data(centroids +5, X)"
  },
  {
    "objectID": "hw/locality_sensitive_hashing_lsh.html",
    "href": "hw/locality_sensitive_hashing_lsh.html",
    "title": "Locality Sensitive Hashing (LSH)",
    "section": "",
    "text": "Local sensitive hashing (LSH) is a technique used in approximate nearest neighbor search and similarity-based retrieval tasks. LSH helps in efficiently finding similar items or reducing the search space for similarity queries.\nLSH works by hashing similar items into the same or nearby hash buckets with a high probability. It operates on the principle that if two items are similar, they are likely to collide (hash to the same bucket) under a certain hash function.\nLSH is “local sensitive” because it ensures that nearby items have a higher probability of being hashed into the same bucket, while items that are far apart have a lower probability of colliding. This property allows for efficient pruning of the search space, as we can focus the search on the items within the same hash buckets.\nThere are different types of LSH algorithms designed for various data types and similarity measures. Some common examples include MinHash for document similarity, SimHash for binary data, and L2-LSH for Euclidean distance-based similarity.\nLSH is particularly useful in scenarios where traditional exact search methods become impractical due to high-dimensional data or large dataset sizes. It allows for approximate similarity search with reduced computational complexity, making it a valuable tool in various applications like recommendation systems, image retrieval, and DNA sequence matching.\n\n#!pip install fastcore\n#!pip install nbdev\n\nI defined the class FastLSH below which takes the following arguments - dimensions: This is the number of features in the dataset. The higher the number of dimensions, the more complex the LSH algorithm will be. - hash_length: This is the length of the hash value. The longer the hash value, the more accurate the LSH algorithm will be. However, a longer hash value will also take longer to compute. - number_hash_tables: This is the number of hash tables that are used by the LSH algorithm. The more hash tables, the more likely it is that two similar items will be hashed to the same table. However, a larger number of hash tables will also take longer to search. - hash_table: This is a data structure that stores the hash values of the items in the dataset. The hash table is used to quickly find items that have similar hash values.\n\nsource\n\nFastLSH\n\n FastLSH (dim, nht, hl)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nfastlsh = FastLSH(dim=2, nht=5, hl=10)\n\n\nfastlsh.hash_table.shape\n\ntorch.Size([5, 10, 2])\n\n\n\ndata = torch.randn(150_000, 2) # data\nquery = data[0][None] # query, adding a unit axis at the start\ndata.shape, query.shape\n\n(torch.Size([150000, 2]), torch.Size([1, 2]))\n\n\nThe purpose of the following hashing code is to apply hash functions to each data point in the input tensor. It performs a cosine similarity between the query and the hashtable, generating hash codes for every data point in the query. The resulting tensor contains these hash codes.\nThe patch decorator patches the function to the LSH class. More about patch here\n\nsource\n\n\nFastLSH.hashing\n\n FastLSH.hashing (query)\n\nLet’s utilize the hashing function mentioned above to hash both the query and data points.\n\ndata_hash = fastlsh.hashing(data)\ndata_hash.shape\n\ntorch.Size([150000, 5, 10])\n\n\nBased on the obtained data_hash.shape from the above, we can observe that each of the 150_000 data points has been hashed using 5 hash functions, resulting in hash codes of length 10 for each data point.\n\nquery_hash = fastlsh.hashing(query)\nquery_hash.shape\n\ntorch.Size([1, 5, 10])\n\n\nNow, let’s proceed to obtain the indexes of data where the hash code of each data point matches the hash code of the query point.\nTo determine if the hash codes are the same, we can begin by calculating the dot product along the last axis and dividing it by the sum of the corresponding axis in the data. If the resulting values are equal to 1, it indicates that the hash codes are the same. Otherwise, if the values differ from 1, it implies that the hash codes are not the same.\n\n(query_hash * data_hash).sum(-1)\n\ntensor([[4, 5, 2, 6, 5],\n        [1, 3, 2, 2, 3],\n        [4, 3, 0, 4, 3],\n        ...,\n        [2, 3, 2, 5, 4],\n        [1, 3, 2, 3, 3],\n        [0, 1, 2, 2, 1]])\n\n\n\ndata_hash.sum(-1)\n\ntensor([[ 4,  5,  2,  6,  5],\n        [ 4,  8,  9,  6,  6],\n        [ 6,  3,  0,  4,  5],\n        ...,\n        [ 5,  6,  4,  8,  4],\n        [ 4,  7,  7,  7,  6],\n        [ 4,  6, 10,  6,  4]])\n\n\n\n(query_hash * data_hash).shape\n\ntorch.Size([150000, 5, 10])\n\n\n\n(query_hash * data_hash).sum(-1) / data_hash.sum(-1)\n\ntensor([[1.000, 1.000, 1.000, 1.000, 1.000],\n        [0.250, 0.375, 0.222, 0.333, 0.500],\n        [0.667, 1.000,   nan, 1.000, 0.600],\n        ...,\n        [0.400, 0.500, 0.500, 0.625, 1.000],\n        [0.250, 0.429, 0.286, 0.429, 0.500],\n        [0.000, 0.167, 0.200, 0.333, 0.250]])\n\n\n\nresult = ( (query_hash * data_hash).sum(-1) / data_hash.sum(-1) ) == 1\nresult\n\ntensor([[ True,  True,  True,  True,  True],\n        [False, False, False, False, False],\n        [False,  True, False,  True, False],\n        ...,\n        [False, False, False, False,  True],\n        [False, False, False, False, False],\n        [False, False, False, False, False]])\n\n\nWe can obtain the indices where the values are True using the following code.\n\nresult_indices = torch.nonzero(torch.any(result, dim=1)).flatten()\nresult_indices.shape\n\ntorch.Size([50337])\n\n\n\ndata[result_indices].shape\n\ntorch.Size([50337, 2])\n\n\nNow that we have obtained the indices, let’s proceed to compute the Euclidean distance (L2 norm).\nTo compute the Euclidean distance, we don’t need to calculate the distance from every one of the 150_000 points. Instead, we only need to compute the distance from the points where the hash codes are the same, as we have already determined from the indices obtained.\n\n((query - data[result_indices])**2).sum(-1).sqrt().shape\n\ntorch.Size([50337])\n\n\nWe can consolidate all of the aforementioned operations into a single function by defining the following function\n\nsource\n\n\nFastLSH.query_neigbours\n\n FastLSH.query_neigbours (query, data, data_hash, neighbours=10)\n\n\nquery = data[0][None]; query.shape\n\ntorch.Size([1, 2])\n\n\n\ndata_hash = fastlsh.hashing(data)\nfastlsh.query_neigbours(query, data, data_hash, 10)\n\n(tensor([0.000, 0.004, 0.004, 0.005, 0.007, 0.007, 0.009, 0.009, 0.009, 0.010]),\n tensor([     0,  16866,  13708,  29511,  37183,  31814,   9378, 122251, 131806,   4483]))\n\n\n\n\n\n11.9 ms ± 643 µs per loop (mean ± std. dev. of 7 runs, 5 loops each)\n\n\n\n\nGPU\nI’m currently unable to determine how to pass batches of query points for computing the hash and obtaining the distances. As a temporary solution, I’m passing a single query point and the data as CUDA. Let’s see if this optimization yields better results compared to the CPU version mentioned above.\n\ndata_cuda = data.cuda()\nquery_cuda = query.cuda()\nfastlsh.hash_table = fastlsh.hash_table.cuda()\n\n\ndata_hash_cuda = fastlsh.hashing(data_cuda)\n\n\nfastlsh.query_neigbours(query_cuda, data_cuda, data_hash_cuda, 10)\n\n(tensor([0.000, 0.004, 0.004, 0.005, 0.007, 0.007, 0.009, 0.009, 0.009, 0.010], device='cuda:0'),\n tensor([     0,  16866,  13708,  29511,  37183,  31814,   9378, 122251, 131806,   4483], device='cuda:0'))\n\n\n\n\n\n739 µs ± 30.9 µs per loop (mean ± std. dev. of 7 runs, 5 loops each)\n\n\nThe GPU computation is 15x faster"
  },
  {
    "objectID": "practice/matmul_fashion_mnist_practice.html",
    "href": "practice/matmul_fashion_mnist_practice.html",
    "title": "Matrix Multiplication from foundations",
    "section": "",
    "text": "import pickle, gzip, os\nfrom pathlib import Path\nimport json, torch\nfrom itertools import islice\nfrom torch import tensor\nimport random\nfrom matplotlib import pyplot as plt\nfrom fastcore.test import test_close\nfrom numba import njit\nimport numpy as np\nimport math\n\n\nif 'google.colab' in str(get_ipython()):\n  path = Path('fashion_mnist/')\nelse:\n  path = Path('../../data/fashion_mnist/')\n\n\nos.listdir(path)\n\n['t10k-images-idx3-ubyte.gz',\n 'train-labels-idx1-ubyte.gz',\n 'train-images-idx3-ubyte.gz',\n 't10k-labels-idx1-ubyte.gz']\n\n\n\n# taken from https://github.com/zalandoresearch/fashion-mnist/blob/master/utils/mnist_reader.py\ndef load_mnist(path, kind='train'):\n    import os\n    import gzip\n    import numpy as np\n\n    \"\"\"Load MNIST data from `path`\"\"\"\n    labels_path = os.path.join(path,\n                               '%s-labels-idx1-ubyte.gz'\n\n    images_path = os.path.join(path,\n                               '%s-images-idx3-ubyte.gz'\n\n\n    with gzip.open(labels_path, 'rb') as lbpath:\n        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n                               offset=8)\n\n    with gzip.open(images_path, 'rb') as imgpath:\n        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n                               offset=16).reshape(len(labels), 784)\n\n    return images, labels\n\n\nclass_mapping = [\n    \"T-shirt/top\",\n    \"Trouser\",\n    \"Pullover\",\n    \"Dress\",\n    \"Coat\",\n    \"Sandal\",\n    \"Shirt\",\n    \"Sneaker\",\n    \"Bag\",\n    \"Ankle boot\"\n]\n\n\nX_train, Y_train = load_mnist(path)\nX_test, Y_test = load_mnist(path, 't10k')\n\nX_train = X_train / 255.\nX_test = X_test / 255.\n\n\nX_train.dtype\n\ndtype('float64')\n\n\n\nX_train.shape, Y_train.shape, X_test.shape, Y_test.shape\n\n((60000, 784), (60000,), (10000, 784), (10000,))\n\n\n\nlst1 = list(X_train[0])\nvals = lst1[200: 210]\nvals\n\n[0.0,\n 0.0,\n 0.0,\n 0.0,\n 0.0,\n 0.0,\n 0.0,\n 0.00392156862745098,\n 0.0,\n 0.27058823529411763]\n\n\n\nvals_iter = iter(vals)\n\n\nnext(vals_iter)\n\n0.0\n\n\n\ndef chunks(lst, sz):\n    for i in range(0, len(lst), sz):\n        yield lst[i: i + sz]\n\n\nvals_chunks = chunks(vals, 5)\n\n\nnext(vals_chunks)\n\n[0.0, 0.0, 0.0, 0.0, 0.0]\n\n\n\nnext(vals_chunks)\n\n[0.0, 0.0, 0.00392156862745098, 0.0, 0.27058823529411763]\n\n\n\nplt.imshow(list(chunks(lst1, 28)))\n\n&lt;matplotlib.image.AxesImage&gt;\n\n\n\n\n\n\nY_train[0], class_mapping[Y_train[0]]\n\n(9, 'Ankle boot')\n\n\n\nvals_iter = iter(vals)\n\n\nlist(islice(vals_iter, 5))\n\n[0.0, 0.0, 0.0, 0.0, 0.0]\n\n\n\nit = iter(lst1)\n\n\nplt.imshow(list(iter(lambda: list(islice(it, 28)), [])))\n\n&lt;matplotlib.image.AxesImage&gt;"
  },
  {
    "objectID": "practice/matmul_fashion_mnist_practice.html#get-data",
    "href": "practice/matmul_fashion_mnist_practice.html#get-data",
    "title": "Matrix Multiplication from foundations",
    "section": "",
    "text": "import pickle, gzip, os\nfrom pathlib import Path\nimport json, torch\nfrom itertools import islice\nfrom torch import tensor\nimport random\nfrom matplotlib import pyplot as plt\nfrom fastcore.test import test_close\nfrom numba import njit\nimport numpy as np\nimport math\n\n\nif 'google.colab' in str(get_ipython()):\n  path = Path('fashion_mnist/')\nelse:\n  path = Path('../../data/fashion_mnist/')\n\n\nos.listdir(path)\n\n['t10k-images-idx3-ubyte.gz',\n 'train-labels-idx1-ubyte.gz',\n 'train-images-idx3-ubyte.gz',\n 't10k-labels-idx1-ubyte.gz']\n\n\n\n# taken from https://github.com/zalandoresearch/fashion-mnist/blob/master/utils/mnist_reader.py\ndef load_mnist(path, kind='train'):\n    import os\n    import gzip\n    import numpy as np\n\n    \"\"\"Load MNIST data from `path`\"\"\"\n    labels_path = os.path.join(path,\n                               '%s-labels-idx1-ubyte.gz'\n\n    images_path = os.path.join(path,\n                               '%s-images-idx3-ubyte.gz'\n\n\n    with gzip.open(labels_path, 'rb') as lbpath:\n        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n                               offset=8)\n\n    with gzip.open(images_path, 'rb') as imgpath:\n        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n                               offset=16).reshape(len(labels), 784)\n\n    return images, labels\n\n\nclass_mapping = [\n    \"T-shirt/top\",\n    \"Trouser\",\n    \"Pullover\",\n    \"Dress\",\n    \"Coat\",\n    \"Sandal\",\n    \"Shirt\",\n    \"Sneaker\",\n    \"Bag\",\n    \"Ankle boot\"\n]\n\n\nX_train, Y_train = load_mnist(path)\nX_test, Y_test = load_mnist(path, 't10k')\n\nX_train = X_train / 255.\nX_test = X_test / 255.\n\n\nX_train.dtype\n\ndtype('float64')\n\n\n\nX_train.shape, Y_train.shape, X_test.shape, Y_test.shape\n\n((60000, 784), (60000,), (10000, 784), (10000,))\n\n\n\nlst1 = list(X_train[0])\nvals = lst1[200: 210]\nvals\n\n[0.0,\n 0.0,\n 0.0,\n 0.0,\n 0.0,\n 0.0,\n 0.0,\n 0.00392156862745098,\n 0.0,\n 0.27058823529411763]\n\n\n\nvals_iter = iter(vals)\n\n\nnext(vals_iter)\n\n0.0\n\n\n\ndef chunks(lst, sz):\n    for i in range(0, len(lst), sz):\n        yield lst[i: i + sz]\n\n\nvals_chunks = chunks(vals, 5)\n\n\nnext(vals_chunks)\n\n[0.0, 0.0, 0.0, 0.0, 0.0]\n\n\n\nnext(vals_chunks)\n\n[0.0, 0.0, 0.00392156862745098, 0.0, 0.27058823529411763]\n\n\n\nplt.imshow(list(chunks(lst1, 28)))\n\n&lt;matplotlib.image.AxesImage&gt;\n\n\n\n\n\n\nY_train[0], class_mapping[Y_train[0]]\n\n(9, 'Ankle boot')\n\n\n\nvals_iter = iter(vals)\n\n\nlist(islice(vals_iter, 5))\n\n[0.0, 0.0, 0.0, 0.0, 0.0]\n\n\n\nit = iter(lst1)\n\n\nplt.imshow(list(iter(lambda: list(islice(it, 28)), [])))\n\n&lt;matplotlib.image.AxesImage&gt;"
  },
  {
    "objectID": "practice/matmul_fashion_mnist_practice.html#random-number",
    "href": "practice/matmul_fashion_mnist_practice.html#random-number",
    "title": "Matrix Multiplication from foundations",
    "section": "Random Number",
    "text": "Random Number\n\nrnd_state = None\n\ndef seed(x):\n    global rnd_state\n    x, a = divmod(x, 30326)\n    x, b = divmod(x, 30327)\n    x, c = divmod(x, 30328)\n    rnd_state = int(a) + 1, int(b) + 1, int(c) + 1\n\n\ndef rand():\n    global rnd_state\n    a, b, c = rnd_state\n    x = (172 * a) % 30327\n    y = (171 * b) % 30328\n    z = (170 * c) % 30329\n    rnd_state = x, y, z\n\n    return (x / 30327 + y / 30328 + z / 30329) % 1.0\n\n\nseed(879828)\n\n\nrand(), rand(), rand()\n\n(0.3015735034453595, 0.6902815800191595, 0.8979090043518492)\n\n\n\nplt.plot([rand() for _ in range(50)])\n\n\n\n\n\nplt.hist([rand() for _ in range(100_000)])\n\n(array([ 9911., 10047.,  9879.,  9924., 10184.,  9979.,  9943., 10164.,\n        10059.,  9910.]),\n array([5.26005285e-06, 1.00004091e-01, 2.00002923e-01, 3.00001754e-01,\n        4.00000585e-01, 4.99999417e-01, 5.99998248e-01, 6.99997079e-01,\n        7.99995911e-01, 8.99994742e-01, 9.99993573e-01]),\n &lt;BarContainer object of 10 artists&gt;)\n\n\n\n\n\n\nif os.fork(): print(f'In parent {rand()}')\nelse:\n    print(f'In child {rand()}')\n    os._exit(os.EX_OK)\n\nIn parent 0.9651230962275226\n\n\n\nif os.fork(): print(f'In parent {torch.rand(1)}')\nelse:\n    print(f'In child {torch.rand(1)}')\n    os._exit(os.EX_OK)\n\nIn parent tensor([0.1955])\nIn child tensor([0.1955])\n\n\n\nif os.fork(): print(f'In parent {random.random()}')\nelse:\n    print(f'In child {random.random()}')\n    os._exit(os.EX_OK)\n\nIn parent 0.1996222936679456\nIn child 0.5101572296608223"
  },
  {
    "objectID": "practice/matmul_fashion_mnist_practice.html#matrix-and-tensor",
    "href": "practice/matmul_fashion_mnist_practice.html#matrix-and-tensor",
    "title": "Matrix Multiplication from foundations",
    "section": "Matrix and Tensor",
    "text": "Matrix and Tensor\n\nX_train[100][121]\n\n0.6823529411764706\n\n\n\nclass Matrix:\n    def __init__(self, xs):\n        self.xs = xs\n    def __getitem__(self, idxs):\n        return self.xs[idxs[0]][idxs[1]]\n\n\nm = Matrix(X_train)\n\n\nm[100, 121]\n\n0.6823529411764706\n\n\n\nimgs = tensor(X_train); imgs[100][121]\n\ntensor(0.6824, dtype=torch.float64)\n\n\n\nimgs.dtype\n\ntorch.float64\n\n\n\nimgs = imgs.reshape(-1, 28, 28)\n\n\nplt.imshow(imgs[4])\n\n&lt;matplotlib.image.AxesImage&gt;\n\n\n\n\n\n\nclass_mapping[Y_train[4]]\n\n'T-shirt/top'\n\n\n\n\n\n5.96 ms ± 2.05 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\n\n\n\n134 µs ± 29.1 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)"
  },
  {
    "objectID": "practice/matmul_fashion_mnist_practice.html#matrix-multiplication",
    "href": "practice/matmul_fashion_mnist_practice.html#matrix-multiplication",
    "title": "Matrix Multiplication from foundations",
    "section": "Matrix Multiplication",
    "text": "Matrix Multiplication\n\nm1 = X_train[:5]; m1\n\narray([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])\n\n\n\nm2 = torch.randn(784, 10); m2.shape\n\ntorch.Size([784, 10])\n\n\n\nar, ac = m1.shape\nbr, bc = m2.shape\n\nc = torch.zeros(ar, bc)\n\nfor i in range(ar):\n    for j in range(bc):\n        for k in range(ac):\n            c[i, j] += (m1[i, k] * m2[k, j])\n\n\nc.shape\n\ntorch.Size([5, 10])\n\n\n\ndef matmul(a, b):\n    ar, ac = m1.shape\n    br, bc = m2.shape\n\n    c = torch.zeros(ar, bc)\n\n    for i in range(ar):\n        for j in range(bc):\n            for k in range(ac):\n                c[i, j] += (m1[i, k] * m2[k, j])\n\n    return c\n\n\nt = matmul(m1, m2); t.shape\n\ntorch.Size([5, 10])\n\n\n\n\n\nCPU times: user 989 ms, sys: 2.23 ms, total: 991 ms\nWall time: 997 ms\n\n\n\n5*10*784\n\n39200"
  },
  {
    "objectID": "practice/matmul_fashion_mnist_practice.html#matrix-multiplication-using-numba",
    "href": "practice/matmul_fashion_mnist_practice.html#matrix-multiplication-using-numba",
    "title": "Matrix Multiplication from foundations",
    "section": "Matrix Multiplication using numba",
    "text": "Matrix Multiplication using numba\n\n@njit\ndef dot(a, b):\n    res = 0\n    for i in range(len(a)):\n        res += a[i] * b[i]\n    return res\n\n\na = np.array([1, 2, 3])\nb = np.array([4, 5, 6])\n\n\n\n\nCPU times: user 440 ms, sys: 153 ms, total: 593 ms\nWall time: 614 ms\n\n\n32\n\n\n\n\n\nCPU times: user 10 µs, sys: 2 µs, total: 12 µs\nWall time: 14.8 µs\n\n\n32\n\n\n\nm1[0, :].shape\n\n(784,)\n\n\n\nm2[:, 0].shape\n\ntorch.Size([784])\n\n\n\ndef matmul(a, b):\n    ar, ac = a.shape\n    br, bc = b.shape\n    c = torch.zeros(ar, bc)\n    for i in range(ar):\n        for j in range(bc):\n            c[i, j] = dot(a[i,:], b[:, j])\n    return c\n\n\n\n\nCPU times: user 87.9 ms, sys: 0 ns, total: 87.9 ms\nWall time: 93.8 ms\n\n\n\ntest_close(t, matmul(m1, m2.numpy()), eps=1e-4)"
  },
  {
    "objectID": "practice/matmul_fashion_mnist_practice.html#matrix-multiplication-using-element-wise-operation",
    "href": "practice/matmul_fashion_mnist_practice.html#matrix-multiplication-using-element-wise-operation",
    "title": "Matrix Multiplication from foundations",
    "section": "Matrix Multiplication using element wise operation",
    "text": "Matrix Multiplication using element wise operation\n\nm1 = torch.tensor(m1).float()\n\n\nm1[0, :].shape, m2[:, 0].shape\n\n(torch.Size([784]), torch.Size([784]))\n\n\n\ndef matmul(a, b):\n    ar, ac = a.shape\n    br, bc = b.shape\n    c = torch.zeros(ar, bc)\n    for i in range(ar):\n        for j in range(bc):\n            c[i, j] = (a[i, :] * b[:, j]).sum()\n    return c\n\n\n\n\nCPU times: user 3.18 ms, sys: 31 µs, total: 3.21 ms\nWall time: 6.33 ms\n\n\n\ntest_close(t, matmul(m1, m2), eps=1e-4)\n\n\ndef matmul(a, b):\n    ar, ac = a.shape\n    br, bc = b.shape\n    c = torch.zeros(ar, bc)\n    for i in range(ar):\n        for j in range(bc):\n            c[i, j] = torch.dot(a[i, :], b[:, j])\n    return c\n\n\n\n\nCPU times: user 2.86 ms, sys: 0 ns, total: 2.86 ms\nWall time: 2.79 ms\n\n\n\ntest_close(t, matmul(m1, m2), eps=1e-4)"
  },
  {
    "objectID": "practice/matmul_fashion_mnist_practice.html#matrix-multiplication-using-broadcasting",
    "href": "practice/matmul_fashion_mnist_practice.html#matrix-multiplication-using-broadcasting",
    "title": "Matrix Multiplication from foundations",
    "section": "Matrix Multiplication using broadcasting",
    "text": "Matrix Multiplication using broadcasting\n\nc = tensor([10, 20, 30]); c\n\ntensor([10, 20, 30])\n\n\n\nm = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\n\nt1 = c.expand_as(m); t1.shape\n\ntorch.Size([3, 3])\n\n\n\nt1.stride(), t1.shape\n\n((0, 1), torch.Size([3, 3]))\n\n\n\nt1.storage()\n\nUserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  t1.storage()\n\n\n 10\n 20\n 30\n[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 3]\n\n\n\nm1\n\ntensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]])\n\n\n\nm1[0].shape\n\ntorch.Size([784])\n\n\n\nm1[0, :].shape\n\ntorch.Size([784])\n\n\n\nm1[0, :, None].shape\n\ntorch.Size([784, 1])\n\n\n\nm2.shape\n\ntorch.Size([784, 10])\n\n\n\n(m1[0, :, None] * m2).shape\n\ntorch.Size([784, 10])\n\n\n\n(m1[0, :, None] * m2).sum(axis=0).shape\n\ntorch.Size([10])\n\n\n\ndef matmul(a, b):\n    ar, ac = a.shape\n    br, bc = b.shape\n\n    c = torch.zeros(ar, bc)\n    for i in range(ar):\n        c[i] = (m1[i, :, None] * m2).sum(axis=0)\n    return c\n\n\ntest_close(t, matmul(m1, m2), eps=1e-4)\n\n\n\n\nCPU times: user 323 µs, sys: 0 ns, total: 323 µs\nWall time: 330 µs"
  },
  {
    "objectID": "practice/matmul_fashion_mnist_practice.html#using-matmul",
    "href": "practice/matmul_fashion_mnist_practice.html#using-matmul",
    "title": "Matrix Multiplication from foundations",
    "section": "Using matmul",
    "text": "Using matmul\n\ntest_close(t, m1 @ m2, eps=1e-4)\n\n\n\n\nCPU times: user 38 µs, sys: 7 µs, total: 45 µs\nWall time: 48.6 µs\n\n\n\ntest_close(t, torch.matmul(m1, m2), eps=1e-4)\n\n\n\n\nCPU times: user 43 µs, sys: 0 ns, total: 43 µs\nWall time: 45.8 µs\n\n\n\n\n\nCPU times: user 28.5 ms, sys: 34.1 ms, total: 62.5 ms\nWall time: 70 ms\n\n\n\n\n\nCPU times: user 1.31 ms, sys: 0 ns, total: 1.31 ms\nWall time: 2.03 ms"
  },
  {
    "objectID": "practice/matmul_fashion_mnist_practice.html#einstein-summation",
    "href": "practice/matmul_fashion_mnist_practice.html#einstein-summation",
    "title": "Matrix Multiplication from foundations",
    "section": "Einstein Summation",
    "text": "Einstein Summation\n\nm1.shape, m2.shape\n\n(torch.Size([5, 784]), torch.Size([784, 10]))\n\n\n\nmr = torch.einsum('ik,kj-&gt;ikj', m1, m2); mr.shape\n\ntorch.Size([5, 784, 10])\n\n\n\ntorch.set_printoptions(precision=2, linewidth=14, sci_mode=False)\n\n\nmr.sum(1)\n\ntensor([[  5.97,\n         -26.21,\n         -19.14,\n          11.53,\n          30.43,\n           5.51,\n         -10.37,\n          -3.66,\n           6.63,\n         -18.34],\n        [  4.37,\n         -24.84,\n         -12.90,\n          15.05,\n          26.32,\n           6.76,\n          -5.28,\n         -13.98,\n          20.55,\n         -20.79],\n        [ -3.20,\n         -10.03,\n           0.13,\n          11.45,\n           6.50,\n           1.72,\n          -2.58,\n           0.95,\n           6.77,\n          -6.72],\n        [ -0.12,\n          -1.54,\n          -3.97,\n          13.97,\n          12.62,\n          -1.87,\n          -3.98,\n          -3.59,\n           7.12,\n          -8.40],\n        [-10.83,\n         -16.76,\n         -12.78,\n          10.36,\n          24.11,\n          15.64,\n          -8.89,\n           1.78,\n           3.56,\n         -11.24]])\n\n\n\nmr = torch.einsum('ik,kj-&gt;ij', m1, m2); mr.shape\n\ntorch.Size([5, 10])\n\n\n\ntest_close(t, mr, eps=1e-4)\n\n\n\n\nCPU times: user 795 µs, sys: 0 ns, total: 795 µs\nWall time: 652 µs\n\n\n\npytorch op\n\ntest_close(t, m1@m2, eps=1e-4)\n\n\ntest_close(t, torch.matmul(m1, m2), eps=1e-4)\n\n\n\n\nCPU times: user 39 µs, sys: 7 µs, total: 46 µs\nWall time: 50.1 µs"
  },
  {
    "objectID": "practice/matmul_fashion_mnist_practice.html#cuda",
    "href": "practice/matmul_fashion_mnist_practice.html#cuda",
    "title": "Matrix Multiplication from foundations",
    "section": "CUDA",
    "text": "CUDA\n\ndef matmul(grid, a, b, c):\n    i, j = grid\n    if i &lt; c.shape[0] and j &lt; c.shape[1]:\n        temp = 0\n        for k in range(a.shape[1]):\n            temp += a[i, k] * b[k, j]\n        c[i, j] = temp\n\n\nar, ac = m1.shape\nbr, bc = m2.shape\nr = torch.zeros(ar, bc)\nmatmul((0, 0), m1, m2, r)\nr\n\ntensor([[5.97,\n         0.00,\n         0.00,\n         0.00,\n         0.00,\n         0.00,\n         0.00,\n         0.00,\n         0.00,\n         0.00],\n        [0.00,\n         0.00,\n         0.00,\n         0.00,\n         0.00,\n         0.00,\n         0.00,\n         0.00,\n         0.00,\n         0.00],\n        [0.00,\n         0.00,\n         0.00,\n         0.00,\n         0.00,\n         0.00,\n         0.00,\n         0.00,\n         0.00,\n         0.00],\n        [0.00,\n         0.00,\n         0.00,\n         0.00,\n         0.00,\n         0.00,\n         0.00,\n         0.00,\n         0.00,\n         0.00],\n        [0.00,\n         0.00,\n         0.00,\n         0.00,\n         0.00,\n         0.00,\n         0.00,\n         0.00,\n         0.00,\n         0.00]])\n\n\n\ndef launch_kernel(kernel, grid_x, grid_y, *args, **kwards):\n    for i in range(grid_x):\n        for j in range(grid_y):\n            kernel((i, j), *args)\n\n\ngrid_x = ar\ngrid_y = bc\nr = torch.zeros(ar, bc)\nlaunch_kernel(matmul, grid_x, grid_y, m1, m2, r)\nr\n\ntensor([[  5.97,\n         -26.21,\n         -19.14,\n          11.53,\n          30.43,\n           5.51,\n         -10.37,\n          -3.66,\n           6.63,\n         -18.34],\n        [  4.37,\n         -24.84,\n         -12.90,\n          15.05,\n          26.32,\n           6.76,\n          -5.28,\n         -13.98,\n          20.55,\n         -20.79],\n        [ -3.20,\n         -10.03,\n           0.13,\n          11.45,\n           6.50,\n           1.72,\n          -2.58,\n           0.95,\n           6.77,\n          -6.72],\n        [ -0.12,\n          -1.54,\n          -3.97,\n          13.97,\n          12.62,\n          -1.87,\n          -3.98,\n          -3.59,\n           7.12,\n          -8.40],\n        [-10.83,\n         -16.76,\n         -12.78,\n          10.36,\n          24.11,\n          15.64,\n          -8.89,\n           1.78,\n           3.56,\n         -11.24]])\n\n\n\ntest_close(t, r, eps=1e-4)\n\n\nfrom numba import cuda\n\n\nTPB = 16\nrr, rc = r.shape\nblockspergrid = (math.ceil(rr / TPB), math.ceil(rc / TPB))\n\n\n@cuda.jit\ndef matmul(a, b, c):\n  i, j = cuda.grid(2)\n  if i &lt; c.shape[0] and j &lt; c.shape[1]:\n    tmp = 0.\n    for k in range(a.shape[1]):\n      tmp += a[i, k] * b[k, j]\n    c[i, j] = tmp\n\n\nr = np.zeros((rr, rc))\nm1 = m1.numpy()\nm2 = m2.numpy()\nm1g, m2g, rg = map(cuda.to_device, (m1, m2, r))\n\n\nmatmul[blockspergrid, (TPB, TPB)](m1, m2, rg)\n\n/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:886: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n  warn(NumbaPerformanceWarning(msg))\n\n\n\nr = rg.copy_to_host(); r.shape\n\n(5, 10)\n\n\n\ntest_close(t, r, eps=1e-4)\n\n\n\n\nCPU times: user 3.34 ms, sys: 56 µs, total: 3.4 ms\nWall time: 3.11 ms\n\n\n\nm1, m2 = map(torch.tensor, (m1, m2))\n\n\n\n\nCPU times: user 573 µs, sys: 0 ns, total: 573 µs\nWall time: 411 µs"
  },
  {
    "objectID": "lectures/meanshift_lsh.html",
    "href": "lectures/meanshift_lsh.html",
    "title": "Meanshift Using LSH",
    "section": "",
    "text": "import numpy as np\nimport math\nfrom math import pi\nimport torch\nfrom matplotlib import pyplot as plt\nfrom torch.distributions import MultivariateNormal\nfrom miniai.lsh import FastLSH\n\n\ntorch.manual_seed(256)\ntorch.set_printoptions(precision=5, linewidth=140)\n\n\nn_clusters = 6\nn_samples= 250\n\n\ncentroids = torch.randn(n_clusters, 2) * 70 - 35\n\n\ndef sample(c): return MultivariateNormal(c, torch.diag(torch.tensor([5., 5.]))).sample((n_samples,))\n\n\ndata = torch.concat([sample(c) for c in centroids], axis=0)\n\n\ndata.shape\n\ntorch.Size([1500, 2])\n\n\n\ndef plot_data(centroids, data, ax=None):\n    if ax is None: fig, ax = plt.subplots()\n    for i, centroid in enumerate(centroids):\n        samples = data[i*n_samples:(i+1)*n_samples]\n        ax.scatter(samples[:, 0], samples[:, 1], s = 1)\n        ax.plot(*centroid, markersize=10, marker=\"x\", color=\"k\", mew=5)\n        ax.plot(*centroid, markersize=5, marker=\"x\", color=\"m\", mew=3)\n\n\nplot_data(centroids, data)\n\n\n\n\n\nX = data.clone()\n\n\nx = X[0]\n\n\nlsh = FastLSH(2, 2, 3)\n\n\nXh = lsh.hashing(X)\n\n\ndef one_update(X):\n    for i, x in enumerate(X):\n        dist, idx = lsh.query_neigbours(x[None], X, Xh, 150)\n        # removing weighting because lsh already returns in a sorted order\n        # and we are requesting for nearest neighbours\n\n        X[i] = X[idx].sum(0)/len(idx)\n\n\ndef meanshift(data):\n    X = data.clone()\n    for i in range(5): one_update(X)\n    return X\n\n\n\n\n1.56 s ± 11.2 ms per loop (mean ± std. dev. of 7 runs, 5 loops each)\n\n\n\nY = meanshift(data)\n\n\nY\n\ntensor([[ -28.38632, -102.51652],\n        [ -28.34384, -102.53816],\n        [ -28.34400, -102.53811],\n        ...,\n        [ -26.40479,  106.70017],\n        [ -26.35939,  106.70464],\n        [ -26.35950,  106.70462]])\n\n\n\nplot_data(centroids+5, Y)\n\n\n\n\n\nfrom matplotlib.animation import FuncAnimation\nfrom IPython.display import HTML\n\n\ndef animate(d):\n    if not d: return plot_data(centroids + 5, X, ax=ax)\n    one_update(X)\n    ax.clear()\n    plot_data(centroids + 5, X, ax=ax)\n\n\nX= data.clone()\nfig, ax = plt.subplots()\nf = FuncAnimation(fig, animate, frames=5, interval=500, repeat=False)\nplt.close()\nHTML(f.to_jshtml())\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  }
]