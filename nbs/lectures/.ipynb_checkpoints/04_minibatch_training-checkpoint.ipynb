{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd5bd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5ae9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import pickle, gzip, math, os, time, shutil, torch, matplotlib as mpl, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, tensor\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1c4666",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anubhavmaity/mambaforge/envs/fastai/lib/python3.9/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.8.13) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from fastcore.test import test_close\n",
    "import deeplake\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "torch.manual_seed(42)\n",
    "\n",
    "mpl.rcParams['image.cmap'] = 'gray'\n",
    "torch.set_printoptions(precision=2, linewidth=125, sci_mode=False)\n",
    "np.set_printoptions(precision=2, linewidth=125)\n",
    "\n",
    "ds = deeplake.load('hub://activeloop/not-mnist-small', read_only=True, verbose=False)\n",
    "\n",
    "images = ds.tensors['images'].numpy().reshape(-1, 784).astype('float32')\n",
    "labels = ds.tensors['labels'].numpy().squeeze(-1).astype('int')\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(images, labels, test_size=0.2, random_state=1)\n",
    "x_train, y_train, x_valid, y_valid = map(tensor, (x_train, y_train, x_valid, y_valid))\n",
    "x_train, x_valid = x_train/255., x_valid/255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8662e9c3",
   "metadata": {},
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4adacba",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a69b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def char(y): return 'ABCDEFGHIJ'[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4eb508",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, m = x_train.shape\n",
    "c = y_train.max() + 1\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07649ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in, nh), nn.ReLU(), nn.Linear(nh, n_out)]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfea3ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14979, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(m, nh, 10)\n",
    "pred = model(x_train)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2407f574",
   "metadata": {},
   "source": [
    "## Cross entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807a950d",
   "metadata": {},
   "source": [
    "First, we need to compute the softmax of out activations. This is defined by:\n",
    "    \n",
    "$$ \\text{Softmax}(x)_i = \\frac{e^{x_i}}{e^{x_1} + e^{x_2} + \\ldots + e^{x_N}}, \\quad \\text{for } i = 1, 2, \\ldots, N $$\n",
    "\n",
    "\n",
    "or more concisely, \n",
    "\n",
    "$$ \\text{Softmax}(x)_i = \\frac{e^{x_i}}{\\sum_{j=1}^{N} e^{x_j}} $$\n",
    "    \n",
    "In practice, we will need the log of the softmax \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67982439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return (x.exp()/x.exp().sum(-1, keepdim=True)).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20d5d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.34, -2.22, -2.05,  ..., -2.41, -2.57, -2.15],\n",
       "        [-2.37, -2.37, -2.03,  ..., -2.52, -2.53, -2.33],\n",
       "        [-2.45, -2.24, -2.15,  ..., -2.43, -2.51, -2.23],\n",
       "        ...,\n",
       "        [-2.39, -2.35, -2.02,  ..., -2.39, -2.54, -2.33],\n",
       "        [-2.53, -2.31, -2.09,  ..., -2.52, -2.51, -2.17],\n",
       "        [-2.38, -2.31, -2.26,  ..., -2.38, -2.42, -2.21]], grad_fn=<LogBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9e8324",
   "metadata": {},
   "source": [
    "Note that the formula\n",
    "\n",
    "$$ \\log_{b}\\left(\\frac{a}{c}\\right) = \\log_{b}(a) - \\log_{b}(c) $$\n",
    "\n",
    "gives a simplification when we compute the log softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5b88d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return x - x.exp().sum(-1, keepdim=True).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7680a315",
   "metadata": {},
   "source": [
    "Then, there is a way to compute the log of the sum of exponentials in a more stable way, called the LogSumExp trick. The idea is to use the following formula\n",
    "\n",
    "$$ \\log\\left(\\sum_{i=1}^{n} e^{x_i}\\right) = a + \\log\\left(\\sum_{i=1}^{n} e^{x_i - a}\\right) $$\n",
    "\n",
    "where a is the maximum of the $x_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5726fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x):\n",
    "    m = x.max(-1)[0]\n",
    "    return m + (x - m[:, None]).exp().sum(-1).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9e58eb",
   "metadata": {},
   "source": [
    "This way, we will avoid an overflow when taking the exponential of a big activation. In PyTorch, this is already implemented for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf7475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return x - x.logsumexp(-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2692ddff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.34, -2.22, -2.05,  ..., -2.41, -2.57, -2.15],\n",
       "        [-2.37, -2.37, -2.03,  ..., -2.52, -2.53, -2.33],\n",
       "        [-2.45, -2.24, -2.15,  ..., -2.43, -2.51, -2.23],\n",
       "        ...,\n",
       "        [-2.39, -2.35, -2.02,  ..., -2.39, -2.54, -2.33],\n",
       "        [-2.53, -2.31, -2.09,  ..., -2.52, -2.51, -2.17],\n",
       "        [-2.38, -2.31, -2.26,  ..., -2.38, -2.42, -2.21]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_close(logsumexp(pred), pred.logsumexp(-1))\n",
    "sm_pred = log_softmax(pred)\n",
    "sm_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8299dc",
   "metadata": {},
   "source": [
    "The cross entropy loss for some target $x$ and some prediction $p(x)$ is given by:\n",
    "    $$-\\sum_{i=1}^{N} y_i \\cdot \\log(\\hat{y}_i)$$\n",
    "But since out $xs$ are 1-hot encoded, this can be written as $-log(p_i)$ where $i$ is the index of the desired target\n",
    "\n",
    "This can be done using numpy-style integer array indexing. Note that PyTorch supports all the tricks in the advanced indexing methods discussed in that link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8096ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 5, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124f3841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-2.40, grad_fn=<SelectBackward0>),\n",
       " tensor(-2.37, grad_fn=<SelectBackward0>),\n",
       " tensor(-2.26, grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred[0, 5], sm_pred[1, 0], sm_pred[2, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45264dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.57, -2.50, -2.15], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred[[0, 1, 2], y_train[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05db97ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target): return -input[range(target.shape[0]), target].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4fabe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.31, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nll(sm_pred, y_train)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce20b32a",
   "metadata": {},
   "source": [
    "Then use PyTorch's implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1c87d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(F.nll_loss(F.log_softmax(pred, -1), y_train), loss, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46f9d6b",
   "metadata": {},
   "source": [
    "In PyTorch, `F.log_softmax` and `F.nll_loss` are combined in one optimized function, `F.cross_entropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0621e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(F.cross_entropy(pred, y_train), loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccf2b5c",
   "metadata": {},
   "source": [
    "## Basic training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76337d6",
   "metadata": {},
   "source": [
    "Basically the training loop repeats over the following steps:\n",
    "\n",
    "    - get the output of the model on a batch of inputs\n",
    "    - compare the output to the labels we have and compute a loss\n",
    "    - calculate the gradients of the loss with repsect to every parameter of the model\n",
    "    - update said parameters with those gradients to make them a little bit better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ba94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931ef057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.02,  0.14,  0.32, -0.03,  0.07, -0.03,  0.07, -0.04, -0.21,  0.21], grad_fn=<SelectBackward0>),\n",
       " torch.Size([64, 10]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 64 # batch size\n",
    "\n",
    "xb = x_train[0:bs] # a mini-batch from x\n",
    "preds = model(xb)\n",
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bee46b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.32, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "loss_func(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5306c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 9, 5, 4, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 9, 2, 2, 4, 2, 2, 1,\n",
       "        2, 2, 4, 2, 2, 2, 2, 4, 4, 2, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2, 9, 9, 2, 2, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(preds, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfdaa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def accuracy(out, yb): return (torch.argmax(out, dim=1)==yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0a8c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.16)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fef2270",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1 # learning rate\n",
    "epochs = 3 # how many epochs to train for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80df3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def report(loss, preds, yb): print(f'{loss: .2f}, {accuracy(preds, yb): .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba6272b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2.32,  0.16\n"
     ]
    }
   ],
   "source": [
    "xb, yb = x_train[:bs], y_train[:bs]\n",
    "preds = model(xb)\n",
    "report(loss_func(preds, yb), preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5473666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.63,  1.00\n",
      " 0.42,  1.00\n",
      " 0.31,  1.00\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n, i + bs))\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for l in model.layers:\n",
    "                if hasattr(l, 'weight'):\n",
    "                    l.weight -= l.weight.grad * lr\n",
    "                    l.bias -= l.bias.grad * lr\n",
    "                    l.weight.grad.zero_()\n",
    "                    l.bias.grad.zero_()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b0c01a",
   "metadata": {},
   "source": [
    "## Using parameters and optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732b158d",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3555691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Module(\n",
       "  (foo): Linear(in_features=3, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = nn.Module()\n",
    "m1.foo = nn.Linear(3, 4)\n",
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b17f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('foo', Linear(in_features=3, out_features=4, bias=True))]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m1.named_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b66f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.named_children>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.named_children()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2445593f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.24, -0.11,  0.46],\n",
       "         [-0.17, -0.46, -0.07],\n",
       "         [-0.29,  0.31,  0.08],\n",
       "         [-0.24,  0.13, -0.17]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.01,  0.51, -0.11, -0.47], requires_grad=True)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85739801",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x): return self.l2(self.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b996781c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=50, bias=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP(m, nh, 10)\n",
    "model.l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004aa5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a87a7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1: Linear(in_features=784, out_features=50, bias=True)\n",
      "l2: Linear(in_features=50, out_features=10, bias=True)\n",
      "relu: ReLU()\n"
     ]
    }
   ],
   "source": [
    "for name, l in model.named_children(): print(f\"{name}: {l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7a45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters(): print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554efb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fedde16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, n, bs):\n",
    "            s = slice(i, min(n, i+bs))\n",
    "            xb, yb = x_train[s], y_train[s]\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters(): p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "        report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4ab345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.67,  1.00\n",
      " 0.45,  1.00\n",
      " 0.32,  1.00\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe11a1db",
   "metadata": {},
   "source": [
    "Behind the scenes, PyTorch overrides the `__setattr__` function in `nn.Module` so that submodules you define are properly registerd as parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc1b8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule:\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        self._modules = {}\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "    \n",
    "    def __setattr__(self, k, v):\n",
    "        if not k.startswith(\"_\"): self._modules[k] = v\n",
    "        super().__setattr__(k, v)\n",
    "    \n",
    "    def __repr__(self): return f'{self._modules}'\n",
    "    \n",
    "    def parameters(self):\n",
    "        for l in self._modules.values():\n",
    "            # for p in l.parameters(): yield p\n",
    "            yield from l.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493d0d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = MyModule(m, nh, 10)\n",
    "mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644a65df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in mdl.parameters(): print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eb9da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule:\n",
    "    def __init__(self):\n",
    "        self._modules = {}\n",
    "    \n",
    "    def __setattr__(self, k, v):\n",
    "        if not k.startswith(\"_\"): self._modules[k] = v\n",
    "        super().__setattr__(k, v)\n",
    "    \n",
    "    def __repr__(self): return f'{self._modules}'\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "    \n",
    "    def forward(self, x): raise Exception(\"Not implemented\")\n",
    "    \n",
    "    def parameters(self):\n",
    "        for l in self._modules.values():\n",
    "            yield from l.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55be5aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(MyModule):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.l2(self.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2138ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(m, nh, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9b8c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b9f889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(xb).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6644642",
   "metadata": {},
   "source": [
    "### Registering modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2071a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235663f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(lambda x, y: x + y, [1, 2, 3, 4, 5], 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b87e407",
   "metadata": {},
   "source": [
    "We can use the original `layers` approach, but we have to register the modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cd6bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=50, out_features=10, bias=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Linear(nh, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4370c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ff3079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg(x): return -x\n",
    "def exp(x): return np.exp(x)\n",
    "def log(x): return np.log(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7bc6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(lambda x, y: y(x), [neg, exp, log, neg], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fdfd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        for i, l in enumerate(self.layers): self.add_module(f'layer_{i}', l)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return reduce(lambda val, layer: layer(val), self.layers, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2a64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (layer_1): ReLU()\n",
       "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90925cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(xb).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34978ee2",
   "metadata": {},
   "source": [
    "## nn.ModuleList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e3c2bf",
   "metadata": {},
   "source": [
    "`nn.ModuleList` does this for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ca4378",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55e705c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialModel(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SequentialModel(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceabc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.71,  0.67\n",
      " 0.47,  1.00\n",
      " 0.32,  1.00\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a352817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.91), tensor(0.90))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model(x_train), y_train), accuracy(model(x_valid), y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c716066d",
   "metadata": {},
   "source": [
    "## nn.Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fd68d7",
   "metadata": {},
   "source": [
    "`nn.Sequential` is a convenient class which does the same as the above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f481ded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(784, nh), nn.ReLU(), nn.Linear(nh, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef818ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.64,  1.00\n",
      " 0.43,  1.00\n",
      " 0.35,  1.00\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f73abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.22, grad_fn=<NllLossBackward0>), tensor(1.))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ff882f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deeee11",
   "metadata": {},
   "source": [
    "## optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fcf3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, params, lr=0.5): \n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "    \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params: p -= p.grad * self.lr\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for p in self.params: p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b1942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069a9713",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimizer(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc42d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2.15,  0.33\n",
      " 1.20,  0.67\n",
      " 1.03,  0.67\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, x_train.shape[0], bs):\n",
    "        s = slice(i, i + bs)\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399574c8",
   "metadata": {},
   "source": [
    "PyTorch already provides this exact functionality in `optim.SGD` (it also handles stiff like momentum, which we'll look at later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a805a762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dbdd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eda47d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.31, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "loss_func(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac874af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.65,  1.00\n",
      " 0.44,  1.00\n",
      " 0.32,  1.00\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, x_train.shape[0], bs):\n",
    "        s = slice(i, i + bs)\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846f4dfe",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7761bc0d",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f680cfb5",
   "metadata": {},
   "source": [
    "It's clunky to iterate through minibatches of x and values seperately:\n",
    "\n",
    "    xb = x_train[s]\n",
    "    yb = y_train[s]\n",
    "\n",
    "Instead, lets do these two steps together by introducing a `Dataset` class:\n",
    "    \n",
    "    xb,yb = train_ds[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2bcbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Dataset:\n",
    "    def __init__(self, x, y): self.x, self.y = x, y\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __getitem__(self, i): return self.x[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee849d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_valid, y_valid)\n",
    "assert len(train_ds) == len(x_train)\n",
    "assert len(valid_ds) == len(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfd1e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.00, 1.00, 1.00,  ..., 1.00, 1.00, 1.00],\n",
       "         [0.85, 1.00, 1.00,  ..., 0.00, 0.00, 0.00],\n",
       "         [0.00, 0.00, 0.00,  ..., 0.00, 0.00, 0.00],\n",
       "         [0.00, 0.00, 0.00,  ..., 0.00, 0.00, 0.00],\n",
       "         [0.43, 1.00, 0.99,  ..., 0.00, 0.00, 0.00]]),\n",
       " tensor([8, 5, 2, 6, 5]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = train_ds[0:5]\n",
    "assert xb.shape == (5, 28 * 28)\n",
    "assert yb.shape == (5,)\n",
    "xb, yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0218c01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.24,  1.00\n",
      " 0.18,  1.00\n",
      " 0.14,  1.00\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(train_ds), bs):\n",
    "        xb, yb = train_ds[i: i + bs]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e346364",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c903ab4f",
   "metadata": {},
   "source": [
    "Previously, our loop iterated over batches (xb, yb) like this:\n",
    "    \n",
    "    for i in range(0, n, bs):\n",
    "        xb, yb = train_ds[i: i + bs]\n",
    "        ...\n",
    "    \n",
    "Let's make out loop much cleaner, using a data loader:\n",
    "    \n",
    "    for xb, yb in train_dl:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3f2e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, ds, bs): self.ds, self.bs = ds, bs\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.ds), self.bs): yield self.ds[i: i + self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8551e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs)\n",
    "valid_dl = DataLoader(valid_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc54fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 784])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(valid_dl))\n",
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb07c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 5, 0, 0, 9, 9, 7, 4, 4, 6, 2, 4, 7, 5, 8, 3, 1, 9, 0, 3, 1, 0, 1, 3, 3, 2, 2, 0, 5, 2, 7, 5, 1, 2, 1, 8, 1, 2, 7,\n",
       "        6, 1, 2, 5, 9, 4, 1, 9, 0, 2, 6, 7, 9, 7, 0, 1, 0, 3, 3, 7, 5, 9, 5, 0, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a781658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xb[6].view(28, 28))\n",
    "char(yb[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079e2e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53886f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in train_dl:\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268ad27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.66,  1.00\n",
      " 0.45,  1.00\n",
      " 0.33,  1.00\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6013e05e",
   "metadata": {},
   "source": [
    "### Random Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136ad4cd",
   "metadata": {},
   "source": [
    "We want our training set to be in random order, and that order should differ each iteration. But the validation set should not be randomized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562ce871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c434512",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler():\n",
    "    def __init__(self, ds, shuffle=False): self.n, self.shuffle = len(ds), shuffle\n",
    "    def __iter__(self):\n",
    "        res = list(range(self.n))\n",
    "        if self.shuffle: random.shuffle(res)\n",
    "        return iter(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c2e1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1283b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = Sampler(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8754c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "it = iter(ss)\n",
    "for _ in range(5): print(next(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6740995f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(islice(ss, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f5d0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6243, 6451, 7888, 2292, 8679]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = Sampler(train_ds, shuffle=True)\n",
    "list(islice(ss, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b89ed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastcore.all as fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7929f90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSampler:\n",
    "    def __init__(self, sampler, bs, drop_last=False):\n",
    "        fc.store_attr()\n",
    "    \n",
    "    def __iter__(self): yield from fc.chunked(iter(self.sampler), self.bs, drop_last=self.drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c94575",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchs = BatchSampler(ss, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f040748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[13386, 2469, 8504, 10104],\n",
       " [1845, 13930, 13418, 13347],\n",
       " [5840, 12160, 13646, 5581],\n",
       " [196, 4360, 9916, 12852],\n",
       " [8950, 4891, 3018, 8395]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(islice(batchs, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8b55b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(b):\n",
    "    xs, ys = zip(*b)\n",
    "    return torch.stack(xs), torch.stack(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cb32fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, ds, batchs, collate_fn=collate): fc.store_attr()\n",
    "    def __iter__(self): yield from (self.collate_fn(self.ds[i] for i in b) for b in self.batchs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3936454",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = BatchSampler(Sampler(train_ds, shuffle=True), bs)\n",
    "valid_samp = BatchSampler(Sampler(valid_ds, shuffle=False), bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adb2a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batchs=train_samp, collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, batchs=valid_samp, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d527229",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7853865a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'G'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xb[0].view(28, 28))\n",
    "char(yb[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6e8e07",
   "metadata": {},
   "source": [
    "## Multiprocessing DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29701fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp\n",
    "from fastcore.basics import store_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16c8ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.00, 0.00, 0.00,  ..., 0.00, 0.00, 0.00],\n",
       "         [0.25, 0.63, 0.99,  ..., 0.00, 0.00, 0.00],\n",
       "         [0.00, 0.00, 0.00,  ..., 0.00, 0.00, 0.00],\n",
       "         [0.85, 1.00, 1.00,  ..., 0.00, 0.00, 0.00]]),\n",
       " tensor([6, 3, 4, 5]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[[3, 6, 8, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c22529e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.00, 0.00, 0.00,  ..., 0.00, 0.00, 0.00],\n",
       "         [0.25, 0.63, 0.99,  ..., 0.00, 0.00, 0.00],\n",
       "         [0.00, 0.00, 0.00,  ..., 0.00, 0.00, 0.00],\n",
       "         [0.85, 1.00, 1.00,  ..., 0.00, 0.00, 0.00]]),\n",
       " tensor([6, 3, 4, 5]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.__getitem__([3, 6, 8, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fcc4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0.00, 0.00, 0.00,  ..., 0.00, 0.00, 0.00],\n",
      "        [0.25, 0.63, 0.99,  ..., 0.00, 0.00, 0.00]]), tensor([6, 3]))\n",
      "(tensor([[0.00, 0.00, 0.00,  ..., 0.00, 0.00, 0.00],\n",
      "        [0.85, 1.00, 1.00,  ..., 0.00, 0.00, 0.00]]), tensor([4, 5]))\n"
     ]
    }
   ],
   "source": [
    "for o in map(train_ds.__getitem__, ([3, 6], [8, 1])): print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70edafb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, ds, batchs, n_workers=1, collate_fn=collate): fc.store_attr()\n",
    "    def __iter__(self):\n",
    "        with mp.Pool(self.n_workers) as ex: yield from ex.map(self.ds.__getitem__, self.batchs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055b42eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batchs=train_samp, n_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50508ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 784]), torch.Size([64]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(train_dl)\n",
    "xb, yb= next(it)\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a009b2a",
   "metadata": {},
   "source": [
    "## Pytorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba6fcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler, BatchSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57eb1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = BatchSampler(RandomSampler(train_ds), bs, drop_last=False)\n",
    "valid_samp = BatchSampler(SequentialSampler(valid_ds), bs, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988d1141",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_sampler=train_samp)\n",
    "valid_dl = DataLoader(valid_ds, batch_sampler=valid_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3696981e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.06,  1.00\n",
      " 1.32,  0.67\n",
      " 0.06,  1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.36, grad_fn=<NllLossBackward0>), tensor(0.90))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "fit()\n",
    "loss_func(model(x_train), y_train), accuracy(model(x_train), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39e4b3a",
   "metadata": {},
   "source": [
    "PyTorch can auto-generate the BatchSampler for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1938331",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, sampler=RandomSampler(train_ds), collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, bs, sampler=SequentialSampler(valid_ds), collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d8e0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 784]), torch.Size([64]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(train_dl))\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4c708b",
   "metadata": {},
   "source": [
    "PyTorch can also generate the Sequential/RandomSamplers too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fc1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, shuffle=True, num_workers=2)\n",
    "valid_dl = DataLoader(valid_ds, bs, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af7a3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 784]), torch.Size([64]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(train_dl))\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c335cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.02,  1.00\n",
      " 1.05,  0.67\n",
      " 0.06,  1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.33, grad_fn=<NllLossBackward0>), tensor(0.91))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "fit()\n",
    "\n",
    "loss_func(model(x_train), y_train), accuracy(model(x_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da691771",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, sampler=train_samp)\n",
    "valid_dl = DataLoader(valid_ds, sampler=valid_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1400575e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64, 784]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(train_dl))\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b973f37f",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98ff81d",
   "metadata": {},
   "source": [
    "You always should also have a validation set, in order to identify if you are overfitting.\n",
    "\n",
    "We will calculate and print the validation loss at the end of each epoch.\n",
    "\n",
    "(Note that we always call `model.train()` before training, and `model.eval()` before inference, because these are used by layers such as `nn.BatchNorm2d` and `nn.Dropout` to ensure appropriate behaviour for these different phases.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046a22f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss = loss_func(model(xb), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            tot_loss, tot_acc, count = 0., 0., 0.\n",
    "            for xb, yb in valid_dl:\n",
    "                pred = model(xb)\n",
    "                n = len(xb)\n",
    "                count += n\n",
    "                tot_loss += loss_func(pred, yb).item() * n\n",
    "                tot_acc += accuracy(pred, yb).item() * n\n",
    "        print(epoch, tot_loss/count, tot_acc/count)\n",
    "    return tot_loss/count, tot_acc/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d18961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
    "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
    "            DataLoader(valid_ds, batch_size=bs*2, **kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c883e391",
   "metadata": {},
   "source": [
    "Now, our whole process of obtaining the data loaders and fitting the model can be run in 3 lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ecdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.495113473247304 0.8579439254246344\n",
      "1 0.4105260279213634 0.8889185583002577\n",
      "2 0.38728047195518606 0.8907877169081939\n",
      "3 3.558573368171824 0.396795727724386\n",
      "4 0.3829993531605271 0.8963951935437079\n"
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl = get_dls(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()\n",
    "loss, acc = fit(5, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561d91a5",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e13360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev import nbdev_export; nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b1ca89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
