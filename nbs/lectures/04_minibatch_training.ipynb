{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd5bd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db81a677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import pickle, gzip, math, os, time, shutil, torch, matplotlib as mpl, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, tensor\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1c4666",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anubhavmaity/mambaforge/envs/fastai/lib/python3.9/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.8.18) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from fastcore.test import test_close\n",
    "import deeplake\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "torch.manual_seed(42)\n",
    "\n",
    "mpl.rcParams['image.cmap'] = 'gray'\n",
    "torch.set_printoptions(precision=2, linewidth=125, sci_mode=False)\n",
    "np.set_printoptions(precision=2, linewidth=125)\n",
    "\n",
    "ds = deeplake.load('hub://activeloop/not-mnist-small', read_only=True, verbose=False)\n",
    "\n",
    "images = ds.tensors['images'].numpy().reshape(-1, 784).astype('float32')\n",
    "labels = ds.tensors['labels'].numpy().squeeze(-1).astype('int')\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(images, labels, test_size=0.2, random_state=1)\n",
    "x_train, y_train, x_valid, y_valid = map(tensor, (x_train, y_train, x_valid, y_valid))\n",
    "x_train, x_valid = x_train/255., x_valid/255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8662e9c3",
   "metadata": {},
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4adacba",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a69b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def char(y): return 'ABCDEFGHIJ'[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4eb508",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, m = x_train.shape\n",
    "c = y_train.max() + 1\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07649ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in, nh), nn.ReLU(), nn.Linear(nh, n_out)]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfea3ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14979, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(m, nh, 10)\n",
    "pred = model(x_train)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2407f574",
   "metadata": {},
   "source": [
    "## Cross entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807a950d",
   "metadata": {},
   "source": [
    "First, we need to compute the softmax of out activations. This is defined by:\n",
    "    \n",
    "$$ \\text{Softmax}(x)_i = \\frac{e^{x_i}}{e^{x_1} + e^{x_2} + \\ldots + e^{x_N}}, \\quad \\text{for } i = 1, 2, \\ldots, N $$\n",
    "\n",
    "\n",
    "or more concisely, \n",
    "\n",
    "$$ \\text{Softmax}(x)_i = \\frac{e^{x_i}}{\\sum_{j=1}^{N} e^{x_j}} $$\n",
    "    \n",
    "In practice, we will need the log of the softmax \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67982439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return (x.exp()/x.exp().sum(-1, keepdim=True)).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20d5d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.34, -2.22, -2.05,  ..., -2.41, -2.57, -2.15],\n",
       "        [-2.37, -2.37, -2.03,  ..., -2.52, -2.53, -2.33],\n",
       "        [-2.45, -2.24, -2.15,  ..., -2.43, -2.51, -2.23],\n",
       "        ...,\n",
       "        [-2.39, -2.35, -2.02,  ..., -2.39, -2.54, -2.33],\n",
       "        [-2.53, -2.31, -2.09,  ..., -2.52, -2.51, -2.17],\n",
       "        [-2.38, -2.31, -2.26,  ..., -2.38, -2.42, -2.21]], grad_fn=<LogBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9e8324",
   "metadata": {},
   "source": [
    "Note that the formula\n",
    "\n",
    "$$ \\log_{b}\\left(\\frac{a}{c}\\right) = \\log_{b}(a) - \\log_{b}(c) $$\n",
    "\n",
    "gives a simplification when we compute the log softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5b88d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return x - x.exp().sum(-1, keepdim=True).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7680a315",
   "metadata": {},
   "source": [
    "Then, there is a way to compute the log of the sum of exponentials in a more stable way, called the LogSumExp trick. The idea is to use the following formula\n",
    "\n",
    "$$ \\log\\left(\\sum_{i=1}^{n} e^{x_i}\\right) = a + \\log\\left(\\sum_{i=1}^{n} e^{x_i - a}\\right) $$\n",
    "\n",
    "where a is the maximum of the $x_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5726fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x):\n",
    "    m = x.max(-1)[0]\n",
    "    return m + (x - m[:, None]).exp().sum(-1).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9e58eb",
   "metadata": {},
   "source": [
    "This way, we will avoid an overflow when taking the exponential of a big activation. In PyTorch, this is already implemented for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf7475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return x - x.logsumexp(-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2692ddff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.34, -2.22, -2.05,  ..., -2.41, -2.57, -2.15],\n",
       "        [-2.37, -2.37, -2.03,  ..., -2.52, -2.53, -2.33],\n",
       "        [-2.45, -2.24, -2.15,  ..., -2.43, -2.51, -2.23],\n",
       "        ...,\n",
       "        [-2.39, -2.35, -2.02,  ..., -2.39, -2.54, -2.33],\n",
       "        [-2.53, -2.31, -2.09,  ..., -2.52, -2.51, -2.17],\n",
       "        [-2.38, -2.31, -2.26,  ..., -2.38, -2.42, -2.21]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_close(logsumexp(pred), pred.logsumexp(-1))\n",
    "sm_pred = log_softmax(pred)\n",
    "sm_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8299dc",
   "metadata": {},
   "source": [
    "The cross entropy loss for some target $x$ and some prediction $p(x)$ is given by:\n",
    "    $$-\\sum_{i=1}^{N} y_i \\cdot \\log(\\hat{y}_i)$$\n",
    "But since out $xs$ are 1-hot encoded, this can be written as $-log(p_i)$ where $i$ is the index of the desired target\n",
    "\n",
    "This can be done using numpy-style integer array indexing. Note that PyTorch supports all the tricks in the advanced indexing methods discussed in that link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8096ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 5, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124f3841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-2.40, grad_fn=<SelectBackward0>),\n",
       " tensor(-2.37, grad_fn=<SelectBackward0>),\n",
       " tensor(-2.26, grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred[0, 5], sm_pred[1, 0], sm_pred[2, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45264dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.57, -2.50, -2.15], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred[[0, 1, 2], y_train[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05db97ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target): return -input[range(target.shape[0]), target].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4fabe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.31, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nll(sm_pred, y_train)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce20b32a",
   "metadata": {},
   "source": [
    "Then use PyTorch's implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1c87d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(F.nll_loss(F.log_softmax(pred, -1), y_train), loss, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46f9d6b",
   "metadata": {},
   "source": [
    "In PyTorch, `F.log_softmax` and `F.nll_loss` are combined in one optimized function, `F.cross_entropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0621e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(F.cross_entropy(pred, y_train), loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccf2b5c",
   "metadata": {},
   "source": [
    "## Basic training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76337d6",
   "metadata": {},
   "source": [
    "Basically the training loop repeats over the following steps:\n",
    "\n",
    "    - get the output of the model on a batch of inputs\n",
    "    - compare the output to the labels we have and compute a loss\n",
    "    - calculate the gradients of the loss with repsect to every parameter of the model\n",
    "    - update said parameters with those gradients to make them a little bit better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ba94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931ef057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.02,  0.14,  0.32, -0.03,  0.07, -0.03,  0.07, -0.04, -0.21,  0.21], grad_fn=<SelectBackward0>),\n",
       " torch.Size([64, 10]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 64 # batch size\n",
    "\n",
    "xb = x_train[0:bs] # a mini-batch from x\n",
    "preds = model(xb)\n",
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bee46b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.32, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "loss_func(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5306c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 9, 5, 4, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 9, 2, 2, 4, 2, 2, 1,\n",
       "        2, 2, 4, 2, 2, 2, 2, 4, 4, 2, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2, 9, 9, 2, 2, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(preds, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfdaa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def accuracy(out, yb): return (torch.argmax(out, dim=1)==yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0a8c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.16)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fef2270",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1 # learning rate\n",
    "epochs = 3 # how many epochs to train for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80df3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def report(loss, preds, yb): print(f'{loss: .2f}, {accuracy(preds, yb): .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba6272b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2.32,  0.16\n"
     ]
    }
   ],
   "source": [
    "xb, yb = x_train[:bs], y_train[:bs]\n",
    "preds = model(xb)\n",
    "report(loss_func(preds, yb), preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5473666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.63,  1.00\n",
      " 0.42,  1.00\n",
      " 0.31,  1.00\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n, i + bs))\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for l in model.layers:\n",
    "                if hasattr(l, 'weight'):\n",
    "                    l.weight -= l.weight.grad * lr\n",
    "                    l.bias -= l.bias.grad * lr\n",
    "                    l.weight.grad.zero_()\n",
    "                    l.bias.grad.zero_()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b0c01a",
   "metadata": {},
   "source": [
    "## Using parameters and optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732b158d",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3555691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Module(\n",
       "  (foo): Linear(in_features=3, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = nn.Module()\n",
    "m1.foo = nn.Linear(3, 4)\n",
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b17f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('foo', Linear(in_features=3, out_features=4, bias=True))]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m1.named_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b66f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.named_children>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.named_children()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2445593f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.24, -0.11,  0.46],\n",
       "         [-0.17, -0.46, -0.07],\n",
       "         [-0.29,  0.31,  0.08],\n",
       "         [-0.24,  0.13, -0.17]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.01,  0.51, -0.11, -0.47], requires_grad=True)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85739801",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x): return self.l2(self.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b996781c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=50, bias=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP(m, nh, 10)\n",
    "model.l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004aa5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a87a7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1: Linear(in_features=784, out_features=50, bias=True)\n",
      "l2: Linear(in_features=50, out_features=10, bias=True)\n",
      "relu: ReLU()\n"
     ]
    }
   ],
   "source": [
    "for name, l in model.named_children(): print(f\"{name}: {l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7a45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters(): print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554efb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fedde16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, n, bs):\n",
    "            s = slice(i, min(n, i+bs))\n",
    "            xb, yb = x_train[s], y_train[s]\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters(): p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "        report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4ab345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.62,  1.00\n",
      " 0.40,  1.00\n",
      " 0.29,  1.00\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe11a1db",
   "metadata": {},
   "source": [
    "Behind the scenes, PyTorch overrides the `__setattr__` function in `nn.Module` so that submodules you define are properly registerd as parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc1b8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule:\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        self._modules = {}\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "    \n",
    "    def __setattr__(self, k, v):\n",
    "        if not k.startswith(\"_\"): self._modules[k] = v\n",
    "        super().__setattr__(k, v)\n",
    "    \n",
    "    def __repr__(self): return f'{self._modules}'\n",
    "    \n",
    "    def parameters(self):\n",
    "        for l in self._modules.values():\n",
    "            # for p in l.parameters(): yield p\n",
    "            yield from l.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493d0d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = MyModule(m, nh, 10)\n",
    "mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644a65df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in mdl.parameters(): print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eb9da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule:\n",
    "    def __init__(self):\n",
    "        self._modules = {}\n",
    "    \n",
    "    def __setattr__(self, k, v):\n",
    "        if not k.startswith(\"_\"): self._modules[k] = v\n",
    "        super().__setattr__(k, v)\n",
    "    \n",
    "    def __repr__(self): return f'{self._modules}'\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "    \n",
    "    def forward(self, x): raise Exception(\"Not implemented\")\n",
    "    \n",
    "    def parameters(self):\n",
    "        for l in self._modules.values():\n",
    "            yield from l.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55be5aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(MyModule):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.l2(self.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2138ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(m, nh, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9b8c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b9f889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(xb).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6644642",
   "metadata": {},
   "source": [
    "### Registering modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2071a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235663f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(lambda x, y: x + y, [1, 2, 3, 4, 5], 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b87e407",
   "metadata": {},
   "source": [
    "We can use the original `layers` approach, but we have to register the modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cd6bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=50, out_features=10, bias=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Linear(nh, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4370c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ff3079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg(x): return -x\n",
    "def exp(x): return np.exp(x)\n",
    "def log(x): return np.log(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7bc6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(lambda x, y: y(x), [neg, exp, log, neg], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fdfd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        for i, l in enumerate(self.layers): self.add_module(f'layer_{i}', l)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return reduce(lambda val, layer: layer(val), self.layers, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2a64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (layer_1): ReLU()\n",
       "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90925cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(xb).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34978ee2",
   "metadata": {},
   "source": [
    "## nn.ModuleList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e3c2bf",
   "metadata": {},
   "source": [
    "`nn.ModuleList` does this for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ca4378",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55e705c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialModel(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SequentialModel(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceabc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.66,  1.00\n",
      " 0.43,  1.00\n",
      " 0.33,  1.00\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a352817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.91), tensor(0.90))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model(x_train), y_train), accuracy(model(x_valid), y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c716066d",
   "metadata": {},
   "source": [
    "## nn.Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fd68d7",
   "metadata": {},
   "source": [
    "`nn.Sequential` is a convenient class which does the same as the above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f481ded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(784, nh), nn.ReLU(), nn.Linear(nh, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef818ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.73,  0.67\n",
      " 0.53,  1.00\n",
      " 0.39,  1.00\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f73abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.25, grad_fn=<NllLossBackward0>), tensor(1.))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ff882f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deeee11",
   "metadata": {},
   "source": [
    "## optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fcf3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, params, lr=0.5): \n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "    \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params: p -= p.grad * self.lr\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for p in self.params: p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b1942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069a9713",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimizer(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc42d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2.20,  0.33\n",
      " 1.46,  0.67\n",
      " 0.84,  0.67\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, x_train.shape[0], bs):\n",
    "        s = slice(i, i + bs)\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399574c8",
   "metadata": {},
   "source": [
    "PyTorch already provides this exact functionality in `optim.SGD` (it also handles stiff like momentum, which we'll look at later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a805a762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dbdd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eda47d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.42, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "loss_func(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac874af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.65,  1.00\n",
      " 0.38,  1.00\n",
      " 0.25,  1.00\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, x_train.shape[0], bs):\n",
    "        s = slice(i, i + bs)\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846f4dfe",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7761bc0d",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f680cfb5",
   "metadata": {},
   "source": [
    "It's clunky to iterate through minibatches of x and y values seperately:\n",
    "\n",
    "    xb = x_train[s]\n",
    "    yb = y_train[s]\n",
    "\n",
    "Instead, lets do these two steps together by introducing a `Dataset` class:\n",
    "    \n",
    "    xb,yb = train_ds[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2bcbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Dataset:\n",
    "    def __init__(self, x, y): self.x, self.y = x, y\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __getitem__(self, i): return self.x[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee849d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_valid, y_valid)\n",
    "assert len(train_ds) == len(x_train)\n",
    "assert len(valid_ds) == len(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfd1e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.00, 1.00, 1.00,  ..., 1.00, 1.00, 1.00],\n",
       "         [0.85, 1.00, 1.00,  ..., 0.00, 0.00, 0.00],\n",
       "         [0.00, 0.00, 0.00,  ..., 0.00, 0.00, 0.00],\n",
       "         [0.00, 0.00, 0.00,  ..., 0.00, 0.00, 0.00],\n",
       "         [0.43, 1.00, 0.99,  ..., 0.00, 0.00, 0.00]]),\n",
       " tensor([8, 5, 2, 6, 5]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = train_ds[0:5]\n",
    "assert xb.shape == (5, 28 * 28)\n",
    "assert yb.shape == (5,)\n",
    "xb, yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0218c01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.19,  1.00\n",
      " 0.14,  1.00\n",
      " 0.12,  1.00\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(train_ds), bs):\n",
    "        xb, yb = train_ds[i: i + bs]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e346364",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c903ab4f",
   "metadata": {},
   "source": [
    "Previously, our loop iterated over batches (xb, yb) like this:\n",
    "    \n",
    "    for i in range(0, n, bs):\n",
    "        xb, yb = train_ds[i: i + bs]\n",
    "        ...\n",
    "    \n",
    "Let's make out loop much cleaner, using a data loader:\n",
    "    \n",
    "    for xb, yb in train_dl:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3f2e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, ds, bs): self.ds, self.bs = ds, bs\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.ds), self.bs): yield self.ds[i: i + self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8551e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs)\n",
    "valid_dl = DataLoader(valid_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc54fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 784])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(valid_dl))\n",
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb07c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 5, 0, 0, 9, 9, 7, 4, 4, 6, 2, 4, 7, 5, 8, 3, 1, 9, 0, 3, 1, 0, 1, 3, 3, 2, 2, 0, 5, 2, 7, 5, 1, 2, 1, 8, 1, 2, 7,\n",
       "        6, 1, 2, 5, 9, 4, 1, 9, 0, 2, 6, 7, 9, 7, 0, 1, 0, 3, 3, 7, 5, 9, 5, 0, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a781658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xb[6].view(28, 28))\n",
    "char(yb[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079e2e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53886f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in train_dl:\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268ad27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.70,  1.00\n",
      " 0.45,  1.00\n",
      " 0.31,  1.00\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6013e05e",
   "metadata": {},
   "source": [
    "### Random Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136ad4cd",
   "metadata": {},
   "source": [
    "We want our training set to be in random order, and that order should differ each iteration. But the validation set should not be randomized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562ce871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c434512",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler():\n",
    "    def __init__(self, ds, shuffle=False): self.n, self.shuffle = len(ds), shuffle\n",
    "    def __iter__(self):\n",
    "        res = list(range(self.n))\n",
    "        if self.shuffle: random.shuffle(res)\n",
    "        return iter(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c2e1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1283b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = Sampler(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8754c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "it = iter(ss)\n",
    "for _ in range(5): print(next(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6740995f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(islice(ss, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f5d0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6243, 6451, 7888, 2292, 8679]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = Sampler(train_ds, shuffle=True)\n",
    "list(islice(ss, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b89ed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastcore.all as fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7929f90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSampler:\n",
    "    def __init__(self, sampler, bs, drop_last=False):\n",
    "        fc.store_attr()\n",
    "    \n",
    "    def __iter__(self): yield from fc.chunked(iter(self.sampler), self.bs, drop_last=self.drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c94575",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchs = BatchSampler(ss, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db162b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13386, 2469, 8504, 10104]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(batchs)\n",
    "next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f040748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4734, 6530, 8349, 1465],\n",
       " [6935, 10705, 9002, 14164],\n",
       " [13897, 14864, 8347, 8576],\n",
       " [14623, 8052, 12372, 13652],\n",
       " [6247, 5697, 9023, 10904]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(islice(batchs, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8b55b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(b):\n",
    "    xs, ys = zip(*b)\n",
    "    return torch.stack(xs), torch.stack(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cb32fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, ds, batchs, collate_fn=collate): fc.store_attr()\n",
    "    def __iter__(self): yield from (self.collate_fn(self.ds[i] for i in b) for b in self.batchs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3936454",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = BatchSampler(Sampler(train_ds, shuffle=True), bs)\n",
    "valid_samp = BatchSampler(Sampler(valid_ds, shuffle=False), bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adb2a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batchs=train_samp, collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, batchs=valid_samp, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d527229",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7853865a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAb0ElEQVR4nO3dfWyV5f3H8c9paY+gbVkpfTijsIIPbAJdZNA1KsPRUOpiRMnm0x9gFKI7NYPOabqoKFvSDRPHNBX+2KQzEZ8SgWgWNqi2xK2wUCWEORva1FEGLZOEPgGl9Fy/PwhnvwPl4T6c02/P4f1K7qTn3Ne395erd8+Hu+fuVZ9zzgkAgBGWYt0AAODaRAABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADAxBjrBs4XCoV0+PBhZWRkyOfzWbcDAPDIOafe3l4FAgGlpFz8OmfUBdDhw4dVWFho3QYA4Cp1dHRo0qRJF90/6gIoIyNDkvSHP/xB48aNu+K6aEJr7969nmskeerrnGhWPIrmCpCrxrOYB1gZqe/1vr4+zzWSdN9993mu+etf/+pp/MmTJxUMBsOv5xcTtwCqra3Vyy+/rM7OThUXF+u1117T3LlzL1t37gsxbtw4Ty/0N9xwg+cex44d67lGIoASAfMAKyP1vT40NOS5RpIyMzM910Tzmidd/t8Vl5sQ3n33XVVVVWn16tX67LPPVFxcrPLych09ejQehwMAJKC4BNArr7yi5cuX69FHH9V3vvMdbdiwQePGjdMbb7wRj8MBABJQzAPo9OnTam5uVllZ2f8OkpKisrIyNTU1XTB+YGBAPT09ERsAIPnFPIC+/vprDQ0NKS8vL+L5vLw8dXZ2XjC+pqZGWVlZ4Y074ADg2mD+i6jV1dXq7u4Obx0dHdYtAQBGQMzvgsvJyVFqaqq6uroinu/q6lJ+fv4F4/1+v/x+f6zbAACMcjG/AkpPT9fs2bNVX18ffi4UCqm+vl6lpaWxPhwAIEHF5feAqqqqtHTpUn3ve9/T3LlztW7dOvX39+vRRx+Nx+EAAAkoLgH0wAMP6L///a9eeOEFdXZ26rvf/a62bdt2wY0JAIBrV9xWQqisrFRlZWXU9SkpKZdcxO58q1at8nyMhoYGzzWSPPV1TigUiupYAJJfamqq55poV0L45z//6blmzpw5nsZf6eud+V1wAIBrEwEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABNxW4x0pEWzmF+0xozxPm2nT5/2XBMIBDzX3HHHHZ5rollcVYpuHqI5VjRf27S0NM81kuTz+UakxjnnuWYkjeb+RrK3kVpEOJrvi6+//jqqY/3oRz/yXOP1L1Vf6esdV0AAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABNJsxr20NDQiB0rmtWPoxEMBj3XRLMa9saNGz3XSFJWVpbnmmhWBY9mReJoVzEeHByMqi7ZRLtC+kgYyd6iOdZIvT5MnDgxqrotW7Z4rtm5c6en8Vf6ejx6zzIAQFIjgAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgImkWI01Gqampnmvq6upGpEaKbqHGaBcJBZB8uAICAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABggsVIRzGfz+e5JjMzMw6dDC8tLc1zzZkzZ+LQCYB48rqIsHPuisZxBQQAMEEAAQBMxDyAXnzxRfl8voht+vTpsT4MACDBxeU9oFtvvVU7duz430HG8FYTACBSXJJhzJgxys/Pj8enBgAkibi8B3TgwAEFAgFNnTpVjzzyiA4ePHjRsQMDA+rp6YnYAADJL+YBVFJSorq6Om3btk3r169Xe3u77rzzTvX29g47vqamRllZWeGtsLAw1i0BAEahmAdQRUWFfvzjH2vWrFkqLy/Xn//8Zx0/flzvvffesOOrq6vV3d0d3jo6OmLdEgBgFIr73QHjx4/XzTffrNbW1mH3+/1++f3+eLcBABhl4v57QH19fWpra1NBQUG8DwUASCAxD6Cnn35ajY2N+uqrr/T3v/9d9913n1JTU/XQQw/F+lAAgAQW8x/BHTp0SA899JCOHTumiRMn6o477tCuXbs0ceLEWB8KAJDAYh5A77zzTqw/JTwYycU+oznW0NBQHDoBkIhYCw4AYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACbGWDeAi3POea5JSRm5/1OkpqaO2LGAROHz+TzXDA0Nea6J5vVhtOEKCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkWI00yfX19I3asM2fOeK4JhUJx6ARAIuIKCABgggACAJjwHEA7d+7UPffco0AgIJ/Ppy1btkTsd87phRdeUEFBgcaOHauysjIdOHAgVv0CAJKE5wDq7+9XcXGxamtrh92/du1avfrqq9qwYYN2796t66+/XuXl5Tp16tRVNwsASB6eb0KoqKhQRUXFsPucc1q3bp2ee+453XvvvZKkN998U3l5edqyZYsefPDBq+sWAJA0YvoeUHt7uzo7O1VWVhZ+LisrSyUlJWpqahq2ZmBgQD09PREbACD5xTSAOjs7JUl5eXkRz+fl5YX3na+mpkZZWVnhrbCwMJYtAQBGKfO74Kqrq9Xd3R3eOjo6rFsCAIyAmAZQfn6+JKmrqyvi+a6urvC+8/n9fmVmZkZsAIDkF9MAKioqUn5+vurr68PP9fT0aPfu3SotLY3loQAACc7zXXB9fX1qbW0NP25vb9fevXuVnZ2tyZMna+XKlfr1r3+tm266SUVFRXr++ecVCAS0ePHiWPYNAEhwngNoz549uuuuu8KPq6qqJElLly5VXV2dnnnmGfX392vFihU6fvy47rjjDm3btk3XXXdd7LoGACQ8zwE0f/58Oecuut/n82nNmjVas2bNVTUGqbe313PN448/7rlmwoQJnmuks7fYe8VipEgkl3qtu5iMjAzPNevWrfNcE+0NWz6fz3NNNPNwJczvggMAXJsIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACY8r4YNaXBwcESO8/vf/95zzbZt2zzXpKameq4BEklaWlpUdf/5z38816xfv95zTUlJiecaVsMGACBKBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATLAY6SjW19fnuaa5uTkOnQCJLT09Paq606dPe66JZpHQa3VBYK6AAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmGAx0iiMGeN92qJZ1PAnP/mJ55rHH3/cc82XX37puUaKfoFHYKT5fL6o6k6cOOG55rbbbvNc88Ybb3iuSQZcAQEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADDBYqRRiHZhQ69mz57tuWb79u2ea15++WXPNZKUkZHhuSYUCkV1LMBCNN/r0Sw8HE1NtEbT9yBXQAAAEwQQAMCE5wDauXOn7rnnHgUCAfl8Pm3ZsiVi/7Jly+Tz+SK2RYsWxapfAECS8BxA/f39Ki4uVm1t7UXHLFq0SEeOHAlvb7/99lU1CQBIPp5vQqioqFBFRcUlx/j9fuXn50fdFAAg+cXlPaCGhgbl5ubqlltu0ZNPPqljx45ddOzAwIB6enoiNgBA8ot5AC1atEhvvvmm6uvr9dvf/laNjY2qqKjQ0NDQsONramqUlZUV3goLC2PdEgBgFIr57wE9+OCD4Y9nzpypWbNmadq0aWpoaNCCBQsuGF9dXa2qqqrw456eHkIIAK4Bcb8Ne+rUqcrJyVFra+uw+/1+vzIzMyM2AEDyi3sAHTp0SMeOHVNBQUG8DwUASCCefwTX19cXcTXT3t6uvXv3Kjs7W9nZ2XrppZe0ZMkS5efnq62tTc8884xuvPFGlZeXx7RxAEBi8xxAe/bs0V133RV+fO79m6VLl2r9+vXat2+f/vSnP+n48eMKBAJauHChfvWrX8nv98euawBAwvMcQPPnz5dz7qL7//KXv1xVQ/ifi905eCkjeRt7f3+/55rRtBAiAFusBQcAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMBHzP8mN2ElNTfVcM2bMyH1JfT7fiB0LQPLhCggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGDCUwDV1NRozpw5ysjIUG5urhYvXqyWlpaIMadOnVIwGNSECRN0ww03aMmSJerq6opp0wCAxOcpgBobGxUMBrVr1y5t375dg4ODWrhwofr7+8NjVq1apQ8//FDvv/++GhsbdfjwYd1///0xbxwAkNjGeBm8bdu2iMd1dXXKzc1Vc3Oz5s2bp+7ubv3xj3/Upk2b9MMf/lCStHHjRn3729/Wrl279P3vfz92nQMAEtpVvQfU3d0tScrOzpYkNTc3a3BwUGVlZeEx06dP1+TJk9XU1DTs5xgYGFBPT0/EBgBIflEHUCgU0sqVK3X77bdrxowZkqTOzk6lp6dr/PjxEWPz8vLU2dk57OepqalRVlZWeCssLIy2JQBAAok6gILBoPbv36933nnnqhqorq5Wd3d3eOvo6LiqzwcASAye3gM6p7KyUh999JF27typSZMmhZ/Pz8/X6dOndfz48YiroK6uLuXn5w/7ufx+v/x+fzRtAAASmKcrIOecKisrtXnzZn388ccqKiqK2D979mylpaWpvr4+/FxLS4sOHjyo0tLS2HQMAEgKnq6AgsGgNm3apK1btyojIyP8vk5WVpbGjh2rrKwsPfbYY6qqqlJ2drYyMzP11FNPqbS0lDvgAAARPAXQ+vXrJUnz58+PeH7jxo1atmyZJOl3v/udUlJStGTJEg0MDKi8vFyvv/56TJoFACQPTwHknLvsmOuuu061tbWqra2NuikAQPJjLTgAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgImo/iIqRq8xY0buSzqSxwKQOJxzCoVClx3HFRAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATrCY5ijnnPNf09PTEoZPhDQ4Oeq65kgUKAVwbuAICAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABggsVIR7GhoSHPNcuWLfNck5IS3f9DsrOzPdecOXMmqmMBSBwDAwN6/fXXLzuOKyAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmkmYx0jFjRu6f4pwbkeO88sornmt27NjhuSbaxUi/+uqrqOoAXD2fzxdV3YkTJzzXvPXWW57G9/b2shgpAGD0IoAAACY8BVBNTY3mzJmjjIwM5ebmavHixWppaYkYM3/+fPl8vojtiSeeiGnTAIDE5ymAGhsbFQwGtWvXLm3fvl2Dg4NauHCh+vv7I8YtX75cR44cCW9r166NadMAgMTn6Z37bdu2RTyuq6tTbm6umpubNW/evPDz48aNU35+fmw6BAAkpat6D6i7u1vShX+a+a233lJOTo5mzJih6urqS951MTAwoJ6enogNAJD8or53ORQKaeXKlbr99ts1Y8aM8PMPP/ywpkyZokAgoH379unZZ59VS0uLPvjgg2E/T01NjV566aVo2wAAJKioAygYDGr//v369NNPI55fsWJF+OOZM2eqoKBACxYsUFtbm6ZNm3bB56murlZVVVX4cU9PjwoLC6NtCwCQIKIKoMrKSn300UfauXOnJk2adMmxJSUlkqTW1tZhA8jv98vv90fTBgAggXkKIOecnnrqKW3evFkNDQ0qKiq6bM3evXslSQUFBVE1CABITp4CKBgMatOmTdq6dasyMjLU2dkpScrKytLYsWPV1tamTZs26e6779aECRO0b98+rVq1SvPmzdOsWbPi8g8AACQmTwG0fv16SWd/2fT/27hxo5YtW6b09HTt2LFD69atU39/vwoLC7VkyRI999xzMWsYAJAcPP8I7lIKCwvV2Nh4VQ0BAK4NSbMa9pkzZ5LuWMeOHfNc88knn8ShEwCjTWpqalR1Q0NDnmu++OILT+OvdMVtFiMFAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgYtQuRhoKhRQKha54/Jo1azwfY8+ePZ5rJOn666/3XHO5lcSH4/P5RqQGQOJJSYnu+uHkyZOea+6++25P43t6eq5oHFdAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADAx6taCO7dm2okTJzzV+f1+z8c6deqU5xopujWYWAsOQCyN5FpwV7q22/njL/e653PRvDLG0aFDh1RYWGjdBgDgKnV0dGjSpEkX3T/qAigUCunw4cPKyMi44H/zPT09KiwsVEdHhzIzM406tMc8nMU8nMU8nMU8nDUa5sE5p97eXgUCgUteqY26H8GlpKRcMjElKTMz85o+wc5hHs5iHs5iHs5iHs6ynoesrKzLjuEmBACACQIIAGAioQLI7/dr9erVUd3xlkyYh7OYh7OYh7OYh7MSaR5G3U0IAIBrQ0JdAQEAkgcBBAAwQQABAEwQQAAAEwkTQLW1tfrWt76l6667TiUlJfrHP/5h3dKIe/HFF+Xz+SK26dOnW7cVdzt37tQ999yjQCAgn8+nLVu2ROx3zumFF15QQUGBxo4dq7KyMh04cMCm2Ti63DwsW7bsgvNj0aJFNs3GSU1NjebMmaOMjAzl5uZq8eLFamlpiRhz6tQpBYNBTZgwQTfccIOWLFmirq4uo47j40rmYf78+RecD0888YRRx8NLiAB69913VVVVpdWrV+uzzz5TcXGxysvLdfToUevWRtytt96qI0eOhLdPP/3UuqW46+/vV3FxsWpra4fdv3btWr366qvasGGDdu/ereuvv17l5eVRLzY7Wl1uHiRp0aJFEefH22+/PYIdxl9jY6OCwaB27dql7du3a3BwUAsXLlR/f394zKpVq/Thhx/q/fffV2Njow4fPqz777/fsOvYu5J5kKTly5dHnA9r16416vgiXAKYO3euCwaD4cdDQ0MuEAi4mpoaw65G3urVq11xcbF1G6Ykuc2bN4cfh0Ihl5+f715++eXwc8ePH3d+v9+9/fbbBh2OjPPnwTnnli5d6u69916TfqwcPXrUSXKNjY3OubNf+7S0NPf++++Hx/zrX/9yklxTU5NVm3F3/jw459wPfvAD97Of/cyuqSsw6q+ATp8+rebmZpWVlYWfS0lJUVlZmZqamgw7s3HgwAEFAgFNnTpVjzzyiA4ePGjdkqn29nZ1dnZGnB9ZWVkqKSm5Js+PhoYG5ebm6pZbbtGTTz6pY8eOWbcUV93d3ZKk7OxsSVJzc7MGBwcjzofp06dr8uTJSX0+nD8P57z11lvKycnRjBkzVF1d7fnP3MTbqFuM9Hxff/21hoaGlJeXF/F8Xl6evvzyS6OubJSUlKiurk633HKLjhw5opdeekl33nmn9u/fr4yMDOv2THR2dkrSsOfHuX3XikWLFun+++9XUVGR2tra9Mtf/lIVFRVqampSamqqdXsxFwqFtHLlSt1+++2aMWOGpLPnQ3p6usaPHx8xNpnPh+HmQZIefvhhTZkyRYFAQPv27dOzzz6rlpYWffDBB4bdRhr1AYT/qaioCH88a9YslZSUaMqUKXrvvff02GOPGXaG0eDBBx8Mfzxz5kzNmjVL06ZNU0NDgxYsWGDYWXwEg0Ht37//mngf9FIuNg8rVqwIfzxz5kwVFBRowYIFamtr07Rp00a6zWGN+h/B5eTkKDU19YK7WLq6upSfn2/U1egwfvx43XzzzWptbbVuxcy5c4Dz40JTp05VTk5OUp4flZWV+uijj/TJJ59E/PmW/Px8nT59WsePH48Yn6znw8XmYTglJSWSNKrOh1EfQOnp6Zo9e7bq6+vDz4VCIdXX16u0tNSwM3t9fX1qa2tTQUGBdStmioqKlJ+fH3F+9PT0aPfu3df8+XHo0CEdO3Ysqc4P55wqKyu1efNmffzxxyoqKorYP3v2bKWlpUWcDy0tLTp48GBSnQ+Xm4fh7N27V5JG1/lgfRfElXjnnXec3+93dXV17osvvnArVqxw48ePd52dndatjaif//znrqGhwbW3t7u//e1vrqyszOXk5LijR49atxZXvb297vPPP3eff/65k+ReeeUV9/nnn7t///vfzjnnfvOb37jx48e7rVu3un379rl7773XFRUVuZMnTxp3HluXmofe3l739NNPu6amJtfe3u527NjhbrvtNnfTTTe5U6dOWbceM08++aTLyspyDQ0N7siRI+HtxIkT4TFPPPGEmzx5svv444/dnj17XGlpqSstLTXsOvYuNw+tra1uzZo1bs+ePa69vd1t3brVTZ061c2bN8+480gJEUDOOffaa6+5yZMnu/T0dDd37ly3a9cu65ZG3AMPPOAKCgpcenq6++Y3v+keeOAB19raat1W3H3yySdO0gXb0qVLnXNnb8V+/vnnXV5envP7/W7BggWupaXFtuk4uNQ8nDhxwi1cuNBNnDjRpaWluSlTprjly5cn3X/Shvv3S3IbN24Mjzl58qT76U9/6r7xjW+4cePGufvuu88dOXLEruk4uNw8HDx40M2bN89lZ2c7v9/vbrzxRveLX/zCdXd32zZ+Hv4cAwDAxKh/DwgAkJwIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCY+D990O9fXmwJUQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xb[0].view(28, 28))\n",
    "char(yb[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6e8e07",
   "metadata": {},
   "source": [
    "## Multiprocessing DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29701fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp\n",
    "from fastcore.basics import store_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16c8ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.00, 0.00, 0.00,  ..., 0.00, 0.00, 0.00],\n",
       "         [0.25, 0.63, 0.99,  ..., 0.00, 0.00, 0.00],\n",
       "         [0.00, 0.00, 0.00,  ..., 0.00, 0.00, 0.00],\n",
       "         [0.85, 1.00, 1.00,  ..., 0.00, 0.00, 0.00]]),\n",
       " tensor([6, 3, 4, 5]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[[3, 6, 8, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c22529e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.00, 0.00, 0.00,  ..., 0.00, 0.00, 0.00],\n",
       "         [0.25, 0.63, 0.99,  ..., 0.00, 0.00, 0.00],\n",
       "         [0.00, 0.00, 0.00,  ..., 0.00, 0.00, 0.00],\n",
       "         [0.85, 1.00, 1.00,  ..., 0.00, 0.00, 0.00]]),\n",
       " tensor([6, 3, 4, 5]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.__getitem__([3, 6, 8, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fcc4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0.00, 0.00, 0.00,  ..., 0.00, 0.00, 0.00],\n",
      "        [0.25, 0.63, 0.99,  ..., 0.00, 0.00, 0.00]]), tensor([6, 3]))\n",
      "(tensor([[0.00, 0.00, 0.00,  ..., 0.00, 0.00, 0.00],\n",
      "        [0.85, 1.00, 1.00,  ..., 0.00, 0.00, 0.00]]), tensor([4, 5]))\n"
     ]
    }
   ],
   "source": [
    "for o in map(train_ds.__getitem__, ([3, 6], [8, 1])): print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70edafb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, ds, batchs, n_workers=1, collate_fn=collate): fc.store_attr()\n",
    "    def __iter__(self):\n",
    "        with mp.Pool(self.n_workers) as ex: yield from ex.map(self.ds.__getitem__, self.batchs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055b42eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batchs=train_samp, n_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50508ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 784]), torch.Size([64]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(train_dl)\n",
    "xb, yb= next(it)\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a009b2a",
   "metadata": {},
   "source": [
    "## Pytorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba6fcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler, BatchSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57eb1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = BatchSampler(RandomSampler(train_ds), bs, drop_last=False)\n",
    "valid_samp = BatchSampler(SequentialSampler(valid_ds), bs, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988d1141",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_sampler=train_samp)\n",
    "valid_dl = DataLoader(valid_ds, batch_sampler=valid_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3696981e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.07,  1.00\n",
      " 1.15,  0.67\n",
      " 2.95,  0.33\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.91, grad_fn=<NllLossBackward0>), tensor(0.73))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "fit()\n",
    "loss_func(model(x_train), y_train), accuracy(model(x_train), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39e4b3a",
   "metadata": {},
   "source": [
    "PyTorch can auto-generate the BatchSampler for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1938331",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, sampler=RandomSampler(train_ds), collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, bs, sampler=SequentialSampler(valid_ds), collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d8e0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 784]), torch.Size([64]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(train_dl))\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4c708b",
   "metadata": {},
   "source": [
    "PyTorch can also generate the Sequential/RandomSamplers too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fc1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, shuffle=True, num_workers=2)\n",
    "valid_dl = DataLoader(valid_ds, bs, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af7a3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 784]), torch.Size([64]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(train_dl))\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c335cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.08,  1.00\n",
      " 0.15,  1.00\n",
      " 0.07,  1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.34, grad_fn=<NllLossBackward0>), tensor(0.90))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "fit()\n",
    "\n",
    "loss_func(model(x_train), y_train), accuracy(model(x_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da691771",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, sampler=train_samp)\n",
    "valid_dl = DataLoader(valid_ds, sampler=valid_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1400575e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64, 784]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(train_dl))\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b973f37f",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98ff81d",
   "metadata": {},
   "source": [
    "You always should also have a validation set, in order to identify if you are overfitting.\n",
    "\n",
    "We will calculate and print the validation loss at the end of each epoch.\n",
    "\n",
    "(Note that we always call `model.train()` before training, and `model.eval()` before inference, because these are used by layers such as `nn.BatchNorm2d` and `nn.Dropout` to ensure appropriate behaviour for these different phases.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046a22f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss = loss_func(model(xb), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            tot_loss, tot_acc, count = 0., 0., 0.\n",
    "            for xb, yb in valid_dl:\n",
    "                pred = model(xb)\n",
    "                n = len(xb)\n",
    "                count += n\n",
    "                tot_loss += loss_func(pred, yb).item() * n\n",
    "                tot_acc += accuracy(pred, yb).item() * n\n",
    "        print(epoch, tot_loss/count, tot_acc/count)\n",
    "    return tot_loss/count, tot_acc/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d18961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
    "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
    "            DataLoader(valid_ds, batch_size=bs*2, **kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c883e391",
   "metadata": {},
   "source": [
    "Now, our whole process of obtaining the data loaders and fitting the model can be run in 3 lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ecdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.4708721767280385 0.8777036050133139\n",
      "1 0.6877785293377926 0.7898531377076784\n",
      "2 0.41901151605537323 0.8726301737875741\n",
      "3 0.36406891479670445 0.900400534268215\n",
      "4 0.34689619346995537 0.9025367158436489\n"
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl = get_dls(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()\n",
    "loss, acc = fit(5, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561d91a5",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e13360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev import nbdev_export; nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18ccdc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
