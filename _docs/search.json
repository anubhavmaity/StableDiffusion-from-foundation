[
  {
    "objectID": "meanshift_practice.html",
    "href": "meanshift_practice.html",
    "title": "Meanshift Practice",
    "section": "",
    "text": "import numpy as np\nimport math\nfrom math import pi\nimport torch\nfrom matplotlib import pyplot as plt\nfrom torch.distributions import MultivariateNormal"
  },
  {
    "objectID": "meanshift_practice.html#gpu-batched-algorithm",
    "href": "meanshift_practice.html#gpu-batched-algorithm",
    "title": "Meanshift Practice",
    "section": "GPU Batched algorithm",
    "text": "GPU Batched algorithm\n\nbs = 5\nX = data.clone()\nx = X[:bs]\nx.shape, X.shape\n\n(torch.Size([5, 2]), torch.Size([1500, 2]))\n\n\n\ndist = ((x[:,None] - X[None]) ** 2).sum(-1).sqrt()\ndist.shape, dist\n\n(torch.Size([5, 1500]),\n tensor([[  0.00000,   2.96982,   3.36906,  ..., 209.04686, 210.20853, 209.90276],\n         [  2.96982,   0.00000,   4.58362,  ..., 208.38335, 209.50293, 209.21017],\n         [  3.36906,   4.58362,   0.00000,  ..., 212.35605, 213.50829, 213.20551],\n         [  3.42341,   1.80829,   3.42423,  ..., 210.16139, 211.27600, 210.98482],\n         [  2.33995,   1.62542,   2.96569,  ..., 209.84781, 210.97752, 210.68167]]))\n\n\n\nweight = gaussian(dist)\nweight\n\ntensor([[0.15958, 0.07880, 0.06436,  ..., 0.00000, 0.00000, 0.00000],\n        [0.07880, 0.15958, 0.02972,  ..., 0.00000, 0.00000, 0.00000],\n        [0.06436, 0.02972, 0.15958,  ..., 0.00000, 0.00000, 0.00000],\n        [0.06249, 0.12285, 0.06246,  ..., 0.00000, 0.00000, 0.00000],\n        [0.10298, 0.12917, 0.07896,  ..., 0.00000, 0.00000, 0.00000]])\n\n\n\nweight.shape\n\ntorch.Size([5, 1500])\n\n\n\n(weight @ X).shape\n\ntorch.Size([5, 2])\n\n\n\nweight.sum(1, keepdims=True).shape\n\ntorch.Size([5, 1])\n\n\n\nfor i in range(0, 10, 2):\n    print(i)\n\n0\n2\n4\n6\n8\n\n\n\ndef one_update(X, bs):\n    n = len(X)\n    for i in range(0, n, bs):\n        s = slice(i, min(i+bs, n))\n        x = X[s]\n        dist = ((x[:,None] - X[None]) ** 2).sum(-1).sqrt()\n        weight = gaussian(dist)\n        X[s] = (weight @ X)/ (weight.sum(1, keepdims=True))\n\n\ndef meanshift(data, bs=16):\n    X = data.clone()\n    for i in range(10): one_update(X, bs)\n    return X\n\n\ndata = data.cuda()\n\n48.1 ms ± 543 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\n\n\n\n4.4 ms ± 1.93 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\n\nX\n\ntensor([[ -28.43384, -102.60363],\n        [ -28.43384, -102.60363],\n        [ -28.43384, -102.60363],\n        ...,\n        [ -26.46349,  106.65351],\n        [ -26.46349,  106.65351],\n        [ -26.46349,  106.65351]])\n\n\n\nplot_data(centroids +5, X)"
  },
  {
    "objectID": "matmul.html",
    "href": "matmul.html",
    "title": "Matrix Multiplication from foundations",
    "section": "",
    "text": "The foundations we will assume throughout this course are - Python - Matplotlib - Python stdlib - Jupyter notebooks and nbdev\nThe dataset we will use for learning fastai part 2 is Kushiji MNIST (KMNIST)"
  },
  {
    "objectID": "matmul.html#what-is-kmnist",
    "href": "matmul.html#what-is-kmnist",
    "title": "Matrix Multiplication from foundations",
    "section": "What is KMNIST?",
    "text": "What is KMNIST?\nThe characters in the KMNIST dataset represent handwritten Kuzushiji characters from the historical Japanese script. Kuzushiji is a script that was widely used in Japan until the early 20th century. The goal of the KMNIST dataset is to provide a modern machine learning benchmark for recognizing and preserving these handwritten characters.\nThe KMNIST dataset consists of 10 classes, each representing a specific character from the Kuzushiji script. Here are the corresponding characters for each class:\n1. お (o)\n\n2. き (ki)\n\n3. す (su)\n\n4. つ (tsu)\n\n5. な (na)\n\n6. は (ha)\n\n7. ま (ma)\n\n8. や (ya)\n\n9. れ (re)\n\n10. を (wo)\nEach class represents a distinct character with its own unique shape and stroke patterns. By working with the KMNIST dataset, researchers and machine learning practitioners can develop models that recognize and classify these handwritten Kuzushiji characters, contributing to the understanding and preservation of this historical script."
  },
  {
    "objectID": "matmul.html#get-the-data-kmnist-dataset",
    "href": "matmul.html#get-the-data-kmnist-dataset",
    "title": "Matrix Multiplication from foundations",
    "section": "Get the Data (KMNIST Dataset)",
    "text": "Get the Data (KMNIST Dataset)\n\nThe repository for dataset is here. We will download the numpy format mentioned in the README of the repository.\n\n\nKMNIST_URL = 'http://codh.rois.ac.jp/kmnist/dataset/kmnist/'\n\n\npath_data = Path('data')\npath_data.mkdir(exist_ok=True)\n\n\ntrain_images_file = 'kmnist-train-imgs.npz'\ntrain_labels_file = 'kmnist-train-labels.npz'\ntest_images_file = 'kmnist-test-imgs.npz'\ntest_labels_file = 'kmnist-test-labels.npz'\n\nWe will use the library urlretrieve to retreive the data to the local\n\nfrom urllib.request import urlretrieve\n\n# Download the training image\nurlretrieve(KMNIST_URL + train_images_file, path_data/train_images_file)\nprint('Training image file downloaded.')\n\n# Download the training label file\nurlretrieve(KMNIST_URL + train_labels_file, path_data/train_labels_file)\nprint('Training label file downloaded.')\n\n# Download the test image file\nurlretrieve(KMNIST_URL + test_images_file, path_data/test_images_file)\nprint('Test image file downloaded.')\n\n# Download the test label file\nurlretrieve(KMNIST_URL + test_labels_file, path_data/test_labels_file)\nprint('Test label file downloaded.')\n\nTraining image file downloaded.\nTraining label file downloaded.\nTest image file downloaded.\nTest label file downloaded.\n\n\n\n!ls -l data\n\ntotal 21004\n-rw-rw-r-- 1 ubuntu ubuntu  3079479 Jun 11 17:28 kmnist-test-imgs.npz\n-rw-rw-r-- 1 ubuntu ubuntu     5304 Jun 11 17:28 kmnist-test-labels.npz\n-rw-rw-r-- 1 ubuntu ubuntu 18384171 Jun 11 17:28 kmnist-train-imgs.npz\n-rw-rw-r-- 1 ubuntu ubuntu    29700 Jun 11 17:28 kmnist-train-labels.npz\n\n\n\nimport numpy as np # using numpy for loading the data\n\n# File paths for the MNIST dataset\nx_train = np.load(path_data/train_images_file)['arr_0'].reshape(-1, 784)/255.0\nx_train = np.float32(x_train)\ny_train = np.load(path_data/train_labels_file)['arr_0']\nx_valid = np.load(path_data/test_images_file)['arr_0'].reshape(-1, 784)/255.0\nx_valid = np.float32(x_valid)\ny_valid = np.load(path_data/test_labels_file)['arr_0']\n\n\nlst1 = list(x_train[0])\nvals = lst1[200:210]\nvals\n\n[0.0, 0.0, 0.0, 0.8039216, 1.0, 0.69803923, 0.011764706, 0.0, 0.0, 0.003921569]\n\n\n\nlen(lst1)\n\n784\n\n\n\ndef chunks(x, sz):\n    for i in range(0, len(x), sz): yield x[i: i+sz]\n\n\nlist(chunks(vals, 5))\n\n[[0.0, 0.0, 0.0, 0.8039216, 1.0],\n [0.69803923, 0.011764706, 0.0, 0.0, 0.003921569]]\n\n\n\nval_iter = chunks(vals, 5)\n\n\nnext(val_iter)\n\n[0.0, 0.0, 0.0, 0.8039216, 1.0]\n\n\n\nnext(val_iter)\n\n[0.69803923, 0.011764706, 0.0, 0.0, 0.003921569]\n\n\n\nmpl.rcParams['image.cmap'] = 'gray'\nplt.imshow(list(chunks(lst1, 28)));\n\n\n\n\nSeeing the image I think it is re, lets confirm\n\ny_train[0]\n\n8\n\n\nIt is re! (The 8 represents the class re)\nislice\n\nfrom itertools import islice\n\n\nit = iter(vals)\n\n\nlist(islice(it, 5))\n\n[0.0, 0.0, 0.0, 0.8039216, 1.0]\n\n\n\nlist(islice(it, 5))\n\n[0.69803923, 0.011764706, 0.0, 0.0, 0.003921569]\n\n\nLets use next\n\nit = iter(vals)\nisit = islice(it, 5)\n\n\nnext(isit)\n\n0.0\n\n\n\nnext(isit)\n\n0.0\n\n\n\nnext(isit)\n\n0.0\n\n\n\nnext(isit)\n\n0.8039216\n\n\n\nnext(isit)\n\n1.0\n\n\nUsing the above code for islice and iter\n\nit = iter(lst1)\nimg = list(iter(lambda: list(islice(it, 28)), []))\n\n\nplt.imshow(img);"
  },
  {
    "objectID": "matmul.html#matrix-and-tensor",
    "href": "matmul.html#matrix-and-tensor",
    "title": "Matrix Multiplication from foundations",
    "section": "Matrix and tensor",
    "text": "Matrix and tensor\n\nimg[20][15]\n\n0.0\n\n\n\nclass Matrix:\n    def __init__(self, xs): self.xs = xs\n    def __getitem__(self, idxs): return self.xs[idxs[0]][idxs[1]]\n\n\nm = Matrix(img)\nm[20, 15]\n\n0.0\n\n\n\nimport torch\nfrom torch import tensor\n\n\ntensor([1, 2, 3])\n\ntensor([1, 2, 3])\n\n\n\nimg_tensor = tensor(img); img_tensor[20, 15]\n\ntensor(0.)\n\n\n\nx_train, y_train, x_valid, y_valid = map(tensor, (x_train, y_train, x_valid, y_valid))\n\n\nx_train.shape\n\ntorch.Size([60000, 784])\n\n\n\nx_train.type()\n\n'torch.FloatTensor'\n\n\nTensor\n\nimgs = x_train.reshape((-1, 28, 28))\nimgs.shape\n\ntorch.Size([60000, 28, 28])\n\n\n\nplt.imshow(imgs[0])\n\n<matplotlib.image.AxesImage>\n\n\n\n\n\n\nimgs[0].shape\n\ntorch.Size([28, 28])\n\n\n\nimgs[0, 20, 15]\n\ntensor(0.)\n\n\n\nn, c = x_train.shape\ny_train, y_train.shape\n\n(tensor([8, 7, 0,  ..., 0, 4, 9], dtype=torch.uint8), torch.Size([60000]))\n\n\n\nmin(y_train), max(y_train)\n\n(tensor(0, dtype=torch.uint8), tensor(9, dtype=torch.uint8))\n\n\n\ny_train.min(), y_train.max()\n\n(tensor(0, dtype=torch.uint8), tensor(9, dtype=torch.uint8))"
  },
  {
    "objectID": "matmul.html#random-numbers",
    "href": "matmul.html#random-numbers",
    "title": "Matrix Multiplication from foundations",
    "section": "Random Numbers",
    "text": "Random Numbers\nBased on the Wichmann Hill algo used before Python 2.3\n\nrnd_state = None\ndef seed(a):\n    global rnd_state\n    a, x = divmod(a, 30268)\n    a, y = divmod(a, 30306)\n    a, z = divmod(a, 30322)\n    rnd_state = int(x) + 1, int(y) + 1, int(z) + 1\n\n\nseed(78)\nrnd_state\n\n(79, 1, 1)\n\n\n\ndef rand():\n    global rnd_state\n    x, y, z = rnd_state\n    x = (171 * x) % 30269\n    y = (172 * y) % 30307\n    z = (170 * x) % 30323\n    rnd_state = x, y, z\n    return (x/30269 + y/30307 + z/30323) % 1.0\n\n\nrand(), rand(), rand()\n\n(0.18755370202551447, 0.08563584800214263, 0.967860810266028)\n\n\n\nif os.fork(): print(f'In parent: {rand()}')\nelse:\n    print(f'In child: {rand()}')\n    os._exit(os.EX_OK)\n\nIn parent: 0.9969053665691592\nIn child: 0.9969053665691592\n\n\n\nif os.fork(): print(f'In parent: {torch.rand(1)}')\nelse:\n    print(f'In child: {torch.rand(1)}')\n    os._exit(os.EX_OK)\n\nIn parent: tensor([0.8378])\nIn child: tensor([0.8378])\n\n\n\nif os.fork(): print(f'In parent: {np.random.rand(1)}')\nelse:\n    print(f'In child: {np.random.rand(1)}')\n    os._exit(os.EX_OK)\n\nIn parent: [0.37408799]\nIn child: [0.37408799]\n\n\n\nimport random\n\n\nif os.fork(): print(f'In parent: {random.random()}')\nelse:\n    print(f'In child: {random.random()}')\n    os._exit(os.EX_OK)\n\nIn parent: 0.8256941082748851\nIn child: 0.024069914563894512\n\n\n\nplt.plot([rand() for _ in range(50)])\n\n\n\n\n\nplt.hist([rand() for _ in range(10_000)])\n\n(array([1028.,  977.,  949., 1005., 1007., 1011.,  999., 1011.,  988.,\n        1025.]),\n array([4.00498918e-05, 1.00035217e-01, 2.00030384e-01, 3.00025551e-01,\n        4.00020718e-01, 5.00015885e-01, 6.00011052e-01, 7.00006219e-01,\n        8.00001386e-01, 8.99996553e-01, 9.99991720e-01]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n\n\n\n2.69 ms ± 31.5 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\n\n\n\n40.7 µs ± 10.5 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)"
  },
  {
    "objectID": "matmul.html#matrix-multiplication",
    "href": "matmul.html#matrix-multiplication",
    "title": "Matrix Multiplication from foundations",
    "section": "Matrix Multiplication",
    "text": "Matrix Multiplication\n\ntorch.manual_seed(1)\nweights = torch.randn(784, 10)\nbias = torch.zeros(10)\n\n\nm1 = x_valid[:5]\nm2 = weights\n\n\nm1.shape, m2.shape\n\n(torch.Size([5, 784]), torch.Size([784, 10]))\n\n\n\nar, ac = m1.shape\nbr, bc = m2.shape\n(ar, ac), (br, bc)\n\n((5, 784), (784, 10))\n\n\n\nt1 = torch.zeros(ar, bc)\nt1.shape\n\ntorch.Size([5, 10])\n\n\n\nfor i in range(ar): # 5\n    for j in range(bc): # 10\n        for k in range(ac): # 784\n            t1[i, j] += m1[i, k] * m2[k, j]\n\n\nt1\n\ntensor([[-3.0117e+00, -8.5644e+00, -9.2000e+00,  2.1133e+00,  3.1043e+01,\n          8.2828e+00, -2.3903e+01, -2.7770e+01,  6.2782e+00,  1.3998e+01],\n        [ 1.8971e+00, -1.6805e+01, -9.0493e+00, -3.1443e+00, -1.4109e+01,\n         -4.6473e+00, -3.5029e+01, -5.0467e+00, -1.0138e+01, -1.3681e+01],\n        [ 7.3971e+00, -9.9802e+00, -8.8278e+00,  3.3733e+00,  6.5050e+00,\n          2.2608e-02,  9.8208e-01, -1.0190e+01, -1.3008e+01,  4.4429e+00],\n        [ 1.0392e+01, -1.2656e+01, -1.7699e+01,  9.2111e+00,  2.2837e+01,\n          2.6548e+01, -1.6465e-01, -1.6619e+01, -1.0451e+01,  1.2815e+01],\n        [-1.2335e+01, -1.2113e+01, -5.0027e+00,  5.7400e+00, -7.7002e+00,\n          7.4970e+00, -2.3195e+00,  4.7629e-02, -3.2490e+01,  4.5530e+00]])\n\n\n\nt1.shape\n\ntorch.Size([5, 10])\n\n\n\ntorch.set_printoptions(precision=2, linewidth=200, sci_mode=False)\nt1\n\ntensor([[    -3.01,     -8.56,     -9.20,      2.11,     31.04,      8.28,    -23.90,    -27.77,      6.28,     14.00],\n        [     1.90,    -16.80,     -9.05,     -3.14,    -14.11,     -4.65,    -35.03,     -5.05,    -10.14,    -13.68],\n        [     7.40,     -9.98,     -8.83,      3.37,      6.50,      0.02,      0.98,    -10.19,    -13.01,      4.44],\n        [    10.39,    -12.66,    -17.70,      9.21,     22.84,     26.55,     -0.16,    -16.62,    -10.45,     12.81],\n        [   -12.34,    -12.11,     -5.00,      5.74,     -7.70,      7.50,     -2.32,      0.05,    -32.49,      4.55]])\n\n\n\nimport numpy as np\nnp.set_printoptions(precision=2, linewidth=140)\n\n\ndef matmul(a, b):\n    (ar, ac), (br, bc) = a.shape, b.shape\n    c = torch.zeros(ar, bc)\n    for i in range(ar):\n        for j in range(bc):\n            for k in range(ac):\n                c[i, j] += a[i, k] * b[k, j]\n    return c\n\n\n\n\nCPU times: user 430 ms, sys: 0 ns, total: 430 ms\nWall time: 430 ms\n\n\n\n\n\nCPU times: user 14min 17s, sys: 170 ms, total: 14min 17s\nWall time: 14min 17s\n\n\n\nar * bc * ac\n\n39200"
  },
  {
    "objectID": "matmul.html#numba",
    "href": "matmul.html#numba",
    "title": "Matrix Multiplication from foundations",
    "section": "Numba",
    "text": "Numba\n\nfrom numba import njit\n\n\n@njit\ndef dot(a, b):\n    res = 0\n    for i in range(len(a)): res += a[i]*b[i]\n    return res\n\n\nfrom numpy import array\n\n\n\n\nCPU times: user 968 ms, sys: 2.28 s, total: 3.25 s\nWall time: 241 ms\n\n\n32.0\n\n\n\n\n\nCPU times: user 6 µs, sys: 11 µs, total: 17 µs\nWall time: 19.8 µs\n\n\n32.0\n\n\nNow only two of our loops are running in Python, not three\n\ndef matmul(a, b):\n    (ar, ac), (br, bc) = a.shape, b.shape\n    c = torch.zeros(ar, bc)\n    for i in range(ar):\n        for j in range(bc):\n            c[i, j] = dot(a[i, :], b[:, j])\n    return c\n\n\nm1a, m2a = m1.numpy(), m2.numpy()\n\n\nfrom fastcore.test import *\n\n\ntest_close(t1, matmul(m1a, m2a), eps=1e-04)\n\n\n\n\n278 µs ± 12 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)"
  },
  {
    "objectID": "matmul.html#elementwise-ops",
    "href": "matmul.html#elementwise-ops",
    "title": "Matrix Multiplication from foundations",
    "section": "Elementwise ops",
    "text": "Elementwise ops\n\na = tensor([10., 6, -4])\nb = tensor([2., 8, 7])\na, b\n\n(tensor([10.,  6., -4.]), tensor([2., 8., 7.]))\n\n\n\na + b\n\ntensor([12., 14.,  3.])\n\n\n\n(a < b).float().mean()\n\ntensor(0.67)\n\n\n\nm  = tensor([[1., 2, 3], [4, 5, 6], [7, 8, 9]]); m\n\ntensor([[1., 2., 3.],\n        [4., 5., 6.],\n        [7., 8., 9.]])\n\n\nFrobenius norm:\n\\[\\| A \\|_F = \\left( \\sum_{i,j=1}^n | a_{ij} |^2 \\right)^{1/2}\\]\n\nsf = (m*m).sum()\nsf\n\ntensor(285.)\n\n\n\nsf.sqrt()\n\ntensor(16.88)\n\n\n\nm[2, :], m[:, 2]\n\n(tensor([7., 8., 9.]), tensor([3., 6., 9.]))\n\n\n\nm[2]\n\ntensor([7., 8., 9.])\n\n\n\ndef matmul(a, b):\n    (ar, ac), (br, bc) = a.shape, b.shape\n    c = torch.zeros(ar, bc)\n    for i in range(ar):\n        for j in range(bc):\n            c[i, j] = (a[i, :] * b[:, j]).sum()\n    return c\n\n\ntest_close(t1, matmul(m1, m2), eps=1e-4)\n\n\n\n\n680 µs ± 5.06 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n\n\n\ndef matmul(a, b):\n    (ar, ac), (br, bc) = a.shape, b.shape\n    c = torch.zeros(ar, bc)\n    for i in range(ar):\n        for j in range(bc): \n            c[i, j] = torch.dot(a[i,:], b[:, j])\n    return c\n\n\ntest_close(t1, matmul(m1, m2), eps=1e-4)\n\n\n\n\n574 µs ± 4.47 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)"
  },
  {
    "objectID": "matmul.html#broadcasting",
    "href": "matmul.html#broadcasting",
    "title": "Matrix Multiplication from foundations",
    "section": "Broadcasting",
    "text": "Broadcasting\n\na\n\ntensor([10.,  6., -4.])\n\n\n\na > 0\n\ntensor([ True,  True, False])\n\n\n\na + 1\n\ntensor([11.,  7., -3.])\n\n\n\nm\n\ntensor([[1., 2., 3.],\n        [4., 5., 6.],\n        [7., 8., 9.]])\n\n\n\n2 * m\n\ntensor([[ 2.,  4.,  6.],\n        [ 8., 10., 12.],\n        [14., 16., 18.]])"
  },
  {
    "objectID": "matmul.html#broadcasting-a-vector-to-matrix",
    "href": "matmul.html#broadcasting-a-vector-to-matrix",
    "title": "Matrix Multiplication from foundations",
    "section": "Broadcasting a vector to matrix",
    "text": "Broadcasting a vector to matrix\n\nc = tensor([10., 20, 30]); c\n\ntensor([10., 20., 30.])\n\n\n\nm\n\ntensor([[1., 2., 3.],\n        [4., 5., 6.],\n        [7., 8., 9.]])\n\n\n\nm.shape, c.shape\n\n(torch.Size([3, 3]), torch.Size([3]))\n\n\n\nm + c\n\ntensor([[11., 22., 33.],\n        [14., 25., 36.],\n        [17., 28., 39.]])\n\n\n\nc + m\n\ntensor([[11., 22., 33.],\n        [14., 25., 36.],\n        [17., 28., 39.]])\n\n\n\nt = c.expand_as(m); t\n\ntensor([[10., 20., 30.],\n        [10., 20., 30.],\n        [10., 20., 30.]])\n\n\n\nm + t\n\ntensor([[11., 22., 33.],\n        [14., 25., 36.],\n        [17., 28., 39.]])\n\n\n\nt.storage()\n\n 10.0\n 20.0\n 30.0\n[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 3]\n\n\n\nt.stride(), t.shape\n\n((0, 1), torch.Size([3, 3]))\n\n\n\nc.unsqueeze(0), c[None, :]\n\n(tensor([[10., 20., 30.]]), tensor([[10., 20., 30.]]))\n\n\n\nc.shape, c.unsqueeze(0).shape\n\n(torch.Size([3]), torch.Size([1, 3]))\n\n\n\nc.unsqueeze(1), c[:, None]\n\n(tensor([[10.],\n         [20.],\n         [30.]]),\n tensor([[10.],\n         [20.],\n         [30.]]))\n\n\n\nc.shape, c.unsqueeze(1).shape\n\n(torch.Size([3]), torch.Size([3, 1]))\n\n\n\nc[None].shape, c[..., None].shape\n\n(torch.Size([1, 3]), torch.Size([3, 1]))\n\n\n\nc[:, None].expand_as(m)\n\ntensor([[10., 10., 10.],\n        [20., 20., 20.],\n        [30., 30., 30.]])\n\n\n\nm + c[:, None]\n\ntensor([[11., 12., 13.],\n        [24., 25., 26.],\n        [37., 38., 39.]])\n\n\n\nm + c[None, :]\n\ntensor([[11., 22., 33.],\n        [14., 25., 36.],\n        [17., 28., 39.]])"
  },
  {
    "objectID": "matmul.html#broadcasting-rules",
    "href": "matmul.html#broadcasting-rules",
    "title": "Matrix Multiplication from foundations",
    "section": "Broadcasting Rules",
    "text": "Broadcasting Rules\n\nc[None, :]\n\ntensor([[10., 20., 30.]])\n\n\n\nc[None, :].shape\n\ntorch.Size([1, 3])\n\n\n\nc[:, None]\n\ntensor([[10.],\n        [20.],\n        [30.]])\n\n\n\nc[:, None].shape\n\ntorch.Size([3, 1])\n\n\n\nc[None, :] * c[:, None]\n\ntensor([[100., 200., 300.],\n        [200., 400., 600.],\n        [300., 600., 900.]])\n\n\n\nc[None] > c[:, None]\n\ntensor([[False,  True,  True],\n        [False, False,  True],\n        [False, False, False]])"
  },
  {
    "objectID": "matmul.html#matmul-with-broadcasting",
    "href": "matmul.html#matmul-with-broadcasting",
    "title": "Matrix Multiplication from foundations",
    "section": "Matmul with broadcasting",
    "text": "Matmul with broadcasting\n\ndigit = m1[0]\ndigit.shape, m2.shape\n\n(torch.Size([784]), torch.Size([784, 10]))\n\n\n\ndigit[:, None].shape\n\ntorch.Size([784, 1])\n\n\n\ndigit[:, None].expand_as(m2).shape\n\ntorch.Size([784, 10])\n\n\n\n(digit[:, None] * m2).shape\n\ntorch.Size([784, 10])\n\n\n\ndef matmul(a, b):\n    (ar, ac), (br, bc) = a.shape, b.shape\n    c = torch.zeros(ar, bc)\n    for i in range(ar):\n        c[i] = (a[i, :, None] * b).sum(dim=0)\n    return c\n\n\ntest_close(t1, matmul(m1, m2), eps=1e-4)\n\n\n\n\n82.6 µs ± 3.01 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n\n\n\nLets do it on whole dataset\n\ntr = matmul(x_train, weights)\ntr\n\ntensor([[  4.11, -12.53,  -1.89,  ..., -21.99,   3.60,   6.80],\n        [  1.38,  15.69, -17.93,  ..., -26.70,  -7.98,   9.86],\n        [-10.35,  -6.54,  -6.13,  ...,  -5.52,  21.08,   6.99],\n        ...,\n        [-13.34, -18.76,   2.85,  ..., -10.86,   2.95,   7.05],\n        [ -6.85, -18.32, -17.35,  ...,  -2.53, -27.76,  20.31],\n        [  0.58, -14.51,   6.24,  ...,  -4.71, -12.11,   8.88]])\n\n\n\ntr.shape\n\ntorch.Size([60000, 10])\n\n\n\n\n\nCPU times: user 977 ms, sys: 0 ns, total: 977 ms\nWall time: 912 ms"
  },
  {
    "objectID": "matmul.html#einstein-summation",
    "href": "matmul.html#einstein-summation",
    "title": "Matrix Multiplication from foundations",
    "section": "Einstein summation",
    "text": "Einstein summation\nEinstein summation is a compact representation for combining products and sums in a general way. The key rules are: - Repeating letters between input arrays means that values along those axes will be multiplied together - Omitting a letter from the output means that values along that axis will be summed\n\nm1.shape, m2.shape\n\n(torch.Size([5, 784]), torch.Size([784, 10]))\n\n\n\nmr = torch.einsum('ik,kj->ikj', m1, m2)\nmr.shape\n\ntorch.Size([5, 784, 10])\n\n\n\nmr.sum(1)\n\ntensor([[    -3.01,     -8.56,     -9.20,      2.11,     31.04,      8.28,    -23.90,    -27.77,      6.28,     14.00],\n        [     1.90,    -16.80,     -9.05,     -3.14,    -14.11,     -4.65,    -35.03,     -5.05,    -10.14,    -13.68],\n        [     7.40,     -9.98,     -8.83,      3.37,      6.50,      0.02,      0.98,    -10.19,    -13.01,      4.44],\n        [    10.39,    -12.66,    -17.70,      9.21,     22.84,     26.55,     -0.16,    -16.62,    -10.45,     12.81],\n        [   -12.34,    -12.11,     -5.00,      5.74,     -7.70,      7.50,     -2.32,      0.05,    -32.49,      4.55]])\n\n\n\ntorch.einsum('ik,kj->ij', m1, m2)\n\ntensor([[    -3.01,     -8.56,     -9.20,      2.11,     31.04,      8.28,    -23.90,    -27.77,      6.28,     14.00],\n        [     1.90,    -16.80,     -9.05,     -3.14,    -14.11,     -4.65,    -35.03,     -5.05,    -10.14,    -13.68],\n        [     7.40,     -9.98,     -8.83,      3.37,      6.50,      0.02,      0.98,    -10.19,    -13.01,      4.44],\n        [    10.39,    -12.66,    -17.70,      9.21,     22.84,     26.55,     -0.16,    -16.62,    -10.45,     12.81],\n        [   -12.34,    -12.11,     -5.00,      5.74,     -7.70,      7.50,     -2.32,      0.05,    -32.49,      4.55]])\n\n\n\ndef matmul(a, b): return torch.einsum('ik,kj->ij', a, b)\n\n\ntest_close(tr, matmul(x_train, weights), eps=1e-3)\n\n\n\n\n4.92 ms ± 189 µs per loop (mean ± std. dev. of 7 runs, 5 loops each)\n\n\n\npytorch op\nWe can use pytorch’s function or operator directly for matrix multiplication.\n\ntest_close(tr, x_train@weights, eps=1e-3)\n\n\n\n\n4.92 ms ± 182 µs per loop (mean ± std. dev. of 7 runs, 5 loops each)"
  },
  {
    "objectID": "matmul.html#cuda",
    "href": "matmul.html#cuda",
    "title": "Matrix Multiplication from foundations",
    "section": "CUDA",
    "text": "CUDA\n\ndef matmul(grid, a, b, c):\n    i, j = grid\n    if i < c.shape[0] and j < c.shape[1]:\n        tmp = 0.\n        for k in range(a.shape[1]): tmp += a[i, k] * b[k, j]\n        c[i, j] = tmp\n\n\nres = torch.zeros(ar, bc)\nmatmul((0, 0), m1, m2, res)\nres\n\ntensor([[-3.01,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00],\n        [ 0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00],\n        [ 0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00],\n        [ 0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00],\n        [ 0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00]])\n\n\n\ndef launch_kernel(kernel, grid_x, grid_y, *args, **kwargs):\n    for i in range(grid_x):\n        for j in range(grid_y):\n            kernel((i, j), *args, **kwargs)\n\n\nres = torch.zeros(ar, bc)\nlaunch_kernel(matmul, ar, bc, m1, m2, res)\nres\n\ntensor([[    -3.01,     -8.56,     -9.20,      2.11,     31.04,      8.28,    -23.90,    -27.77,      6.28,     14.00],\n        [     1.90,    -16.80,     -9.05,     -3.14,    -14.11,     -4.65,    -35.03,     -5.05,    -10.14,    -13.68],\n        [     7.40,     -9.98,     -8.83,      3.37,      6.50,      0.02,      0.98,    -10.19,    -13.01,      4.44],\n        [    10.39,    -12.66,    -17.70,      9.21,     22.84,     26.55,     -0.16,    -16.62,    -10.45,     12.81],\n        [   -12.34,    -12.11,     -5.00,      5.74,     -7.70,      7.50,     -2.32,      0.05,    -32.49,      4.55]])\n\n\n\nfrom numba import cuda\n\n\n@cuda.jit\ndef matmul(a, b, c):\n    i, j = cuda.grid(2)\n    if i < c.shape[0] and j < c.shape[1]:\n        tmp = 0.\n        for k in range(a.shape[1]): tmp += a[i, k] * b[k, j]\n        c[i, j] = tmp\n\n\nr = np.zeros(tr.shape)\nm1g, m2g, rg = cuda.to_device(x_train), cuda.to_device(weights), cuda.to_device(r)\n\n\nr.shape\n\n(60000, 10)\n\n\n\nTPB = 16\nrr, rc = r.shape\nblockspergrid = (math.ceil(rr / TPB), math.ceil(rc / TPB))\nblockspergrid\n\n(3750, 1)\n\n\n\nmatmul[blockspergrid, (TPB, TPB)](m1g, m2g, rg)\nr = rg.copy_to_host()\ntest_close(tr, r, eps=1.03)\n\n\nmatmul[blockspergrid, (TPB, TPB)](m1g, m2g, rg)\nr = rg.copy_to_host()\n\n5.18 ms ± 57.5 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\n\nm1c, m2c = x_train.cuda(), weights.cuda()\n\n\nr = (m1c @ m2c).cpu()\n\n\n\n\n698 µs ± 139 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\nOur broadcastng version was > 500ms, and our CUDA version is around 0.5 ms, which is another 1000x improvement compared to broacasting. So our total speedup is around 5 million times compared to the initial 3 loop matrix multiplication!"
  },
  {
    "objectID": "meanshift_lsh.html",
    "href": "meanshift_lsh.html",
    "title": "Meanshift Using LSH",
    "section": "",
    "text": "import numpy as np\nimport math\nfrom math import pi\nimport torch\nfrom matplotlib import pyplot as plt\nfrom torch.distributions import MultivariateNormal\nfrom miniai.lsh import LSH"
  },
  {
    "objectID": "meanshift_lsh.html#gpu-batched-algorithm",
    "href": "meanshift_lsh.html#gpu-batched-algorithm",
    "title": "Meanshift Using LSH",
    "section": "GPU Batched algorithm",
    "text": "GPU Batched algorithm\n\nbs = 5\nX = data.clone()\nx = X[:bs]\nx.shape, X.shape\n\n(torch.Size([5, 2]), torch.Size([1500, 2]))\n\n\n\ndist = ((x[:,None] - X[None]) ** 2).sum(-1).sqrt()\ndist.shape, dist\n\n(torch.Size([5, 1500]),\n tensor([[  0.00000,   2.96982,   3.36906,  ..., 209.04686, 210.20853, 209.90276],\n         [  2.96982,   0.00000,   4.58362,  ..., 208.38335, 209.50293, 209.21017],\n         [  3.36906,   4.58362,   0.00000,  ..., 212.35605, 213.50829, 213.20551],\n         [  3.42341,   1.80829,   3.42423,  ..., 210.16139, 211.27600, 210.98482],\n         [  2.33995,   1.62542,   2.96569,  ..., 209.84781, 210.97752, 210.68167]]))\n\n\n\nweight = gaussian(dist)\nweight\n\ntensor([[0.15958, 0.07880, 0.06436,  ..., 0.00000, 0.00000, 0.00000],\n        [0.07880, 0.15958, 0.02972,  ..., 0.00000, 0.00000, 0.00000],\n        [0.06436, 0.02972, 0.15958,  ..., 0.00000, 0.00000, 0.00000],\n        [0.06249, 0.12285, 0.06246,  ..., 0.00000, 0.00000, 0.00000],\n        [0.10298, 0.12917, 0.07896,  ..., 0.00000, 0.00000, 0.00000]])\n\n\n\nweight.shape\n\ntorch.Size([5, 1500])\n\n\n\n(weight @ X).shape\n\ntorch.Size([5, 2])\n\n\n\nweight.sum(1, keepdims=True).shape\n\ntorch.Size([5, 1])\n\n\n\nfor i in range(0, 10, 2):\n    print(i)\n\n0\n2\n4\n6\n8\n\n\n\ndef one_update(X, bs):\n    n = len(X)\n    for i in range(0, n, bs):\n        s = slice(i, min(i+bs, n))\n        x = X[s]\n        dist = ((x[:,None] - X[None]) ** 2).sum(-1).sqrt()\n        weight = gaussian(dist)\n        X[s] = (weight @ X)/ (weight.sum(1, keepdims=True))\n\n\ndef meanshift(data, bs=16):\n    X = data.clone()\n    for i in range(10): one_update(X, bs)\n    return X\n\n\ndata = data.cuda()\n\n48.1 ms ± 543 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\n\n\n\n4.4 ms ± 1.93 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\n\nX\n\ntensor([[ -28.43384, -102.60363],\n        [ -28.43384, -102.60363],\n        [ -28.43384, -102.60363],\n        ...,\n        [ -26.46349,  106.65351],\n        [ -26.46349,  106.65351],\n        [ -26.46349,  106.65351]])\n\n\n\nplot_data(centroids +5, X)"
  },
  {
    "objectID": "meanshift.html",
    "href": "meanshift.html",
    "title": "Clustering",
    "section": "",
    "text": "Clustering techniques are unsupervised algorithms that try to group unlabelled data into “clusters”, using the (typically spatial) structure of the data itself. It has many applications.\nThe easiest way to demonstrate how clustering works is to simply generate some data and show them in action. We’ll start off by importing the libraries we’ll be using today."
  },
  {
    "objectID": "meanshift.html#create-data",
    "href": "meanshift.html#create-data",
    "title": "Clustering",
    "section": "Create data",
    "text": "Create data\n\nn_clusters = 6\nn_samples = 250\n\nTo generate our data, we are going back to pick 6 random points, which we will call centroids, and for each point we are going to generate 250 random points about it.\n\ncentroids = torch.rand(n_clusters, 2) * 70 - 35\n\n\ncentroids\n\ntensor([[ 26.759,  29.050],\n        [ -8.200,  32.151],\n        [ -7.669,   7.063],\n        [-17.040,  20.555],\n        [ 30.854, -25.677],\n        [ 30.422,   6.551]])\n\n\n\nfrom torch.distributions.multivariate_normal import MultivariateNormal\nfrom torch import tensor\n\n\ndef sample(m): return MultivariateNormal(m, torch.diag(tensor([5., 5.]))).sample((n_samples, ))\n\n\nslices = [sample(c) for c in centroids]\ndata  = torch.cat(slices)\ndata.shape\n\ntorch.Size([1500, 2])\n\n\nBelow we can see each centroid marked w/X, and the coloring associated to each respective cluster.\n\ndef plot_data(centroids, data, n_samples, ax=None):\n    if ax is None: _, ax = plt.subplots()\n    for i, centroid in enumerate(centroids):\n        samples = data[i*n_samples: (i+1)*n_samples]\n        ax.scatter(samples[:, 0], samples[:, 1], s=1)\n        ax.plot(*centroid, markersize=10, marker=\"x\", color='k', mew=5)\n        ax.plot(*centroid, markersize=5, marker=\"x\", color='m', mew=2)\n\n\nplot_data(centroids, data, n_samples)"
  },
  {
    "objectID": "meanshift.html#mean-shift",
    "href": "meanshift.html#mean-shift",
    "title": "Clustering",
    "section": "Mean Shift",
    "text": "Mean Shift\nMost people that have come across clustering algorithms have learnt about k-means. Mean shift clustering is a newer and less well-known approach, but it has some important advantages: - It doesn’t require selecting the number of clusters in advance, but instead just requires a bandwidth to be specified, which can be easily chosen automatically. - It can handle clusters of any shape, whereas k-means (without using special extensions) requires that clusters be roughly ball shaped\nThe algorithm is as follows: - For each data point x in the sample X, find the distance between that point x and every other point in X - Create weights for each point in X by using the Gaussian kernel of that point’s distance to x - This weighting approach penalizes points further away from x - The rate at which the weights fall to zero is determined by the bandwidth, which is the standard deviation of the Gaussian - Update x as the weighted all other points in X, weighted based on the previous step\nThis will iteratively push points that are close together even closer until they are next to each other\n\nmidp = data.mean(0)\nmidp\n\ntensor([ 9.222, 11.604])\n\n\n\nplot_data([midp]*6, data, n_samples)\n\n\n\n\nSo here is the definition of the gaussian kernel, which you may remember from high school..\n\\[ \\frac{1}{\\sqrt{ 2 \\pi \\sigma^2 }} \\exp\\biggl( - \\frac{ (x - \\mu)^2 } {2 \\sigma^2} \\biggr) \\]\n\ndef gaussian(d, bw): return torch.exp(-0.5*((d/bw))**2) / (bw*math.sqrt(2*math.pi))\n\n\ndef plot_func(f):\n    x = torch.linspace(0, 10, 100)\n    plt.plot(x, f(x))\n\n\nplot_func(partial(gaussian, bw=2.5))\n\n\n\n\n\npartial\n\nfunctools.partial\n\n\nIn our implementation, we choose the bandwidth to be 2.5\nOne easy way to choose bandwidth is to find which bandwidth covers one thid of the data\n\ndef tri(d, i): return (-d + i).clamp_min(0)/i\n\n\nplot_func(partial(tri, i=8))\n\n\n\n\n\nX = data.clone()\nx = data[0]\n\n\nx\n\ntensor([26.204, 26.349])\n\n\n\nx.shape, X.shape, x[None].shape\n\n(torch.Size([2]), torch.Size([1500, 2]), torch.Size([1, 2]))\n\n\n\n(x[None] - X)[:8]\n\ntensor([[ 0.000,  0.000],\n        [ 0.513, -3.865],\n        [-4.227, -2.345],\n        [ 0.557, -3.685],\n        [-5.033, -3.745],\n        [-4.073, -0.638],\n        [-3.415, -5.601],\n        [-1.920, -5.686]])\n\n\n\n(x - X)[:8]\n\ntensor([[ 0.000,  0.000],\n        [ 0.513, -3.865],\n        [-4.227, -2.345],\n        [ 0.557, -3.685],\n        [-5.033, -3.745],\n        [-4.073, -0.638],\n        [-3.415, -5.601],\n        [-1.920, -5.686]])\n\n\n\ndist = ((x-X)**2).sum(1).sqrt()\ndist[:8]\n\ntensor([0.000, 3.899, 4.834, 3.726, 6.273, 4.122, 6.560, 6.002])\n\n\n\n((x-X)**2).sum(1)\n\ntensor([  0.000,  15.199,  23.369,  ..., 310.729, 511.192, 467.316])\n\n\n\nrewrite using torch.einsum\n\n\ntorch.einsum('ik,ik->i',x-X, x-X).sqrt()\n\ntensor([ 0.000,  3.899,  4.834,  ..., 17.628, 22.610, 21.617])\n\n\n\nweight = gaussian(dist, 2.5)\nweight\n\ntensor([    0.160,     0.047,     0.025,  ...,     0.000,     0.000,     0.000])\n\n\n\nweight.shape, X.shape\n\n(torch.Size([1500]), torch.Size([1500, 2]))\n\n\n\nweight[:, None].shape\n\ntorch.Size([1500, 1])\n\n\n\nweight[:, None] * X\n\ntensor([[    4.182,     4.205],\n        [    1.215,     1.429],\n        [    0.749,     0.706],\n        ...,\n        [    0.000,     0.000],\n        [    0.000,     0.000],\n        [    0.000,     0.000]])\n\n\n\ndef one_update(X):\n    for i, x in enumerate(X):\n        dist = torch.sqrt(((x - X)**2).sum(1))\n#         weight = gaussian(dist, 2.5)\n        weight = tri(dist, 8)\n        X[i] = (weight[:, None] * X).sum(0)/weight.sum()\n\n\ndef meanshift(data):\n    X = data.clone()\n    for it in range(5): one_update(X)\n    return X\n\n\n\n\nCPU times: user 470 ms, sys: 0 ns, total: 470 ms\nWall time: 470 ms\n\n\n\nplot_data(centroids + 2, X, n_samples)"
  },
  {
    "objectID": "meanshift.html#animation",
    "href": "meanshift.html#animation",
    "title": "Clustering",
    "section": "Animation",
    "text": "Animation\n\nfrom matplotlib.animation import FuncAnimation\nfrom IPython.display import HTML\n\n\ndef do_one(d):\n    if not d: return plot_data(centroids + 2, X, n_samples, ax=ax)\n    one_update(X)\n    ax.clear()\n    plot_data(centroids + 2, X, n_samples, ax=ax)\n\n\nX = data.clone()\nfig,ax = plt.subplots()\nani = FuncAnimation(fig, do_one, frames=5, interval=500, repeat=False)\nplt.close()\nHTML(ani.to_jshtml())\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\nanimation for your own algorithm"
  },
  {
    "objectID": "meanshift.html#gpu-batched-algorithm",
    "href": "meanshift.html#gpu-batched-algorithm",
    "title": "Clustering",
    "section": "GPU batched algorithm",
    "text": "GPU batched algorithm\nTo truly accelerate the algorithm, we need to be performing updates on a batch of points per iteration, instead of just one as were doing\n\nbs = 5\nX = data.clone()\nx = X[:bs]\nx.shape, X.shape\n\n(torch.Size([5, 2]), torch.Size([1500, 2]))\n\n\n\ndef dist_b(a, b): return torch.sqrt(((a[None] - b[:, None])**2).sum(2))\n\n\ndist_b(X, x)\n\ntensor([[ 0.000,  3.899,  4.834,  ..., 17.628, 22.610, 21.617],\n        [ 3.899,  0.000,  4.978,  ..., 21.499, 26.508, 25.500],\n        [ 4.834,  4.978,  0.000,  ..., 19.373, 24.757, 23.396],\n        [ 3.726,  0.185,  4.969,  ..., 21.335, 26.336, 25.333],\n        [ 6.273,  5.547,  1.615,  ..., 20.775, 26.201, 24.785]])\n\n\n\ndist_b(X, x).shape\n\ntorch.Size([5, 1500])\n\n\n\nX[None, :].shape, x[:, None].shape, (X[None, :] - x[:, None]).shape\n\n(torch.Size([1, 1500, 2]), torch.Size([5, 1, 2]), torch.Size([5, 1500, 2]))\n\n\n\nweight = gaussian(dist_b(X, x), 2)\nweight\n\ntensor([[    0.199,     0.030,     0.011,  ...,     0.000,     0.000,     0.000],\n        [    0.030,     0.199,     0.009,  ...,     0.000,     0.000,     0.000],\n        [    0.011,     0.009,     0.199,  ...,     0.000,     0.000,     0.000],\n        [    0.035,     0.199,     0.009,  ...,     0.000,     0.000,     0.000],\n        [    0.001,     0.004,     0.144,  ...,     0.000,     0.000,     0.000]])\n\n\n\nweight.shape, X.shape\n\n(torch.Size([5, 1500]), torch.Size([1500, 2]))\n\n\n\nweight[..., None].shape, X[None].shape\n\n(torch.Size([5, 1500, 1]), torch.Size([1, 1500, 2]))\n\n\n\nnum = (weight[..., None]*X[None]).sum(1)\nnum.shape\n\ntorch.Size([5, 2])\n\n\n\nnum\n\ntensor([[367.870, 386.231],\n        [518.332, 588.680],\n        [329.665, 330.782],\n        [527.617, 598.217],\n        [231.302, 234.155]])\n\n\n\ntorch.einsum('ij,jk->ik', weight, X)\n\ntensor([[367.870, 386.231],\n        [518.332, 588.680],\n        [329.665, 330.782],\n        [527.617, 598.217],\n        [231.302, 234.155]])\n\n\n\nweight@X\n\ntensor([[367.870, 386.231],\n        [518.332, 588.680],\n        [329.665, 330.782],\n        [527.617, 598.217],\n        [231.302, 234.155]])\n\n\n\ndiv = weight.sum(1, keepdim=True)\ndiv.shape\n\ntorch.Size([5, 1])\n\n\n\nnum/div\n\ntensor([[26.376, 27.692],\n        [26.101, 29.643],\n        [28.892, 28.990],\n        [26.071, 29.559],\n        [29.323, 29.685]])\n\n\n\ndef meanshift(data, bs=500):\n    n = len(data)\n    X = data.clone()\n    for it in range(5):\n        for i in range(0, n, bs):\n            s = slice(i, min(i+bs, n))\n            weight = gaussian(dist_b(X, X[s]), 2.5)\n            div = weight.sum(1, keepdim=True)\n            X[s] = weight@X/div\n    return X\n\nAlthough each iteration still has to launch a new cuda kernel, there are now fewer iterations, and the acceleration from updating a batch of points more than makes up for it.\n\ndata = data.cuda()\n\n\nX = meanshift(data).cpu()\n\n\n\n\n2.25 ms ± 36 µs per loop (mean ± std. dev. of 7 runs, 5 loops each)\n\n\n\nplot_data(centroids + 2, X, n_samples)\n\n\n\n\n\n\n\n45 ms ± 654 µs per loop (mean ± std. dev. of 7 runs, 5 loops each)"
  },
  {
    "objectID": "locality_sensitive_hashing_lsh.html",
    "href": "locality_sensitive_hashing_lsh.html",
    "title": "Locality Sensitive Hashing (LSH)",
    "section": "",
    "text": "Local sensitive hashing (LSH) is a technique used in approximate nearest neighbor search and similarity-based retrieval tasks. LSH helps in efficiently finding similar items or reducing the search space for similarity queries.\nLSH works by hashing similar items into the same or nearby hash buckets with a high probability. It operates on the principle that if two items are similar, they are likely to collide (hash to the same bucket) under a certain hash function.\nLSH is “local sensitive” because it ensures that nearby items have a higher probability of being hashed into the same bucket, while items that are far apart have a lower probability of colliding. This property allows for efficient pruning of the search space, as we can focus the search on the items within the same hash buckets.\nThere are different types of LSH algorithms designed for various data types and similarity measures. Some common examples include MinHash for document similarity, SimHash for binary data, and L2-LSH for Euclidean distance-based similarity.\nLSH is particularly useful in scenarios where traditional exact search methods become impractical due to high-dimensional data or large dataset sizes. It allows for approximate similarity search with reduced computational complexity, making it a valuable tool in various applications like recommendation systems, image retrieval, and DNA sequence matching.\nI defined the class LSH below which takes the following arguments - dimensions: This is the number of features in the dataset. The higher the number of dimensions, the more complex the LSH algorithm will be. - hash_length: This is the length of the hash value. The longer the hash value, the more accurate the LSH algorithm will be. However, a longer hash value will also take longer to compute. - number_hash_tables: This is the number of hash tables that are used by the LSH algorithm. The more hash tables, the more likely it is that two similar items will be hashed to the same table. However, a larger number of hash tables will also take longer to search. - hash_table: This is a data structure that stores the hash values of the items in the dataset. The hash table is used to quickly find items that have similar hash values.\n\nsource\n\nLSH\n\n LSH (dim, nht, hl)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nlsh = LSH(dim=2, nht=2, hl=5)\n\n\nlsh.hash_table.shape\n\ntorch.Size([2, 5, 2])\n\n\n\ndata = torch.randn(1500, 2) # data\nquery = data[0][None] # query, adding a unit axis at the start\ndata.shape, query.shape\n\n(torch.Size([1500, 2]), torch.Size([1, 2]))\n\n\nThe following line of code performs a cosine similarity between the query and hashtable. The purpose of the code is to apply hash functions to each data point in the input tensor. Each hash function generates a hash code for every data point in query, resulting in a tensor with hash codes\n\nsource\n\n\nLSH.hashing\n\n LSH.hashing (query)\n\nLets hash both the query and data points using hashing function above\n\ndata_hash = lsh.hashing(data)\ndata_hash.shape\n\ntorch.Size([1500, 2, 5])\n\n\nFrom the above the data_hash.shape, we can see we obtained hash_code of length 5 for each 1500 data points generated by 2 hash function\n\nquery_hash = lsh.hashing(query)\nquery_hash.shape\n\ntorch.Size([1, 2, 5])\n\n\nFrom here lets try to get indexes of data where the hashcode of the data and the query point are same\nTo check if it is the same, first we can take a dot product along the last axis and divided by the data’s sum along the last axis.\nIf the values are 1 then it is same, other wise they are not\n\n(query_hash * data_hash).sum(-1)\n\ntensor([[1, 3],\n        [3, 3],\n        [3, 3],\n        ...,\n        [3, 3],\n        [2, 3],\n        [1, 3]])\n\n\n\ndata_hash.sum(-1)\n\ntensor([[3, 3],\n        [2, 2],\n        [2, 3],\n        ...,\n        [3, 2],\n        [3, 1],\n        [3, 3]])\n\n\n\n(query_hash * data_hash).shape\n\ntorch.Size([1500, 2, 5])\n\n\n\n(query_hash * data_hash).sum(-1) / data_hash.sum(-1)\n\ntensor([[1.000, 1.000],\n        [0.000, 0.000],\n        [0.000, 0.667],\n        ...,\n        [1.000, 0.500],\n        [0.333, 0.000],\n        [0.333, 0.667]])\n\n\n\nNow if the `dot product` and its division are\n\n\nresult = ( (query_hash * data_hash).sum(-1) / data_hash.sum(-1) ) == 1\nresult\n\ntensor([[ True,  True],\n        [False, False],\n        [False, False],\n        ...,\n        [ True, False],\n        [False, False],\n        [False, False]])\n\n\nWe can get the indices where the values are True with the following code\n\nresult_indices = torch.nonzero(torch.any(result, dim=1)).flatten()\nresult_indices.shape\n\ntorch.Size([755])\n\n\n\ndata[result_indices].shape\n\ntorch.Size([755, 2])\n\n\nWe got the indices, not lets compute the euclidiean distance (L2 norm). For the compute of the euclidean distance we dont have to compute the distance from every 1500 points but only the points where the hashcode was same.\n\n((query - data[result_indices])**2).sum(-1).sqrt().shape\n\ntorch.Size([755])\n\n\nPutting all the above operation into following single function\n\nsource\n\n\nLSH.query_neigbours\n\n LSH.query_neigbours (query, data, data_hash, neighbours=10)\n\n\nquery = data[0]; query.shape\n\ntorch.Size([2])\n\n\n\ndata_hash = lsh.hashing(data)\nlsh.query_neigbours(query, data, data_hash, 10)\n\n(tensor([1.183, 1.215, 1.221, 1.232, 1.247, 1.267, 1.288, 1.289, 1.292, 1.292]),\n tensor([1100, 1221,  243, 1490,  239, 1071,  957, 1160,  188,  501]))\n\n\n\n\n\n826 µs ± 264 µs per loop (mean ± std. dev. of 7 runs, 5 loops each)\n\n\n\n\nGPU\nI am not able to figure out how can i pass batches of query points for the computation of hash to get the distances\nSo for now I am passing a single query point and data as cuda, lets see if that optimizes than the cpu version above"
  }
]